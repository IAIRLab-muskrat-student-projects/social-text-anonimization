{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–∂–µ—Ç –ø–æ–ª—É—á–∏—Ç—å—Å—è –Ω–∞–π—Ç–∏ –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è —É–º–µ–µ—Ç –ª—É—á—à–µ –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –∞–≤—Ç–æ—Ä–∞ —Ç–µ–∫—Å—Ç–∞ (0.26 —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ) | Done\n",
    "\n",
    "–•–µ—à—Ç–µ–≥–∏:\n",
    "–ë–µ—Ä–µ–º –±–µ—Ä—Ç, –≤—ã—á–∏—Å–ª—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Å–µ—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —É—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ —Ö–µ—à—Ç–µ–≥–∞–º. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞—Ö–æ–¥–∏–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞. –ó–∞–º–µ–Ω—É –∏—â–µ–º –∏–∑ –±–ª–∏–∂–∞–π—à–∏—Ö –ø–æ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–º—É —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é, –Ω–æ —Ç–∞–∫–∂–µ –Ω–µ –±–ª–∏–∑–∫–∏—Ö –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é –ª–µ–≤–µ–Ω—à—Ç–∞–π–Ω–∞.\n",
    "\n",
    "–ü–æ—Å—á–∏—Ç–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –±–µ—Ä—Ç–∞ –Ω–∞ –∑–∞–¥–∞—á–∞—Ö MLM –∏ NSP –¥–ª—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –∏ –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö.\n",
    "–ü–æ—Å—á–∏—Ç–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –∑–∞–¥–∞—á–µ –æ—Ü–µ–Ω–∫–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏. –î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –∏–Ω—Å—Ç—ã –º–æ–∂–µ—Ç –ú–∏—à–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å, –µ—Å—Ç—å –≤ –∏–Ω–µ—Ç–µ —Ç–∞–∫–∂–µ –ø–æ —Ç–≤–∏—Ç—Ç–µ—Ä—É.\n",
    "\n",
    "–ö–∞–∫ –æ—Å—Ç–∞–≤–∏—Ç—å —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –¥—Ä—É–≥–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π? –ó–∞–º–µ–Ω–∏—Ç—å –∏—Ö –≤ —Ç–µ–∫—Å—Ç–µ –Ω–∞ <MASK> –Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ—Ç–æ–º –≤—Å—Ç–∞–≤–∏—Ç—å –Ω–∞ –º–µ—Å—Ç–æ —Ç–æ–∫–µ–Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "eng_stopwords = stopwords.words('english')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import fasttext\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "from cleantext import clean\n",
    "\n",
    "from transformers import (\n",
    "    AutoModel, \n",
    "    AutoModelForMaskedLM,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from transformers import pipeline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Embedding\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import re\n",
    "from itertools import chain, islice\n",
    "import logging\n",
    "import os\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "from utils import apply_clean, get_text_and_hashtags\n",
    "\n",
    "SEED = 42\n",
    "TRAIN_DOC_COUNT = 10000\n",
    "TEST_DOC_COUNT = 1000\n",
    "AUTHOR_COUNT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = torch.randn(100, 128)\n",
    "input2 = torch.randn(100, 128)\n",
    "cos_sim = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "output = cos_sim(input1, input2)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small.n.01 ['small']\n",
      "small.n.02 ['small']\n",
      "small.a.01 ['small', 'little']\n",
      "minor.s.10 ['minor', 'modest', 'small', 'small-scale', 'pocket-size', 'pocket-sized']\n",
      "little.s.03 ['little', 'small']\n"
     ]
    }
   ],
   "source": [
    "synonyms = wordnet.synsets('small')\n",
    "for ss in islice(synonyms, 5):\n",
    "    print(ss.name(), ss.lemma_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortcode</th>\n",
       "      <th>caption</th>\n",
       "      <th>authorid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BtE14s-AcIT</td>\n",
       "      <td>Right or Left?\\n\\nBuffalo Chicken slice on the...</td>\n",
       "      <td>4640452414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BtEYaa1FozM</td>\n",
       "      <td>Friday‚Äôs at the office just got a little sweet...</td>\n",
       "      <td>8486247913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BtDq0V4FKOZ</td>\n",
       "      <td>The early bird gets the best sunrise pics.</td>\n",
       "      <td>185562852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BtEwnkfFzCg</td>\n",
       "      <td>Poor Cyndy!  This superstar massage therapist ...</td>\n",
       "      <td>247991751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BtEwsGCAcmq</td>\n",
       "      <td>he hit the booty like a drum, yumyum.üòÄ why he ...</td>\n",
       "      <td>8102841338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     shortcode                                            caption    authorid\n",
       "0  BtE14s-AcIT  Right or Left?\\n\\nBuffalo Chicken slice on the...  4640452414\n",
       "1  BtEYaa1FozM  Friday‚Äôs at the office just got a little sweet...  8486247913\n",
       "2  BtDq0V4FKOZ         The early bird gets the best sunrise pics.   185562852\n",
       "3  BtEwnkfFzCg  Poor Cyndy!  This superstar massage therapist ...   247991751\n",
       "4  BtEwsGCAcmq  he hit the booty like a drum, yumyum.üòÄ why he ...  8102841338"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['shortcode', 'caption', 'authorid']\n",
    "\n",
    "nyc_posts_df = pd.read_csv('/mnt/ess_storage/DN_1/storage/home/vpanov/instagram_posts/data/nyc_posts_2019.csv', usecols=cols, nrows=10000000)\n",
    "nyc_posts_df = nyc_posts_df.dropna(axis=0)\n",
    "nyc_posts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2422245"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nyc_posts_df['authorid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288898810     405\n",
       "581325206     404\n",
       "31033532      404\n",
       "6612357200    404\n",
       "2206015241    403\n",
       "             ... \n",
       "1303589730    374\n",
       "3711248845    374\n",
       "7370266134    374\n",
       "1418705634    373\n",
       "1291658614    373\n",
       "Name: authorid, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset = 500\n",
    "nyc_posts_df['authorid'].value_counts()[offset:offset+AUTHOR_COUNT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortcode</th>\n",
       "      <th>caption</th>\n",
       "      <th>authorid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4947526</th>\n",
       "      <td>BxtFxE0FYag</td>\n",
       "      <td>TODAY\\nMay 20th\\n@fortythirdstreetcafe will be...</td>\n",
       "      <td>450551504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384135</th>\n",
       "      <td>BwmpRlZgfXV</td>\n",
       "      <td>Today is beautiful and so are you.</td>\n",
       "      <td>1594705691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9020735</th>\n",
       "      <td>B0Dy8axlAI1</td>\n",
       "      <td>It‚Äôs definitely a good feeling when you see yo...</td>\n",
       "      <td>1506891433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726136</th>\n",
       "      <td>BsGM4d2FP6W</td>\n",
       "      <td>Bike Club Shop Ride, Croton Aqueduct Trail, Ja...</td>\n",
       "      <td>36407423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6367470</th>\n",
       "      <td>B3a6YFwHss1</td>\n",
       "      <td>World War 2 casualty #gravesite #ww2 #soldier ...</td>\n",
       "      <td>1567349564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           shortcode                                            caption  \\\n",
       "4947526  BxtFxE0FYag  TODAY\\nMay 20th\\n@fortythirdstreetcafe will be...   \n",
       "4384135  BwmpRlZgfXV                 Today is beautiful and so are you.   \n",
       "9020735  B0Dy8axlAI1  It‚Äôs definitely a good feeling when you see yo...   \n",
       "5726136  BsGM4d2FP6W  Bike Club Shop Ride, Croton Aqueduct Trail, Ja...   \n",
       "6367470  B3a6YFwHss1  World War 2 casualty #gravesite #ww2 #soldier ...   \n",
       "\n",
       "           authorid  \n",
       "4947526   450551504  \n",
       "4384135  1594705691  \n",
       "9020735  1506891433  \n",
       "5726136    36407423  \n",
       "6367470  1567349564  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_productive_authors = nyc_posts_df['authorid'].value_counts()[offset:offset+AUTHOR_COUNT].index.values\n",
    "nyc_posts_authors_df = nyc_posts_df[nyc_posts_df.authorid.isin(most_productive_authors)].sample(frac=1.0, random_state=SEED)\n",
    "nyc_posts_authors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)\n",
    "\n",
    "def apply_clean(doc):\n",
    "    doc = clean(doc,\n",
    "                fix_unicode=True,               # fix various unicode errors\n",
    "                to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "                lower=True,                     # lowercase text\n",
    "                no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them\n",
    "                no_urls=True,                  # replace all URLs with a special token\n",
    "                no_emails=True,                # replace all email addresses with a special token\n",
    "                no_phone_numbers=False,         # replace all phone numbers with a special token\n",
    "                no_numbers=False,               # replace all numbers with a special token\n",
    "                no_digits=False,                # replace all digits with a special token\n",
    "                no_currency_symbols=False,      # replace all currency symbols with a special token\n",
    "                no_punct=False,                 # remove punctuations\n",
    "                replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
    "                replace_with_url=\"<URL>\",\n",
    "                replace_with_email=\"<EMAIL>\",\n",
    "                lang=\"en\"                       # set to 'de' for German special handling\n",
    "               )\n",
    "    doc = remove_emojis(doc)\n",
    "    return doc\n",
    "\n",
    "nyc_posts_authors_df.caption = nyc_posts_authors_df.caption.apply(apply_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortcode</th>\n",
       "      <th>caption</th>\n",
       "      <th>authorid</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4947526</th>\n",
       "      <td>BxtFxE0FYag</td>\n",
       "      <td>today may 20th @fortythirdstreetcafe will be o...</td>\n",
       "      <td>450551504</td>\n",
       "      <td>today may 20th @fortythirdstreetcafe will be o...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384135</th>\n",
       "      <td>BwmpRlZgfXV</td>\n",
       "      <td>today is beautiful and so are you.</td>\n",
       "      <td>1594705691</td>\n",
       "      <td>today is beautiful and so are you.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9020735</th>\n",
       "      <td>B0Dy8axlAI1</td>\n",
       "      <td>it's definitely a good feeling when you see yo...</td>\n",
       "      <td>1506891433</td>\n",
       "      <td>it's definitely a good feeling when you see yo...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726136</th>\n",
       "      <td>BsGM4d2FP6W</td>\n",
       "      <td>bike club shop ride, croton aqueduct trail, ja...</td>\n",
       "      <td>36407423</td>\n",
       "      <td>bike club shop ride, croton aqueduct trail, ja...</td>\n",
       "      <td>#bike #bikes #bikelife #shopride #shoplife #my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6367470</th>\n",
       "      <td>B3a6YFwHss1</td>\n",
       "      <td>world war 2 casualty #gravesite #ww2 #soldier ...</td>\n",
       "      <td>1567349564</td>\n",
       "      <td>world war 2 casualty</td>\n",
       "      <td>#gravesite #ww2 #soldier #rip #queens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           shortcode                                            caption  \\\n",
       "4947526  BxtFxE0FYag  today may 20th @fortythirdstreetcafe will be o...   \n",
       "4384135  BwmpRlZgfXV                 today is beautiful and so are you.   \n",
       "9020735  B0Dy8axlAI1  it's definitely a good feeling when you see yo...   \n",
       "5726136  BsGM4d2FP6W  bike club shop ride, croton aqueduct trail, ja...   \n",
       "6367470  B3a6YFwHss1  world war 2 casualty #gravesite #ww2 #soldier ...   \n",
       "\n",
       "           authorid                                               text  \\\n",
       "4947526   450551504  today may 20th @fortythirdstreetcafe will be o...   \n",
       "4384135  1594705691                 today is beautiful and so are you.   \n",
       "9020735  1506891433  it's definitely a good feeling when you see yo...   \n",
       "5726136    36407423  bike club shop ride, croton aqueduct trail, ja...   \n",
       "6367470  1567349564                               world war 2 casualty   \n",
       "\n",
       "                                                  hashtags  \n",
       "4947526                                                     \n",
       "4384135                                                     \n",
       "9020735                                                     \n",
       "5726136  #bike #bikes #bikelife #shopride #shoplife #my...  \n",
       "6367470              #gravesite #ww2 #soldier #rip #queens  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_text_and_hashtags(row):\n",
    "    text = row['caption']\n",
    "    if len(text) == 0:\n",
    "        return ''\n",
    "    return re.sub('#\\w+', '', text).strip(), ' '.join(re.findall('#\\w+', text))\n",
    "\n",
    "nyc_posts_authors_df[['text', 'hashtags']] = nyc_posts_authors_df.apply(get_text_and_hashtags, axis=1, result_type='expand')\n",
    "nyc_posts_authors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38795"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nyc_posts_authors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25969"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nyc_posts_authors_df[nyc_posts_authors_df.text.str.len() > 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nyc_posts_authors_df[nyc_posts_authors_df.text.str.len() > 50].authorid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10579934087    403\n",
       "288898810      400\n",
       "182549672      399\n",
       "1706798002     398\n",
       "2112186305     392\n",
       "10198719       392\n",
       "1795862337     392\n",
       "2040926754     391\n",
       "477908643      386\n",
       "270846038      386\n",
       "643127146      385\n",
       "2421664219     383\n",
       "1317549717     382\n",
       "299818632      382\n",
       "228791166      381\n",
       "480519937      380\n",
       "7291939241     379\n",
       "340711336      378\n",
       "582872531      377\n",
       "2906490331     375\n",
       "4978535758     375\n",
       "1303589730     373\n",
       "1814837251     373\n",
       "1411792405     373\n",
       "1291658614     373\n",
       "10192579486    372\n",
       "9059101974     372\n",
       "1418705634     371\n",
       "655934981      370\n",
       "4529154010     369\n",
       "31033532       368\n",
       "450551504      366\n",
       "3165744688     365\n",
       "6612357200     364\n",
       "7624638307     361\n",
       "581325206      358\n",
       "257267175      356\n",
       "3282508444     351\n",
       "39037837       349\n",
       "21452784       346\n",
       "1514849890     342\n",
       "213882856      340\n",
       "3050309989     330\n",
       "1125451713     329\n",
       "4473522466     327\n",
       "488134907      316\n",
       "32219305       314\n",
       "1920983937     312\n",
       "217402170      310\n",
       "4334476665     305\n",
       "Name: authorid, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_posts_authors_df[nyc_posts_authors_df.text.str.len() > 50].authorid.value_counts()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_authors = 50\n",
    "least_long = 50\n",
    "\n",
    "long_posts = nyc_posts_authors_df[nyc_posts_authors_df.text.str.len() > least_long]\n",
    "authors_posts_count = long_posts.authorid.value_counts()\n",
    "authors = authors_posts_count[:max_authors].index.tolist()\n",
    "min_posts = authors_posts_count.values[max_authors - 1]\n",
    "median_posts = int(authors_posts_count.median())\n",
    "\n",
    "train_posts = []\n",
    "test_posts = []\n",
    "\n",
    "for i in authors:\n",
    "    author_i_posts = nyc_posts_authors_df[(nyc_posts_authors_df.text.str.len() > least_long) & (nyc_posts_authors_df.authorid == i)]\n",
    "    l = len(author_i_posts)\n",
    "    train_posts.append(author_i_posts[:l - 20])\n",
    "    test_posts.append(author_i_posts[l - 20:])\n",
    "\n",
    "train_posts = pd.concat(train_posts).sample(frac=1.0, random_state=SEED)\n",
    "test_posts = pd.concat(test_posts).sample(frac=1.0, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_posts, others = train_test_split(nyc_posts_df[nyc_posts_df.text.str.len() > 100], train_size=TRAIN_DOC_COUNT, random_state=SEED)\n",
    "# test_posts = others[others.authorid.isin(train_posts.authorid.unique())].sample(n=TEST_DOC_COUNT, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17271"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortcode</th>\n",
       "      <th>caption</th>\n",
       "      <th>authorid</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7062952</th>\n",
       "      <td>B2zJvl_F3Ho</td>\n",
       "      <td>we are definitely sailing tonight at 5pm!! cal...</td>\n",
       "      <td>2040926754</td>\n",
       "      <td>we are definitely sailing tonight at 5pm!! cal...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8245150</th>\n",
       "      <td>Bse6L35FoPx</td>\n",
       "      <td>to dance , to eat, to drink , to flirt and at ...</td>\n",
       "      <td>581325206</td>\n",
       "      <td>to dance , to eat, to drink , to flirt and at ...</td>\n",
       "      <td>#brooklyn #ny #restaurant #brooklyn #wedding #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138598</th>\n",
       "      <td>BtQt1YJBuCF</td>\n",
       "      <td>another reminder about cold weather safety fro...</td>\n",
       "      <td>1125451713</td>\n",
       "      <td>another reminder about cold weather safety fro...</td>\n",
       "      <td>#winter #coldweather #bundleup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5252918</th>\n",
       "      <td>B4VsLN0D2a6</td>\n",
       "      <td>our cosmopolitan feels fridaylicious join us f...</td>\n",
       "      <td>4334476665</td>\n",
       "      <td>our cosmopolitan feels fridaylicious join us f...</td>\n",
       "      <td>#happyhour #seawalkrestaurant #inwood #uptown ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490783</th>\n",
       "      <td>B4i4-yrFYFc</td>\n",
       "      <td>every saturday @spyce_astoria. rsvp now for cr...</td>\n",
       "      <td>31033532</td>\n",
       "      <td>every saturday @spyce_astoria. rsvp now for cr...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           shortcode                                            caption  \\\n",
       "7062952  B2zJvl_F3Ho  we are definitely sailing tonight at 5pm!! cal...   \n",
       "8245150  Bse6L35FoPx  to dance , to eat, to drink , to flirt and at ...   \n",
       "3138598  BtQt1YJBuCF  another reminder about cold weather safety fro...   \n",
       "5252918  B4VsLN0D2a6  our cosmopolitan feels fridaylicious join us f...   \n",
       "6490783  B4i4-yrFYFc  every saturday @spyce_astoria. rsvp now for cr...   \n",
       "\n",
       "           authorid                                               text  \\\n",
       "7062952  2040926754  we are definitely sailing tonight at 5pm!! cal...   \n",
       "8245150   581325206  to dance , to eat, to drink , to flirt and at ...   \n",
       "3138598  1125451713  another reminder about cold weather safety fro...   \n",
       "5252918  4334476665  our cosmopolitan feels fridaylicious join us f...   \n",
       "6490783    31033532  every saturday @spyce_astoria. rsvp now for cr...   \n",
       "\n",
       "                                                  hashtags  \n",
       "7062952                                                     \n",
       "8245150  #brooklyn #ny #restaurant #brooklyn #wedding #...  \n",
       "3138598                     #winter #coldweather #bundleup  \n",
       "5252918  #happyhour #seawalkrestaurant #inwood #uptown ...  \n",
       "6490783                                                     "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortcode</th>\n",
       "      <th>caption</th>\n",
       "      <th>authorid</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9904347</th>\n",
       "      <td>Bx7ciYrHfIo</td>\n",
       "      <td>just a reminder that we are closed today and t...</td>\n",
       "      <td>9059101974</td>\n",
       "      <td>just a reminder that we are closed today and t...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8251367</th>\n",
       "      <td>BsgSx_GlNJJ</td>\n",
       "      <td>miss twin peaksis next saturday night at @joes...</td>\n",
       "      <td>257267175</td>\n",
       "      <td>miss twin peaksis next saturday night at @joes...</td>\n",
       "      <td>#twinpeaks #misstwinpeaks2019 #davidlynch #joe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047692</th>\n",
       "      <td>ByUWouqnbuw</td>\n",
       "      <td>attention  this thursday june 6th #privilegedt...</td>\n",
       "      <td>3282508444</td>\n",
       "      <td>attention  this thursday june 6th ‚Äº presents  ...</td>\n",
       "      <td>#privilegedthursday #theprinceofny #power105 #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420468</th>\n",
       "      <td>BusFIZGnY68</td>\n",
       "      <td>congratulations to this week's trivia winners-...</td>\n",
       "      <td>6612357200</td>\n",
       "      <td>congratulations to this week's trivia winners-...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7769533</th>\n",
       "      <td>BsIXTrGlAAN</td>\n",
       "      <td>since inception, amici by baci's mission has b...</td>\n",
       "      <td>4978535758</td>\n",
       "      <td>since inception, amici by baci's mission has b...</td>\n",
       "      <td>#aw19 #winter19 #boutiquefashion #agelessbeaut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           shortcode                                            caption  \\\n",
       "9904347  Bx7ciYrHfIo  just a reminder that we are closed today and t...   \n",
       "8251367  BsgSx_GlNJJ  miss twin peaksis next saturday night at @joes...   \n",
       "1047692  ByUWouqnbuw  attention  this thursday june 6th #privilegedt...   \n",
       "3420468  BusFIZGnY68  congratulations to this week's trivia winners-...   \n",
       "7769533  BsIXTrGlAAN  since inception, amici by baci's mission has b...   \n",
       "\n",
       "           authorid                                               text  \\\n",
       "9904347  9059101974  just a reminder that we are closed today and t...   \n",
       "8251367   257267175  miss twin peaksis next saturday night at @joes...   \n",
       "1047692  3282508444  attention  this thursday june 6th ‚Äº presents  ...   \n",
       "3420468  6612357200  congratulations to this week's trivia winners-...   \n",
       "7769533  4978535758  since inception, amici by baci's mission has b...   \n",
       "\n",
       "                                                  hashtags  \n",
       "9904347                                                     \n",
       "8251367  #twinpeaks #misstwinpeaks2019 #davidlynch #joe...  \n",
       "1047692  #privilegedthursday #theprinceofny #power105 #...  \n",
       "3420468                                                     \n",
       "7769533  #aw19 #winter19 #boutiquefashion #agelessbeaut...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_posts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2e79ce50ef4b2a8b578adec946e5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1a042e3a3b4823945d3377211a6301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/829 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9307b076e6064b2ba884ef67640ddbd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189a0465f6a64b71b6dfe6a54933c228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654959017bf94ff3a25fbb006859b765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f5f32c98b047729b6fa1aad0c6755b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/413M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poor Cyndy!  This superstar massage therapist had to endure an hour of Amy's special playlist with The Sky treatment to break a 4 day cuckoo migraine.  Wow, this treatment works!  But, Cyndy will never ever want to listen to Pearl Jam, DMB or REM again. #sorrynotsorry #nomoremigraine #cyndyisthebest\n",
      "\n",
      "[{'entity': 'B-PER', 'score': 0.99826306, 'index': 2, 'word': 'Cy', 'start': 5, 'end': 7}, {'entity': 'B-PER', 'score': 0.9971724, 'index': 16, 'word': 'Amy', 'start': 71, 'end': 74}, {'entity': 'I-ORG', 'score': 0.59139955, 'index': 24, 'word': 'Sky', 'start': 103, 'end': 106}, {'entity': 'B-PER', 'score': 0.9979698, 'index': 46, 'word': 'Cy', 'start': 185, 'end': 187}, {'entity': 'B-PER', 'score': 0.6932147, 'index': 55, 'word': 'Pearl', 'start': 225, 'end': 230}, {'entity': 'I-PER', 'score': 0.6572199, 'index': 56, 'word': 'Jam', 'start': 231, 'end': 234}, {'entity': 'B-MISC', 'score': 0.92161834, 'index': 58, 'word': 'D', 'start': 236, 'end': 237}]\n"
     ]
    }
   ],
   "source": [
    "example = nyc_posts_df['caption'][3]\n",
    "\n",
    "ner_results = nlp(example)\n",
    "print(example)\n",
    "print()\n",
    "print(ner_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text anonymization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SynTF method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SYNSETS = False\n",
    "TEXT_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_docs = nyc_posts_df.loc[nyc_posts_df['text'].str.len() > 100, 'text'][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'@\\w+', ' ', text.lower())\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    words = text.split()\n",
    "    words = filter(lambda x: x not in eng_stopwords, words)\n",
    "    return ' '.join(lemmatizer.lemmatize(x) for x in words)\n",
    "\n",
    "def get_synonyms(uniq_words):\n",
    "    all_synonyms = set()\n",
    "    for word in uniq_words:\n",
    "        synonyms = wordnet.synsets(word)\n",
    "        all_synonyms.update(chain.from_iterable([word.lemma_names() for word in synonyms]))\n",
    "    return all_synonyms\n",
    "\n",
    "docs = original_docs.apply(preprocess).tolist()\n",
    "if USE_SYNSETS:\n",
    "    uniq_words = set(chain.from_iterable([doc.split() for doc in docs]))\n",
    "    synonyms = ' '.join(get_synonyms(uniq_words))\n",
    "    docs_with_synonyms = [*docs, synonyms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "if USE_SYNSETS:\n",
    "    tfidf.fit(docs_with_synonyms)\n",
    "else:\n",
    "    tfidf.fit(docs)\n",
    "doc_vecs = tfidf.transform(docs)\n",
    "doc_vecs = normalize(doc_vecs, norm='l1')\n",
    "words = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7458"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = fasttext.load_facebook_model(datapath('/mnt/ess_storage/DN_1/storage/home/vpanov/cc.en.300.bin.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7458, 7458)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vecs = [ft.wv[word] for word in words]\n",
    "word_similarities = cosine_similarity(word_vecs, word_vecs)\n",
    "word_similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kgram_overlap(word1, word2, k):\n",
    "    a = set([word1[i:i+k] for i in range(0, len(word1) - k + 1)])\n",
    "    b = set([word2[i:i+k] for i in range(0, len(word2) - k + 1)])\n",
    "    inter = len(a.intersection(b))\n",
    "    return inter / (len(a) + len(b) - inter)\n",
    "\n",
    "def score(word1, word2):\n",
    "    idx1, idx2 = tfidf.vocabulary_[word1], tfidf.vocabulary_[word2]\n",
    "    return word_similarities[idx1, idx2] - 0.3 * kgram_overlap(word1, word2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://programming-dp.com/notebooks/ch9.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unforgettable ['unedited']\n"
     ]
    }
   ],
   "source": [
    "def exponential_gen(x, R, u, sensitivity=1, epsilon=25.4):\n",
    "    # Calculate the score for each element of R\n",
    "    scores = [u(x, r) for r in R]\n",
    "    \n",
    "    # Calculate the probability for each element, based on its score\n",
    "    probabilities = [np.exp(epsilon * score / (2 * sensitivity)) for score in scores]\n",
    "    \n",
    "    # Normalize the probabilties so they sum to 1\n",
    "    probabilities = probabilities / np.linalg.norm(probabilities, ord=1)\n",
    "\n",
    "    # Choose an element from R based on the probabilities\n",
    "    return np.random.choice(R, 1, p=probabilities)\n",
    "\n",
    "num = 7000\n",
    "print(words[num], exponential_gen(words[num], words, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3342ecb536a0454d9452dbfbf1e3cd3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=7458.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7458, 7458)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exponential(x, R, u, sensitivity=1, epsilon=25.4):\n",
    "    # Calculate the score for each element of R\n",
    "    scores = [u(x, r) for r in R]\n",
    "    \n",
    "    # Calculate the probability for each element, based on its score\n",
    "    probabilities = [np.exp(epsilon * score / (2 * sensitivity)) for score in scores]\n",
    "    \n",
    "    # Normalize the probabilties so they sum to 1\n",
    "    probabilities = probabilities / np.linalg.norm(probabilities, ord=1)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "word_replace_probs = []\n",
    "\n",
    "for word in tqdm(words):\n",
    "    word_replace_probs.append(exponential(word, words, score))\n",
    "\n",
    "word_replace_probs = np.array(word_replace_probs)\n",
    "word_replace_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--ORIGINAL--\n",
      "Right or Left?\n",
      "\n",
      "Buffalo Chicken slice on the right and Chicken, Bacon(beef), Ranch on the left from @saucny, all new halal pizza spot in New Hyde Park.\n",
      "--PREPROCESSED--\n",
      "right left buffalo chicken slice right chicken bacon beef ranch left new halal pizza spot new hyde park\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "freshwater bend fish horn lyndhurst cabbage placed rice priestley proof goat rippon bacon inside pork nearby spot though\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "Poor Cyndy!  This superstar massage therapist had to endure an hour of Amy's special playlist with The Sky treatment to break a 4 day cuckoo migraine.  Wow, this treatment works!  But, Cyndy will never ever want to listen to Pearl Jam, DMB or REM again.\n",
      "--PREPROCESSED--\n",
      "poor cyndy superstar massage therapist endure hour amy special playlist sky treatment break 4 day cuckoo migraine wow treatment work cyndy never ever want listen pearl jam dmb rem\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "spray elizabeth falling karen occasion atlanta visited soft revamped heidi superstar else crush tech scott blue elizabeth nice folklore kitt edwin programing tmn defiantly waking rosie drummer twelve product\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "he hit the booty like a drum, yumyum.üòÄ why he wanna stutter and he know he wanna butter my buns and have all of my sons. got them young and old like yang hyun suk and bang yong guk and my baby knows how to cook, red suit,  korean look.  startin all them trends in the mercedes benz playin that kpop, that jrock, i'm playin with that cüêàüêìk he likes a chick that plays wu tang that's how we bang, loves to talk slang knows how to freestyle knows how to get buckwild. he's a little bit of bruce lee doin karate, he a hottie he pulls out the shottie and we keep it sexual, also intellectual they askin what the dragon  do! üêâüî•üî•üî•                   üçéüçè          üòò‚õ≤üòúüí±üì≥üåÉüíöüí´\n",
      "--PREPROCESSED--\n",
      "hit booty like drum yumyum wanna stutter know wanna butter bun son got young old like yang hyun suk bang yong guk baby know cook red suit korean look startin trend mercedes benz playin kpop jrock playin c k like chick play wu tang bang love talk slang know freestyle know get buckwild little bit bruce lee doin karate hottie pull shottie keep sexual also intellectual askin dragon\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "jen strangely booty dj bruce pulling ndido guk intellectual infant whine garlic alright ssi hackensack slang let nicole heavy blvd heat samantha stutter look giant husband jummah ure bagel everywhere bjj echt enrichment second mater charming hell trans rts adversity push uch sobre new chunky true zou pointed verlo streammiter rhd conozcas sportin girl nenhum farm ah medical seriously tof little firsties sky naomi suk cheryl bit key\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "First cocktail of the day ‚Äî Three Hearts ‚Äî featuring Kansas distilled spirit. And our bartender just finished writing her first play.\n",
      "--PREPROCESSED--\n",
      "first cocktail day three heart featuring kansa distilled spirit bartender finished writing first play\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "twice fourth summer timing kansa finishing allowing second seven includes snack clase unfinished named\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "Just a week away we are welcoming all the youth from ages 14-18 !!! Let us start this year with God !\n",
      "--PREPROCESSED--\n",
      "week away welcoming youth age 14 18 let u start year god\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "34 23 welcoming god joyous hating pursuing adult month 30 true announcing\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for idx, doc in enumerate(docs[:5]):\n",
    "    print('--ORIGINAL--')\n",
    "    print(original_docs[original_docs.index[idx]])\n",
    "    print('--PREPROCESSED--')\n",
    "    print(doc)\n",
    "    print('--GENERATED SEQUENCE (WITHOUT WORD ORDER)--')\n",
    "    words_count = len(doc.split())\n",
    "    words_ = np.random.choice(words, words_count, p=doc_vecs[idx].todense().tolist()[0])\n",
    "    for i in range(words_count):\n",
    "        word_idx = tfidf.vocabulary_[words_[i]]\n",
    "        words_[i] = np.random.choice(words, 1, p=word_replace_probs[word_idx])[0]\n",
    "    print(' '.join(words_))\n",
    "    print('-'*150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ER-AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = 'distilbert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bert = AutoModel.from_pretrained(model_name, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 146, 11850, 24109, 15703, 119, 12689, 72894, 11268, 119, 102] [CLS] I like pigs. And apples. [SEP]\n",
      "[101, 177, 11850, 24109, 15703, 119, 10111, 72894, 11268, 119, 102] [CLS] i like pigs. and apples. [SEP]\n",
      "[101, 177, 11850, 24109, 15703, 119, 10111, 72894, 11268, 119, 102] [CLS] i like pigs. and apples. [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode('I like pigs. And apples.'), tokenizer.decode(tokenizer.encode('I like pigs. And apples.')))\n",
    "print(tokenizer.encode('i like pigs. and apples.'), tokenizer.decode(tokenizer.encode('i like pigs. and apples.')))\n",
    "print(tokenizer.encode('i like pigs . and apples .'), tokenizer.decode(tokenizer.encode('i like pigs . and apples .')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(doc):\n",
    "    doc = tokenizer.decode(tokenizer.encode(doc, max_length=128, padding='max_length', truncation=True))\n",
    "#     doc = tokenizer.decode(tokenizer.encode(doc))\n",
    "    doc = re.sub(r'([\\.,\\'‚Äô\\\"\\-!\\?\\(\\)])', r' \\1 ', doc)\n",
    "    doc = re.sub('\\s', ' ', doc)\n",
    "    return doc.split()\n",
    "\n",
    "unique_tokens = set(chain.from_iterable([*train_posts.text.apply(get_words).tolist(),\n",
    "                                       *test_posts.text.apply(get_words).tolist()]))\n",
    "\n",
    "token2idx = {token: idx for idx, token in enumerate(unique_tokens)}\n",
    "idx2token = {idx: token for idx, token in enumerate(unique_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_TOKEN_ID = token2idx['[CLS]']\n",
    "EOS_TOKEN_ID = token2idx['[SEP]']\n",
    "PAD_TOKEN_ID = token2idx['[PAD]']\n",
    "\n",
    "VOCAB_SIZE = len(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26641"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_idx(sent: str, word: str):\n",
    "    return sent.split(\" \").index(word)\n",
    "\n",
    "# def get_hidden_states(encoded, token_ids_words, model, layers):\n",
    "#     \"\"\"Push input IDs through model. Stack and sum `layers` (last four by default).\n",
    "#         Select only those subword token outputs that belong to our word of interest\n",
    "#         and average them.\"\"\"\n",
    "#     with torch.no_grad():\n",
    "#         output = model(**encoded)\n",
    " \n",
    "#     # Get all hidden states\n",
    "#     states = output.hidden_states\n",
    "#     # Stack and sum all requested layers\n",
    "#     output = torch.stack([states[i] for i in layers]).sum(0).squeeze()[1:-1, :]\n",
    "#     # Only select the tokens that constitute the requested word\n",
    "#     # word_tokens_output = output[token_ids_word]\n",
    "    \n",
    "#     labels = torch.LongTensor(token_ids_words)\n",
    "#     labels = labels.view(labels.size(0), 1).expand(-1, output.size(1))\n",
    "    \n",
    "#     unique_labels, labels_count = labels.unique(dim=0, return_counts=True)\n",
    "#     res = torch.zeros_like(unique_labels, dtype=torch.float)\n",
    "#     res = res.scatter_add_(0, labels, output)\n",
    "#     res = res / labels_count.float().unsqueeze(1)\n",
    "    \n",
    "#     res = torch.cat((output[:1], res, output[-1:]), dim=0)\n",
    " \n",
    "#     return res\n",
    "\n",
    "def get_hidden_states(encoded, token_ids_words, model, layers):\n",
    "    \"\"\"Push input IDs through model. Stack and sum `layers` (last four by default).\n",
    "        Select only those subword token outputs that belong to our word of interest\n",
    "        and average them.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded)\n",
    " \n",
    "    # Get all hidden states\n",
    "    states = output.hidden_states\n",
    "    # Stack and sum all requested layers\n",
    "    output = torch.stack([states[i] for i in layers]).sum(0).squeeze()\n",
    "#     output_token = output[1:-1, :]\n",
    "    \n",
    "    # Only select the tokens that constitute the requested word\n",
    "    # word_tokens_output = output[token_ids_word]\n",
    "    \n",
    "#     labels = torch.LongTensor(token_ids_words)\n",
    "#     labels = labels.view(labels.size(0), 1).expand(-1, output_token.size(1))\n",
    "    \n",
    "    \n",
    "#     unique_labels, labels_count = labels.unique(dim=0, return_counts=True)\n",
    "    res = []\n",
    "    labels_count = []\n",
    "    \n",
    "    for idx, (outp, label) in enumerate(zip(output, token_ids_words)):\n",
    "        if label is None or token_ids_words[idx - 1] is None or token_ids_words[idx - 1] != token_ids_words[idx]:\n",
    "            res.append(outp)\n",
    "            labels_count.append(1)\n",
    "        else: \n",
    "            res[-1] += outp\n",
    "            labels_count[-1] += 1\n",
    "#     res = res.scatter_add_(0, labels, output_token)\n",
    "    res = torch.vstack(res)\n",
    "    res = res / torch.tensor(labels_count).float().unsqueeze(1)\n",
    " \n",
    "    return res\n",
    "\n",
    "\n",
    "def get_word_vectors(sent, tokenizer, model, layers):\n",
    "    \"\"\"Get a word vector by first tokenizing the input sentence, getting all token idxs\n",
    "        that make up the word of interest, and then `get_hidden_states`.\"\"\"\n",
    "    encoded = tokenizer.encode_plus(sent, return_tensors=\"pt\", max_length=128, padding='max_length', truncation=True)\n",
    "    return get_hidden_states(encoded, encoded.word_ids(), model, layers)\n",
    "\n",
    "\n",
    "def exmpl(layers=None):\n",
    "    # Use last four layers by default\n",
    "    layers = [-4, -3, -2, -1] if layers is None else layers\n",
    "\n",
    "    sent = train_posts.text[train_posts.index[23]]\n",
    "\n",
    "    word_embedding = get_word_vectors(sent, tokenizer, bert, layers)\n",
    "\n",
    "    return word_embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exmpl().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "['[CLS]', 'outpour', 'is', 'here', 'all', 'the', 'vlogs', 'led', 'us', 'to', 'this', '!', 'you', 'don', \"'\", 't', 'want', 'to', 'miss', 'what', 'we', 'have', 'prepared', 'for', 'you', '.', 'come', 'expecting', '!', 'doors', 'open', 'at', '6', ':', '30pm', ',', 'come', 'early', 'and', 'get', 'our', 'new', 'merch', 'at', 'the', 'pop', 'up', 'shop', '!', 'special', 'guests', ':', '@', 'havilahcunnington', '@', 'annagoldenmusic', '@', 'waynefrancis', '@', 'degroves', 'wednesday', '/', '/', '7pm', 'thursday', '/', '/', '7pm', 'friday', '/', '/', '7pm', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (97) must match the existing size (98) at non-singleton dimension 0.  Target sizes: [97, 768].  Tensor sizes: [98, 1]\n",
      "688\n",
      "['[CLS]', 'help', 'barc', 'out', '!', '!', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', 'for', 'next', '15', 'days', 'only', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (114) must match the existing size (115) at non-singleton dimension 0.  Target sizes: [114, 768].  Tensor sizes: [115, 1]\n",
      "1054\n",
      "['[CLS]', 'come', 'check', 'out', 'my', 'day', 'time', 'bar', 'star', '@', 'andrellamaringa', 'as', 'she', 'create', 'her', 'signature', 'cocktails', '@', 'chefdomcreates', '@', 'larouge', '_', 'restaurant', '_', 'lounge', 'we', 'don', \"'\", 't', 'own', 'the', 'rights', 'to', 'this', 'song', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (116) must match the existing size (117) at non-singleton dimension 0.  Target sizes: [116, 768].  Tensor sizes: [117, 1]\n",
      "1294\n",
      "['[CLS]', '1', 'more', 'days', 'till', 'the', 'biggest', 'birthday', 'celebration', '@', 'empireloungenj', '@', 'chefdomcreates', '@', 'unclevinrock', '@', 'larouge', '_', 'restaurant', '_', 'lounge', '@', 'sa', '_', 'kye', '_', 'dom', '@', 'djsupadice', '@', 'mrdjovaflow', '@', 'judexmrgoodlife', 'chef', 'dom', \"'\", 's', 'birthday', 'celebration', '!', '!', '!', 'bottle', 'service', ',', 'hookah', ',', 'food', 'will', 'be', 'catered', 'by', 'no', 'other', 'but', 'me', 'lol', ',', 'vip', 'section', 'available', '.', '.', '.', '.', '.', '.', 'stay', 'tune', 'for', 'more', 'details', '\"', 'i', 'don', \"'\", 't', 'own', 'the', 'copyright', 'to', 'this', 'song', '\"', 'empire', 'lounge', 'vip', 'section', 'still', 'available', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (95) must match the existing size (96) at non-singleton dimension 0.  Target sizes: [95, 768].  Tensor sizes: [96, 1]\n",
      "1757\n",
      "['[CLS]', 'new', 'collection', 'alert', '.', '.', 'an', 'exclusive', 'sneak', 'peek', 'from', 'amici', 'by', 'baci', 'we', 'have', 'just', 'received', '!', 'this', 'is', 'one', 'collection', 'you', 'don', \"'\", 't', 'want', 'to', 'miss', '!', '.', '.', '.', 'you', 'can', 'contact', 'amici', 'through', 'baci', 'via', 'the', 'link', 'in', 'our', 'bio', 'for', 'more', 'information', 'about', 'the', 'line', '.', '.', 'hudson', 'mercantile', ',', 'february', '24', '-', '26', '2019', ',', 'studio', 'atelier', 'nyc', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (117) must match the existing size (118) at non-singleton dimension 0.  Target sizes: [117, 768].  Tensor sizes: [118, 1]\n",
      "2078\n",
      "['[CLS]', 'missing', 'dog', ':', 'lily', ',', 'still', 'with', 'leash', 'and', 'harness', ',', 'last', 'seen', 'on', 'prospect', 'park', 'west', 'and', '5th', 'street', '.', 'don', \"'\", 't', 'chase', 'if', 'seen', '!', '!', '!', 'call', 'lindsey', 'at', '917', '-', '515', '-', '4355', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (120) must match the existing size (121) at non-singleton dimension 0.  Target sizes: [120, 768].  Tensor sizes: [121, 1]\n",
      "2087\n",
      "['[CLS]', 'enough', 'with', 'the', 'hamburger', 'and', 'hotdogs', '.', '.', '.', '.', 'come', 'eat', 'some', 'real', 'food', 'and', 'drinks', 'at', 'larouge', 'lounge', 'and', 'restaurant', '972', 'broad', 'street', 'newark', 'nj', '@', 'chefdomcreates', '@', 'larouge', '_', 'restaurant', '_', 'lounge', 'kitchen', 'open', '6', '-', '12am', 'today', 'i', 'don', \"'\", 't', 'own', 'the', 'right', 'to', 'the', 'songs', 'playing', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (112) must match the existing size (113) at non-singleton dimension 0.  Target sizes: [112, 768].  Tensor sizes: [113, 1]\n",
      "2663\n",
      "['[CLS]', 'enough', 'with', 'the', 'hamburger', 'and', 'hotdogs', '.', '.', '.', '.', 'come', 'eat', 'some', 'real', 'food', 'and', 'drinks', 'at', 'larouge', 'lounge', 'and', 'restaurant', '972', 'broad', 'street', 'newark', 'nj', '@', 'chefdomcreates', '@', 'larouge', '_', 'restaurant', '_', 'lounge', 'kitchen', 'open', '6', '-', '12am', 'today', 'i', 'don', \"'\", 't', 'own', 'the', 'right', 'to', 'the', 'songs', 'playing', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (112) must match the existing size (113) at non-singleton dimension 0.  Target sizes: [112, 768].  Tensor sizes: [113, 1]\n",
      "2706\n",
      "['[CLS]', 'copper', 'has', 'had', 'a', 'very', 'exhausting', 'day', 'meeting', 'his', 'new', 'family', ',', 'friends', ',', 'home', ',', 'and', 'hang', 'out', 'spots', '!', 'please', 'don', \"'\", 't', 'wake', 'him', 'from', 'his', 'nap', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (124) must match the existing size (125) at non-singleton dimension 0.  Target sizes: [124, 768].  Tensor sizes: [125, 1]\n",
      "2944\n",
      "['[CLS]', 'caries', 'are', 'true', 'cavities', 'in', 'animals', '.', 'they', 'are', 'caused', 'by', 'consumption', 'of', 'carbohydrates', 'such', 'as', 'peas', ',', 'carrots', ',', 'green', 'beans', ',', 'and', 'sweet', 'potatoes', '.', 'unlike', 'people', ',', 'we', 'don', \"'\", 't', 'fill', 'cavities', ',', 'the', 'treatment', 'would', 'be', 'extraction', 'of', 'the', 'tooth', '.', 'brushing', 'can', 'help', 'remove', 'food', 'particles', 'stuck', 'in', 'teeth', 'that', 'may', 'contribute', 'to', 'cavities', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (108) must match the existing size (109) at non-singleton dimension 0.  Target sizes: [108, 768].  Tensor sizes: [109, 1]\n",
      "3130\n",
      "['[CLS]', 'show', 'your', 'support', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', 'for', 'next', '25', 'days', 'only', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (115) must match the existing size (116) at non-singleton dimension 0.  Target sizes: [115, 768].  Tensor sizes: [116, 1]\n",
      "3184\n",
      "['[CLS]', 'heatwave', 'in', 'effect', 'the', 'next', 'couple', 'days', '.', 'keep', 'your', 'pets', 'safe', '.', 'don', \"'\", 't', 'pour', 'water', 'on', 'them', 'outside', 'in', 'the', 'heat', ',', 'you', 'are', 'cooking', 'their', 'skin', '.', 'stay', 'indoors', '!', '!', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (125) must match the existing size (126) at non-singleton dimension 0.  Target sizes: [125, 768].  Tensor sizes: [126, 1]\n",
      "3506\n",
      "['[CLS]', 'help', 'barc', 'out', '!', '!', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', '9', 'days', 'only', 'left', 'on', 'this', 'fundraiser', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (112) must match the existing size (113) at non-singleton dimension 0.  Target sizes: [112, 768].  Tensor sizes: [113, 1]\n",
      "3545\n",
      "['[CLS]', 'spots', 'are', 'going', 'fast', 'for', 'our', 'next', 'on', 'march', '16', '!', '!', '!', 'be', 'sure', 'to', 'call', 'our', 'store', 'to', 'pre', '-', 'register', '.', 'we', 'will', 'be', 'donating', 'the', 'proceeds', 'we', 'get', 'from', 'the', 'venue', 'fee', 'to', 'the', '@', 'americancancersociety', ',', 'so', 'please', 'spread', 'the', 'word', '.', 'all', 'donations', 'are', 'welcome', '.', 'you', 'don', \"'\", 't', 'have', 'to', 'be', 'a', 'participate', 'to', 'donate', '.', 'we', 'are', 'also', 'accepting', 'sign', '-', 'ups', 'for', 'our', 'doubles', 'tournament', 'on', 'march', '23rd', '!', 'you', 'must', 'pre', '-', 'register', 'both', 'yourself', 'and', 'your', 'partner', 'when', 'you', 'call', '.', 'thank', 'you', '!', 'for', 'more', 'info', 'on', 'our', 'policies', 'and', 'rulesets', ',', 'please', 'visit', 'sidescroller', '[SEP]']\n",
      "The expanded size of the tensor (109) must match the existing size (110) at non-singleton dimension 0.  Target sizes: [109, 768].  Tensor sizes: [110, 1]\n",
      "3626\n",
      "['[CLS]', '\"', 'microchips', 'greatly', 'increase', 'the', 'chances', 'that', 'pets', 'will', 'be', 'reuinted', 'with', 'their', 'families', 'if', 'they', 'are', 'lost', 'or', 'stolen', ',', 'but', 'a', 'microchip', 'only', 'works', 'if', 'its', 'registration', 'information', 'is', 'accurate', '.', '\"', 'when', 'we', 'place', 'a', 'microchip', '@', 'abingdonsquarevet', 'we', 'register', 'the', 'chip', 'for', 'you', 'but', 'you', 'need', 'to', 'keep', 'the', 'info', 'up', 'to', 'date', '!', 'if', 'your', 'pet', 'already', 'has', 'a', 'chip', ',', 'we', 'can', 'scan', 'it', 'and', 'provide', 'you', 'the', 'number', '.', '<', 'url', '>', 'can', 'be', 'helpful', 'if', 'you', 'know', 'the', 'microchip', 'number', 'but', 'don', \"'\", 't', 'know', 'what', 'company', 'to', 'register', 'your', 'pet', \"'\", 's', 'microchip', '!', '[SEP]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (107) must match the existing size (108) at non-singleton dimension 0.  Target sizes: [107, 768].  Tensor sizes: [108, 1]\n",
      "3640\n",
      "['[CLS]', '5', 'days', 'remaining', '!', '!', 'help', 'barc', 'out', ',', 'only', '6', 'days', 'left', '!', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', '5', 'days', 'only', 'left', 'on', 'this', 'fundraiser', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]']\n",
      "The expanded size of the tensor (112) must match the existing size (113) at non-singleton dimension 0.  Target sizes: [112, 768].  Tensor sizes: [113, 1]\n",
      "3642\n",
      "['[CLS]', 'all', 'of', 'our', 'services', 'are', 'by', 'appointment', 'only', '.', 'we', 'don', \"'\", 't', 'take', 'any', 'walk', '-', 'ins', '.', 'we', 'want', 'to', 'ensure', 'that', 'no', 'one', 'is', 'waiting', 'and', 'that', 'everyone', 'may', 'have', 'a', 'wonderful', 'experience', 'with', 'us', 'at', 'gorgeous', 'spa', '.', 'send', 'us', 'a', 'direct', 'message', 'or', 'call', 'us', 'at', '(', '347', ')', '460', '-', '6006', '.', 'we', 'look', 'forward', 'to', 'hearing', 'from', 'you', 'gorgeous', '!', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (120) must match the existing size (121) at non-singleton dimension 0.  Target sizes: [120, 768].  Tensor sizes: [121, 1]\n",
      "3762\n",
      "['[CLS]', 'we', 'don', \"'\", 't', 'cross', 'our', 'arms', 'to', 'rest', ',', 'only', 'just', 'to', 'show', 'our', 'wonders', 'of', 'design', 'fingerless', 'gloves', 'de', 'main', '145', 'front', 'st', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (124) must match the existing size (125) at non-singleton dimension 0.  Target sizes: [124, 768].  Tensor sizes: [125, 1]\n",
      "4122\n",
      "['[CLS]', 'join', 'us', 'friday', ',', 'june', '21st', 'at', '8', ':', '15pm', 'for', 'our', 'kickoff', 'to', 'summer', 'black', 'light', 'class', '!', 'this', '90', 'minute', 'class', 'with', 'feature', '2', 'surprise', 'trainers', '!', 'if', 'you', 'would', 'like', 'an', 'official', 'cko', 'black', 'light', 'shirt', ',', 'preorder', 'yours', 'at', 'the', 'front', 'desk', 'for', '$', '15', 'by', 'sunday', ',', 'june', '9th', '!', '!', 'wear', 'neon', 'or', 'white', 'shirts', 'if', 'you', 'don', \"'\", 't', 'purchase', 'a', 'cko', 'shirt', '.', 'reserve', 'your', 'bag', 'at', 'the', 'front', 'desk', 'or', 'dm', 'to', 'reserve', 'your', 'spot', '!', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (112) must match the existing size (113) at non-singleton dimension 0.  Target sizes: [112, 768].  Tensor sizes: [113, 1]\n",
      "4181\n",
      "['[CLS]', 'robell', 'is', 'everyday', '-', 'luxury', 'for', 'women', 'who', 'don', \"'\", 't', 'want', 'to', 'compromise', 'when', 'it', 'comes', 'to', 'look', 'or', 'comfort', '.', '.', 'if', 'you', 'buy', 'a', 'pair', 'of', 'robell', 'trousers', ',', 'you', 'are', 'guaranteed', 'a', 'high', 'quality', '-', 'at', 'reasonable', 'prices', '.', '.', 'robell', 'knows', 'that', 'each', 'woman', 'is', 'different', '.', 'therefore', ',', 'you', 'will', 'find', 'the', 'trousers', 'and', 'jeans', 'in', 'different', 'styles', 'in', 'a', 'number', 'of', 'colours', 'and', 'fashionable', 'prints', '-', 'whether', 'you', 'prefer', 'a', 'classical', 'or', 'a', 'more', 'stylish', 'look', '.', '.', '.', 'you', 'can', 'contact', 'robell', 'through', 'godske', 'group', 'via', '.', '.', 'hudson', 'mercantile', ',', 'february', '24', '-', '26', '[SEP]']\n",
      "The expanded size of the tensor (104) must match the existing size (105) at non-singleton dimension 0.  Target sizes: [104, 768].  Tensor sizes: [105, 1]\n",
      "4354\n",
      "['[CLS]', '1', 'more', 'days', 'till', 'the', 'biggest', 'birthday', 'celebration', '@', 'empireloungenj', '@', 'chefdomcreates', '@', 'unclevinrock', '@', 'larouge', '_', 'restaurant', '_', 'lounge', '@', 'sa', '_', 'kye', '_', 'dom', '@', 'djsupadice', '@', 'mrdjovaflow', '@', 'judexmrgoodlife', 'chef', 'dom', \"'\", 's', 'birthday', 'celebration', '!', '!', '!', 'bottle', 'service', ',', 'hookah', ',', 'food', 'will', 'be', 'catered', 'by', 'no', 'other', 'but', 'me', 'lol', ',', 'vip', 'section', 'available', '.', '.', '.', '.', '.', '.', 'stay', 'tune', 'for', 'more', 'details', '\"', 'i', 'don', \"'\", 't', 'own', 'the', 'copyright', 'to', 'this', 'song', '\"', 'empire', 'lounge', 'vip', 'section', 'still', 'available', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (95) must match the existing size (96) at non-singleton dimension 0.  Target sizes: [95, 768].  Tensor sizes: [96, 1]\n",
      "4423\n",
      "['[CLS]', 'did', 'you', 'make', 'our', 'last', 'black', 'light', 'class', '?', 'if', 'not', '.', '.', '.', 'join', 'us', 'friday', ',', 'june', '21st', 'at', '8', ':', '15pm', 'for', 'our', 'kickoff', 'to', 'summer', 'black', 'light', 'class', '!', 'if', 'you', 'would', 'like', 'an', 'official', 'cko', 'black', 'light', 'shirt', ',', 'preorder', 'yours', 'at', 'the', 'front', 'desk', 'for', '$', '15', 'by', 'sunday', ',', 'june', '9th', '!', '!', '!', 'wear', 'neon', 'or', 'white', 'shirts', 'if', 'you', 'don', \"'\", 't', 'purchase', 'a', 'cko', 'shirt', '.', 'reserve', 'your', 'spot', 'at', 'the', 'front', 'desk', 'or', 'by', 'dm', '!', 'don', \"'\", 't', 'forget', 'after', 'party', 'at', 'cj', \"'\", 's', 'at', '10pm', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (110) must match the existing size (111) at non-singleton dimension 0.  Target sizes: [110, 768].  Tensor sizes: [111, 1]\n",
      "4590\n",
      "['[CLS]', 'lost', 'dog', 'named', 'murphy', ',', 'slipped', 'out', 'of', 'her', 'harness', 'around', 'gates', 'and', 'marcy', 'avenue', ',', 'brooklyn', '.', 'don', \"'\", 't', 'chase', '!', 'offer', 'treats', '!', 'any', 'sightings', 'or', 'information', ',', 'call', '301', '-', '956', '-', '6937', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (116) must match the existing size (117) at non-singleton dimension 0.  Target sizes: [116, 768].  Tensor sizes: [117, 1]\n",
      "4661\n",
      "['[CLS]', '\"', 'don', \"'\", 'thing', 'from', 'selfish', 'ambition', 'or', 'conceit', ',', 'but', 'in', 'humility', 'count', 'others', 'more', 'significant', 'than', 'yourselves', '.', '\"', '-', 'philippians', '2', ':', '3', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (117) must match the existing size (118) at non-singleton dimension 0.  Target sizes: [117, 768].  Tensor sizes: [118, 1]\n",
      "5221\n",
      "['[CLS]', 'friends', ',', 'please', 'don', \"'\", 't', 'forget', 'to', 'reserve', 'your', 'table', 'for', 'fathers', 'day', 'for', 'this', 'sunday', '!', 'we', 'still', 'have', 'some', 'tables', 'available', ',', 'but', 'please', 'rush', '!', 'happy', 'fathers', 'day', 'guys', '!', '347', '-', '673', '-', '5411', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (117) must match the existing size (118) at non-singleton dimension 0.  Target sizes: [117, 768].  Tensor sizes: [118, 1]\n",
      "6001\n",
      "['[CLS]', 'barc', 'shelter', 'just', 'updated', 'our', 'wishlist', 'on', 'amazon', ',', 'and', 'we', 'are', 'out', 'of', 'stock', 'on', 'these', 'items', '.', 'if', 'you', 'would', 'like', 'to', 'donate', ',', 'go', 'to', '@', 'barcshelter', 'and', 'on', 'our', 'profile', 'you', 'will', 'see', 'our', 'amazon', 'wishlist', '.', 'if', 'you', 'don', \"'\", 't', 'want', 'to', 'purchase', 'through', 'amazon', ',', 'you', 'can', 'also', 'get', 'it', 'through', 'costco', '/', 'target', 'or', 'buy', 'it', 'locally', 'and', 'drop', 'it', 'off', '.', 'every', 'little', 'thing', 'helps', '.', 'thank', 'you', 'for', 'your', 'kind', 'heart', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (116) must match the existing size (117) at non-singleton dimension 0.  Target sizes: [116, 768].  Tensor sizes: [117, 1]\n",
      "6910\n",
      "['[CLS]', 'every', 'week', 'we', 'get', 'submissions', 'from', 'people', 'from', 'around', 'the', 'world', 'for', 'a', 'segment', 'of', 'our', 'open', 'mic', 'called', '\"', 'read', 'my', 'lines', '.', '\"', 'this', 'allows', 'artists', 'to', 'submit', 'their', 'work', 'whenever', 'they', 'cannot', 'attend', 'our', 'events', 'or', 'if', 'they', 'don', \"'\", 't', 'live', 'in', 'our', 'country', 'or', 'state', 'or', 'if', 'they', 'have', 'stage', 'fright', 'but', 'still', 'want', 'their', 'voice', 'heard', ',', 'and', 'a', 'volunteer', 'will', 'be', 'recorded', 'reading', 'their', 'work', '.', '.', 'we', 'would', 'like', 'to', 'give', 'a', 'big', 'shoutout', 'to', '@', 'shay', '_', 'marie', '_', 'g', 'for', 'an', 'awesome', 'job', 'reading', '@', 'kingcesar1583', 'erotic', 'short', 'story', '.', 'special', 'thank', 'you', 'to', '@', 'kingcesar1583', '[SEP]']\n",
      "The expanded size of the tensor (107) must match the existing size (108) at non-singleton dimension 0.  Target sizes: [107, 768].  Tensor sizes: [108, 1]\n",
      "7412\n",
      "['[CLS]', 'did', 'you', 'make', 'our', 'last', 'black', 'light', 'class', '?', 'if', 'not', '.', '.', '.', 'join', 'us', 'friday', ',', 'june', '21st', 'at', '8', ':', '15pm', 'for', 'our', 'kickoff', 'to', 'summer', 'black', 'light', 'class', '!', 'if', 'you', 'would', 'like', 'an', 'official', 'cko', 'black', 'light', 'shirt', ',', 'preorder', 'yours', 'at', 'the', 'front', 'desk', 'for', '$', '15', 'by', 'sunday', ',', 'june', '9th', '!', '!', '!', 'wear', 'neon', 'or', 'white', 'shirts', 'if', 'you', 'don', \"'\", 't', 'purchase', 'a', 'cko', 'shirt', '.', 'reserve', 'your', 'spot', 'at', 'the', 'front', 'desk', 'or', 'by', 'dm', '!', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (113) must match the existing size (114) at non-singleton dimension 0.  Target sizes: [113, 768].  Tensor sizes: [114, 1]\n",
      "7800\n",
      "['[CLS]', '~', 'where', 'can', 'you', 'relax', 'and', 'fully', 'be', 'yourself', '~', '.', '~', 'where', 'can', 'you', 'go', 'and', 'feel', 'loved', 'and', 'safe', '?', '~', '.', '~', 'where', 'is', 'the', 'place', 'you', 'can', 'go', 'and', 'heal', 'from', 'the', 'areas', 'in', 'which', 'you', 'don', \"'\", 't', 'feel', 'supported', '?', '~', '.', 'it', 'can', 'be', 'hard', 'to', 'find', 'a', 'place', 'like', 'that', 'and', 'when', 'you', 'do', '.', '.', '.', 'hold', 'onto', 'it', '.', '.', 'join', 'us', 'tonight', 'for', 'a', 'healing', 'soundbath', 'with', 'shunny', '@', 'sounddreamsnyc', '.', 'last', 'sound', 'bath', 'of', 'the', 'decade', 'learning', 'how', 'to', 'manifest', 'our', 'realities', 'and', 'find', 'happiness', 'within', 'ourselves', 'amongst', 'a', 'wild', 'continuously', 'moving', 'and', 'chaotic', 'world', '[SEP]']\n",
      "The expanded size of the tensor (108) must match the existing size (109) at non-singleton dimension 0.  Target sizes: [108, 768].  Tensor sizes: [109, 1]\n",
      "8582\n",
      "['[CLS]', 'barc', 'shelter', 'is', 'almost', 'out', 'of', 'these', 'cleaning', 'items', '.', 'if', 'you', 'would', 'like', 'to', 'donate', ',', 'go', 'to', '@', 'barcshelter', 'and', 'on', 'our', 'profile', 'you', 'will', 'see', 'our', 'amazon', 'wishlist', '.', 'if', 'you', 'don', \"'\", 't', 'want', 'to', 'purchase', 'through', 'amazon', ',', 'you', 'can', 'also', 'get', 'it', 'through', 'costco', ',', 'or', 'buy', 'it', 'locally', 'and', 'drop', 'it', 'off', '.', 'every', 'little', 'thing', 'helps', '.', 'thank', 'you', 'for', 'your', 'kind', 'heart', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (117) must match the existing size (118) at non-singleton dimension 0.  Target sizes: [117, 768].  Tensor sizes: [118, 1]\n",
      "8758\n",
      "['[CLS]', 'how', 'did', 'we', 'not', 'respect', 'this', '.', '.', '.', 'we', 'complain', 'about', 'but', 'we', 'don', \"'\", 't', 'keep', 'shit', 'up', '?', '?', '!', '!', 'let', \"'\", 's', 'talk', 'about', 'it', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (126) must match the existing size (127) at non-singleton dimension 0.  Target sizes: [126, 768].  Tensor sizes: [127, 1]\n",
      "8800\n",
      "['[CLS]', 'snow', 'is', 'in', 'the', 'forecast', ',', 'but', 'please', 'don', \"'\", 't', 'confuse', 'cute', 'zorro', 'with', 'a', 'snowflake', '.', '@', 'zorro', '_', 'maltese', '_', 'puppy', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (115) must match the existing size (116) at non-singleton dimension 0.  Target sizes: [115, 768].  Tensor sizes: [116, 1]\n",
      "8932\n",
      "['[CLS]', 'help', 'barc', 'out', '!', '!', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', 'for', 'next', '16', 'days', 'only', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (114) must match the existing size (115) at non-singleton dimension 0.  Target sizes: [114, 768].  Tensor sizes: [115, 1]\n",
      "9199\n",
      "['[CLS]', 'tomorrow', 'is', 'saturday', 'at', '!', 'our', 'event', 'will', 'begin', 'at', '5pm', '.', 'register', 'over', 'at', 'smash', '.', 'gg', '(', 'link', 'in', 'bio', ')', '.', 'walk', '-', 'ins', 'are', 'welcome', '.', 'if', 'you', 'don', \"'\", 't', 'have', 'a', 'smash', '.', 'gg', 'account', ',', 'you', 'can', 'make', 'one', 'for', 'free', 'at', 'time', 'of', 'sign', '-', 'up', '.', 'you', 'can', 'find', 'our', 'rules', 'on', 'our', 'smash', '.', 'gg', 'page', 'as', 'well', 'as', 'our', 'website', 'sidescrollersnj', '.', 'com', '/', 'tournaments', 'please', 'note', ':', 'our', 'shop', 'will', 'have', 'a', 'delayed', 'opening', 'at', '2pm', '.', 'the', 'will', 'be', 'closed', 'off', 'to', 'non', '-', 'participants', 'during', 'the', 'tournament', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (109) must match the existing size (110) at non-singleton dimension 0.  Target sizes: [109, 768].  Tensor sizes: [110, 1]\n",
      "9313\n",
      "['[CLS]', 'the', 'best', 'part', 'by', 'living', 'by', 'this', 'view', '&', 'comin', 'home', 'straight', 'after', 'work', 'is', 'that', 'its', 'peaceful', ',', 'a', 'blessing', '&', 'a', 'spot', 'to', 'clear', 'ur', 'mind', '&', 'think', 'about', 'alot', 'of', 'things', 'and', 'relex', 'when', 'u', 'alone', 'but', 'the', 'hardest', 'part', 'about', 'it', 'is', 'when', 'u', 'take', 'the', 'time', 'to', 'think', 'about', 'someone', 'you', 'really', 'miss', '&', 'love', 'but', 'cant', 'don', \"'\", 'thing', 'about', 'it', 'to', 'show', 'them', 'or', 'prove', 'to', 'them', 'what', 'you', 'mean', 'to', 'then', '&', 'l', '@', 'djeasynyc', '@', 'djeasycalderon', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (113) must match the existing size (114) at non-singleton dimension 0.  Target sizes: [113, 768].  Tensor sizes: [114, 1]\n",
      "10910\n",
      "['[CLS]', 'it', \"'\", 's', 'too', 'this', 'week', ',', 'protect', 'your', 'pets', '!', 'also', 'don', \"'\", 't', 'pour', 'water', 'on', 'your', 'pets', 'outside', 'in', 'this', 'heat', ',', 'you', 'will', 'be', 'cooking', 'them', ',', 'walk', 'in', 'the', 'shade', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (125) must match the existing size (126) at non-singleton dimension 0.  Target sizes: [125, 768].  Tensor sizes: [126, 1]\n",
      "10925\n",
      "['[CLS]', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (115) must match the existing size (116) at non-singleton dimension 0.  Target sizes: [115, 768].  Tensor sizes: [116, 1]\n",
      "11052\n",
      "['[CLS]', 'when', 'you', \"'\", 're', 'trapped', 'in', 'the', 'black', 'lodge', ',', 'how', 'long', 'does', 'it', 'take', 'for', 'you', 'to', 'realized', 'you', \"'\", 're', 'stuck', 'in', 'there', '?', '25', 'years', '?', 'it', \"'\", 's', 'hard', 'to', 'say', 'how', 'or', 'why', ',', 'but', 'my', 'burlesque', 'accounts', 'don', \"'\", 't', 'get', 'seen', 'much', 'these', 'days', '.', 'please', 'give', 'us', 'a', 'like', 'and', 'maybe', 'a', 'comment', '?', 'pretty', 'please', '?', 'help', 'me', 'get', 'released', '!', '@', 'thepinkroomburlesque', 'call', 'for', 'help', '!', 'we', \"'\", 're', 'trapped', 'in', 'the', 'black', 'lodge', 'and', 'we', 'cant', 'get', 'out', '!', '@', 'thepinkroomburlesque', 'appears', 'to', 'be', 'under', 'the', 'effects', 'of', 'shadowban', '[SEP]']\n",
      "The expanded size of the tensor (101) must match the existing size (102) at non-singleton dimension 0.  Target sizes: [101, 768].  Tensor sizes: [102, 1]\n",
      "11168\n",
      "['[CLS]', 'barc', 'shelter', 'is', 'almost', 'out', 'of', 'these', 'items', '.', 'if', 'you', 'would', 'like', 'to', 'donate', ',', 'go', 'to', '@', 'barcshelter', 'and', 'on', 'our', 'profile', 'you', 'will', 'see', 'our', 'amazon', 'wishlist', '.', 'if', 'you', 'don', \"'\", 't', 'want', 'to', 'purchase', 'through', 'amazon', ',', 'you', 'can', 'also', 'get', 'it', 'through', 'costco', ',', 'or', 'buy', 'it', 'locally', 'and', 'drop', 'it', 'off', '.', 'every', 'little', 'thing', 'helps', '.', 'thank', 'you', 'for', 'your', 'kind', 'heart', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (118) must match the existing size (119) at non-singleton dimension 0.  Target sizes: [118, 768].  Tensor sizes: [119, 1]\n",
      "11291\n",
      "['[CLS]', 'friends', ',', 'please', 'don', \"'\", 't', 'forget', 'to', 'reserve', 'your', 'table', 'for', 'fathers', 'day', 'for', 'this', 'sunday', '!', 'we', 'still', 'have', 'some', 'tables', 'available', ',', 'but', 'please', 'rush', '!', 'happy', 'fathers', 'day', 'guys', '!', '347', '-', '673', '-', '5411', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (117) must match the existing size (118) at non-singleton dimension 0.  Target sizes: [117, 768].  Tensor sizes: [118, 1]\n",
      "11456\n",
      "['[CLS]', 'help', 'barc', 'out', '!', '!', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', 'for', 'next', '20', 'days', 'only', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (114) must match the existing size (115) at non-singleton dimension 0.  Target sizes: [114, 768].  Tensor sizes: [115, 1]\n",
      "13096\n",
      "['[CLS]', 'help', 'barc', 'out', ',', 'only', '6', 'days', 'left', '!', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', '6', 'days', 'only', 'left', 'on', 'this', 'fundraiser', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (112) must match the existing size (113) at non-singleton dimension 0.  Target sizes: [112, 768].  Tensor sizes: [113, 1]\n",
      "13811\n",
      "['[CLS]', 'barc', 'shelter', 'is', 'running', 'out', 'of', 'litter', 'in', 'our', 'cat', 'loft', '.', 'if', 'you', 'would', 'like', 'to', 'donate', ',', 'go', 'to', '@', 'barcshelter', 'and', 'on', 'our', 'profile', 'you', 'will', 'see', 'our', 'amazon', 'wishlist', '.', 'if', 'you', 'don', \"'\", 't', 'want', 'to', 'purchase', 'through', 'amazon', ',', 'you', 'can', 'also', 'get', 'it', 'through', 'costco', ',', 'or', 'buy', 'it', 'locally', 'and', 'drop', 'it', 'off', '.', 'every', 'little', 'thing', 'helps', '.', 'thank', 'you', 'for', 'your', 'kind', 'heart', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (116) must match the existing size (117) at non-singleton dimension 0.  Target sizes: [116, 768].  Tensor sizes: [117, 1]\n",
      "14493\n",
      "['[CLS]', 'all', 'of', 'our', 'services', 'are', 'by', 'appointment', 'only', '.', 'we', 'don', \"'\", 't', 'take', 'any', 'walk', '-', 'ins', '.', 'we', 'want', 'to', 'ensure', 'that', 'no', 'one', 'is', 'waiting', 'and', 'that', 'everyone', 'may', 'have', 'a', 'wonderful', 'experience', 'with', 'us', 'at', 'gorgeous', 'spa', '.', 'send', 'us', 'a', 'direct', 'message', 'or', 'call', 'us', 'at', '(', '347', ')', '460', '-', '6006', '.', 'we', 'look', 'forward', 'to', 'hearing', 'from', 'you', 'gorgeous', '!', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (120) must match the existing size (121) at non-singleton dimension 0.  Target sizes: [120, 768].  Tensor sizes: [121, 1]\n",
      "14945\n",
      "['[CLS]', 'friends', ',', 'please', 'don', \"'\", 't', 'forget', 'to', 'reserve', 'your', 'table', 'for', 'fathers', 'day', 'this', 'sunday', '!', 'we', 'still', 'have', 'some', 'tables', 'available', ',', 'but', 'the', 'holiday', 'is', 'literally', 'tomorrow', '!', 'and', 'happy', 'fathers', 'day', '718', '-', '513', '-', '6004', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (119) must match the existing size (120) at non-singleton dimension 0.  Target sizes: [119, 768].  Tensor sizes: [120, 1]\n",
      "15596\n",
      "['[CLS]', 'barc', 'shelter', 'is', 'almost', 'out', 'of', 'these', 'items', '.', 'if', 'you', 'would', 'like', 'to', 'donate', ',', 'go', 'to', '@', 'barcshelter', 'and', 'on', 'our', 'profile', 'you', 'will', 'see', 'our', 'amazon', 'wishlist', '.', 'if', 'you', 'don', \"'\", 't', 'want', 'to', 'purchase', 'through', 'amazon', ',', 'you', 'can', 'also', 'get', 'it', 'through', 'costco', ',', 'or', 'buy', 'it', 'locally', 'and', 'drop', 'it', 'off', '.', 'every', 'little', 'thing', 'helps', '.', 'thank', 'you', 'for', 'your', 'kind', 'heart', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (118) must match the existing size (119) at non-singleton dimension 0.  Target sizes: [118, 768].  Tensor sizes: [119, 1]\n",
      "15778\n",
      "['[CLS]', 'friends', ',', 'please', 'don', \"'\", 't', 'forget', 'to', 'reserve', 'your', 'table', 'for', 'fathers', 'day', 'for', 'this', 'sunday', '!', 'we', 'still', 'have', 'some', 'tables', 'available', ',', 'but', 'please', 'rush', '!', 'happy', 'fathers', 'day', 'guys', '!', '347', '-', '673', '-', '5411', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (117) must match the existing size (118) at non-singleton dimension 0.  Target sizes: [117, 768].  Tensor sizes: [118, 1]\n",
      "16167\n",
      "['[CLS]', 'friends', ',', 'please', 'don', \"'\", 't', 'forget', 'to', 'reserve', 'your', 'table', 'for', 'fathers', 'day', 'this', 'sunday', '!', 'we', 'still', 'have', 'some', 'tables', 'available', ',', 'but', 'the', 'holiday', 'is', 'literally', 'tomorrow', '!', 'and', 'happy', 'fathers', 'day', '718', '-', '513', '-', '6004', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (119) must match the existing size (120) at non-singleton dimension 0.  Target sizes: [119, 768].  Tensor sizes: [120, 1]\n",
      "16201\n",
      "['[CLS]', 'is', 'it', 'still', 'moonday', '?', 'how', 'luck', 'am', 'i', 'that', 'i', 'get', 'to', 'don', \"'\", 't', 'one', 'butt', 'two', 'shows', 'with', '@', 'mspussnboots', 'this', 'week', '?', 'catch', 'me', 'on', 'tuesday', 'at', '@', 'naughtynoirshow', \"'\", 's', '5th', 'anniversary', 'at', '@', 'thedelancey', 'thursday', 'at', '@', 'stachenovak', \"'\", 's', 'midnight', 'fingers', 'at', '@', 'slipperroomnyc', 'for', 'a', 'lynchian', 'night', 'that', \"'\", 's', 'gonna', 'have', 'you', 'up', 'in', 'flames', 'then', 'stay', 'turned', 'for', '@', 'thepinkroomburlesque', 'to', 'release', 'tickets', 'real', 'soon', 'for', 'our', 'oct', '19th', 'costume', 'party', 'at', '@', 'bedlamnyc', '!', '[SEP]']\n",
      "The expanded size of the tensor (86) must match the existing size (87) at non-singleton dimension 0.  Target sizes: [86, 768].  Tensor sizes: [87, 1]\n",
      "16724\n",
      "['[CLS]', 'don', \"'\", 't', 'let', 'the', 'cold', 'stop', 'you', 'from', 'what', 'you', 'love', '!', '.', 'class', 'with', '@', 'daya', '_', 'mama', 'tomorrow', 'at', '8am', '.', 'if', 'you', 'miss', ',', 'it', \"'\", 's', 'ok', '!', 'we', 'have', 'classes', 'all', 'day', '!', 'come', 'by', 'for', 'some', 'yoga', 'and', 'tea', 'and', 'smiles', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (123) must match the existing size (124) at non-singleton dimension 0.  Target sizes: [123, 768].  Tensor sizes: [124, 1]\n"
     ]
    }
   ],
   "source": [
    "def get_word_vectors(sent, tokenizer, model, layers):\n",
    "    \"\"\"Get a word vector by first tokenizing the input sentence, getting all token idxs\n",
    "        that make up the word of interest, and then `get_hidden_states`.\"\"\"\n",
    "    \n",
    "    encoded = tokenizer.encode_plus(sent, return_tensors=\"pt\", max_length=128, padding='max_length', truncation=True)\n",
    "#     encoded = tokenizer.encode_plus(sent, return_tensors=\"pt\")\n",
    "    \n",
    "    input_ids = list(map(lambda x: token2idx[x], get_words(sent)))\n",
    "    input_ids = torch.tensor(input_ids).unsqueeze(0)\n",
    "    return get_hidden_states(encoded, encoded.word_ids(), model, layers).cpu(), input_ids\n",
    "\n",
    "def get_embedding(doc, model=bert):\n",
    "    \"Get embedding for each word\"\n",
    "    layers = [-4, -3, -2, -1]\n",
    "    return get_word_vectors(doc, tokenizer, model, layers)\n",
    "\n",
    "# def get_embedding(doc, model=bert):\n",
    "#     \"Get embedding for each token\"\n",
    "#     layers = [-4, -3, -2, -1]\n",
    "# #     embedding = get_word_vectors(doc, tokenizer, model, layers)\n",
    "#     encoded = tokenizer.encode_plus(doc, return_tensors=\"pt\", max_length=128, padding='max_length', truncation=True)\n",
    "#     with torch.no_grad():\n",
    "#         output = model(**encoded)\n",
    " \n",
    "#     # Get all hidden states\n",
    "#     states = output.hidden_states\n",
    "#     # Stack and sum all requested layers\n",
    "#     output = torch.stack([states[i] for i in layers]).sum(0).squeeze()\n",
    "#     return output.cpu(), encoded.input_ids.cpu()\n",
    "\n",
    "embeddings = []\n",
    "input_ids = []\n",
    "\n",
    "token_embeddings = torch.zeros((VOCAB_SIZE, 768))\n",
    "token_count = torch.zeros((VOCAB_SIZE,))\n",
    "\n",
    "for idx, doc in enumerate(train_posts.text):\n",
    "    try:\n",
    "        embedding, ids = get_embedding(doc)\n",
    "        embeddings.append(embedding)\n",
    "        input_ids.append(ids)\n",
    "        token_embeddings.scatter_add_(0, ids[0].unsqueeze(1).expand(embedding.shape), embedding)\n",
    "        token_count.scatter_add_(0, ids[0], torch.ones_like(ids[0]).float())\n",
    "    except Exception as e:\n",
    "        print(idx)\n",
    "        print(get_words(doc))\n",
    "        print(e)\n",
    "\n",
    "token_embeddings = torch.nan_to_num(torch.div(token_embeddings, token_count.unsqueeze(1).expand(token_embeddings.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26641, 768])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_similarities = cosine_similarity(token_embeddings, token_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85      , 0.56472343, 0.33764276, ..., 0.62420136, 0.62081015,\n",
       "        0.5720375 ],\n",
       "       [0.56472343, 0.85      , 0.30267996, ..., 0.5240807 , 0.5224425 ,\n",
       "        0.54111636],\n",
       "       [0.33764276, 0.30267996, 0.85      , ..., 0.25307572, 0.32413712,\n",
       "        0.29881054],\n",
       "       ...,\n",
       "       [0.62420136, 0.5240807 , 0.25307572, ..., 0.85      , 0.57771885,\n",
       "        0.64851695],\n",
       "       [0.62081015, 0.5224425 , 0.32413712, ..., 0.57771885, 0.85      ,\n",
       "        0.5793119 ],\n",
       "       [0.5720375 , 0.54111636, 0.29881054, ..., 0.64851695, 0.5793119 ,\n",
       "        0.85      ]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_similarities.clip(max=0.85, out=token_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26641, 26641)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NYDataset(Dataset):\n",
    "    def __init__(self, embeddings, input_ids):\n",
    "        self.embeddings = embeddings\n",
    "        self.input_ids = list(map(lambda x: x.squeeze(), input_ids))\n",
    "        \n",
    "        self.embeddings = nn.utils.rnn.pad_sequence(self.embeddings, batch_first=True, padding_value=0)\n",
    "        self.input_ids = nn.utils.rnn.pad_sequence(self.input_ids, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return embeddings[idx], input_ids[idx].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 26641])\n"
     ]
    }
   ],
   "source": [
    "gen = torch.randn(128, 64, VOCAB_SIZE)\n",
    "print(gen[:, 0, :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(770229.4375)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = F.log_softmax(torch.randn(128, 64, VOCAB_SIZE), -1)\n",
    "orig = torch.randint(0, VOCAB_SIZE, (64, 128))\n",
    "\n",
    "gen_doc = gen[:, 0, :]\n",
    "orig_doc = orig[0, :]\n",
    "\n",
    "def doc_embed_loss(gen_doc, orig_doc, k=5):\n",
    "    topk_values, topk_indices = torch.topk(gen_doc, k, dim=-1)\n",
    "    rand_indices = torch.randint(0, VOCAB_SIZE, (gen_doc.shape[0], k))\n",
    "    doc_loss = 0\n",
    "    for i in range(gen_doc.shape[0]):\n",
    "        rand_values = torch.index_select(gen_doc, -1, rand_indices[i])\n",
    "        doc_loss += (topk_values * token_similarities[orig_doc[i].item(), topk_indices[i]]).sum()\n",
    "        doc_loss += (rand_values * token_similarities[orig_doc[i].item(), rand_indices[i]]).sum()\n",
    "    \n",
    "    return -doc_loss\n",
    "\n",
    "doc_embed_loss(gen_doc, orig_doc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21210"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_doc[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.6765)\n",
      "tensor(49420204.)\n",
      "tensor(24722414.)\n"
     ]
    }
   ],
   "source": [
    "gen = torch.randn(64, 128, VOCAB_SIZE)\n",
    "orig = torch.randint(0, VOCAB_SIZE, (64, 1, 128))\n",
    "\n",
    "# LOSS FUNCTIONS\n",
    "\n",
    "def recon_loss(inp, targ):\n",
    "    \"Loss of first stage\"\n",
    "    return F.cross_entropy(inp.view(-1, VOCAB_SIZE), targ.reshape(-1))\n",
    "\n",
    "def doc_embed_loss(gen_doc, orig_doc, k=5):\n",
    "    topk_values, topk_indices = torch.topk(gen_doc, k, dim=-1)\n",
    "    rand_indices = torch.randint(0, VOCAB_SIZE, (gen_doc.shape[0], k))\n",
    "    doc_loss = 0\n",
    "    \n",
    "    for i in range(gen_doc.shape[0]):\n",
    "        rand_values = torch.index_select(gen_doc, -1, rand_indices[i])\n",
    "        doc_loss += (topk_values * token_similarities[orig_doc[i].item(), topk_indices[i]]).sum()\n",
    "        doc_loss += (rand_values * token_similarities[orig_doc[i].item(), rand_indices[i]]).sum()\n",
    "\n",
    "    return doc_loss\n",
    "\n",
    "def embed_loss(inp, targ, k=5):\n",
    "    loss = 0\n",
    "    inp = F.log_softmax(inp, dim=-1)\n",
    "    for i in range(inp.shape[0]):\n",
    "        loss += doc_embed_loss(inp[i], targ[i][0], k=k)\n",
    "    return -loss\n",
    "\n",
    "def total_loss(inp, targ, alpha=1, beta=0.5, k=5):\n",
    "    \"Loss of second stage\"\n",
    "    return alpha * recon_loss(inp, targ) + beta * embed_loss(inp, targ, k)\n",
    "\n",
    "print(recon_loss(gen, orig))\n",
    "print(embed_loss(gen, orig))\n",
    "print(total_loss(gen, orig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch-lightning.readthedocs.io/en/latest/notebooks/lightning_examples/datamodules.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(samples):\n",
    "    x = [sample[0] for sample in samples]\n",
    "    y = [sample[1].squeeze() for sample in samples]\n",
    "    \n",
    "    x = nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=0.0)\n",
    "    y = nn.utils.rnn.pad_sequence(y, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "    \n",
    "    if x.shape[1] < y.shape[1]:\n",
    "        y = y[:, :x.shape[1]]\n",
    "    \n",
    "#     print(x.shape, y.shape)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "class LitERAE(pl.LightningModule):\n",
    "    def __init__(self, data, hidden_size=512, num_layers=2, learning_rate=1e-3):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # We hardcode dataset specific stuff here.\n",
    "        self.data = data\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Build model\n",
    "        self.gru_1 = nn.GRU(768, hidden_size, num_layers, bidirectional=True, batch_first=True)\n",
    "        self.linear_1 = nn.Linear(hidden_size * 2, 768)\n",
    "        self.gru_2 = nn.GRU(768, hidden_size, num_layers, bidirectional=True, batch_first=True)\n",
    "        self.linear_2 = nn.Linear(hidden_size * 2, VOCAB_SIZE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, hidden = self.gru_1(x)\n",
    "        x = self.linear_1(x)\n",
    "        x, _ = self.gru_2(x, hidden)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_func(logits, y)\n",
    "        \n",
    "        self.log(f'train_loss', loss)\n",
    "        self.log(f'avg_train_loss', loss, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_func(logits, y)\n",
    "        \n",
    "        self.log(f'val_loss', loss)\n",
    "        self.log(f'avg_val_loss', loss, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        lr_scheduler = {\"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, verbose=True), \"monitor\": \"avg_val_loss\"}\n",
    "        return {'optimizer': optimizer, 'lr_shceduler': lr_scheduler}\n",
    "\n",
    "    def on_train_batch_end(self, outputs, batch, batch_idx, dataloader_idx):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "#         logger.info(f'Batch train loss {metrics}')\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        print(f'Train loss: {metrics[\"avg_train_loss\"]}')\n",
    "\n",
    "    def on_validation_batch_end(self, outputs, batch, batch_idx, dataloader_idx):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "#         logger.info(f'Batch validation loss {metrics}')\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        print(f'Val loss: {metrics[\"avg_val_loss\"]}')\n",
    "\n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "\n",
    "#     def prepare_data(self):\n",
    "#         self.data = nn.utils.rnn.pad_sequence(self.data)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            train_size = int(0.9 * len(self.data))\n",
    "            val_size = len(self.data) - train_size\n",
    "            self.data_train, self.data_val = random_split(self.data, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "            self.loss_func = recon_loss\n",
    "        \n",
    "        if stage == 'fit_2':\n",
    "            train_size = int(0.9 * self.data.shape[1])\n",
    "            val_size = self.data.shape[1] - train_size\n",
    "            self.data_train, self.data_val = random_split(self.data, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "            self.loss_func = total_loss\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "#         if stage == \"test\" or stage is None:\n",
    "#             self.data_test\n",
    "#             self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.data_train, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.data_val, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "#     def test_dataloader(self):\n",
    "#         return DataLoader(self.mnist_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chechpoint_path = \"checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = NYDataset(embeddings, input_ids)\n",
    "model = LitERAE(data)\n",
    "model.train()\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=chechpoint_path, save_top_k=2, monitor=\"val_loss\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=20,\n",
    "    progress_bar_refresh_rate=20,\n",
    "    gpus=1,\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitERAE.load_from_checkpoint(checkpoint_path=checkpoint_callback.best_model_path, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.stage = 'fit_2'\n",
    "model.train()\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=chechpoint_path, save_top_k=2, monitor=\"val_loss\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=10,\n",
    "    progress_bar_refresh_rate=20,\n",
    "    gpus=1,\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitERAE.load_from_checkpoint(checkpoint_path=checkpoint_callback.best_model_path, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'epoch=0-step=243-v1.ckpt'  'epoch=19-step=4860-v1.ckpt'\n",
      "'epoch=0-step=243.ckpt'     'epoch=19-step=4860.ckpt'\n",
      "'epoch=14-step=3645.ckpt'   'epoch=3-step=972.ckpt'\n",
      "'epoch=18-step=4617.ckpt'   'epoch=5-step=1458.ckpt'\n"
     ]
    }
   ],
   "source": [
    "# !ls checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = NYDataset(embeddings, input_ids)\n",
    "model = LitERAE.load_from_checkpoint(checkpoint_path='checkpoints/epoch=19-step=4860-v1.ckpt', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_mechanism(pho, epsilon, delta):\n",
    "    pho = np.array(pho)\n",
    "    temp = np.exp(epsilon / (2 * delta) * pho)\n",
    "    return temp / np.sum(temp)\n",
    "\n",
    "\n",
    "def predict(model, sent, seed=None):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    inp = get_embedding(sent)[0].unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        logits = model(inp)[0]\n",
    "    \n",
    "    predicted_probs = torch.softmax(logits, dim=-1)\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    def build_two_sets(probs, k=5):\n",
    "        # return lexical set and semantic set\n",
    "        probs = np.array(probs)\n",
    "        l_set = rng.choice(probs.shape[0], k, p=probs, replace=True)\n",
    "        l_set_probs = probs[l_set]\n",
    "\n",
    "        marks = np.ones(probs.shape[0], dtype=bool)\n",
    "        marks[l_set] = False\n",
    "\n",
    "        whole_idxs = np.arange(probs.shape[0])\n",
    "        s_set = whole_idxs[marks]\n",
    "        s_set_probs = probs[marks]\n",
    "\n",
    "        return l_set, s_set, l_set_probs, s_set_probs\n",
    "\n",
    "    def choose_set(l_set, s_set, l_set_probs, s_set_probs, eps=80):\n",
    "        probs = [0, 0]\n",
    "        probs[0] = np.sum(l_set_probs) / (np.sum(l_set_probs) + np.sum(s_set_probs))\n",
    "        probs[1] = 1 - probs[0]\n",
    "        probs = exponential_mechanism(probs, eps, 1)\n",
    "        po = [(l_set, l_set_probs), (s_set, s_set_probs)]\n",
    "        indxs = [0, 1]\n",
    "        indx = int(rng.choice(indxs, 1, p=probs))\n",
    "        return po[indx]\n",
    "\n",
    "    for probs in predicted_probs:\n",
    "        # build set\n",
    "        l_set, s_set, l_set_probs, s_set_probs = build_two_sets(probs, k=5)\n",
    "\n",
    "        # choose set\n",
    "        c_set, c_set_probs = choose_set(l_set, s_set, l_set_probs, s_set_probs)\n",
    "\n",
    "        # choose token\n",
    "        token_eps = 0.1\n",
    "        c_set_probs = exponential_mechanism(c_set_probs, token_eps, 1)\n",
    "        token_idx = int(rng.choice(c_set, 1, p=c_set_probs))\n",
    "\n",
    "        if token_idx == EOS_TOKEN_ID:\n",
    "            break\n",
    "        res.append(token_idx)\n",
    "#     o_pred = ' '.join([self.params['idx2word'][idx] for idx in res])\n",
    "#     o_pred = tokenizer.decode(res, skip_special_tokens=True)\n",
    "    o_pred = ' '.join(idx2token[idx] for idx in res[1:])\n",
    "    return o_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Original>:\n",
      "miss twin peaksis next saturday night at @joespub ! will you be there? @schafferthedarklord @revlegsmalone @bunnybuxom @booboodarlin @seedyedie @holly_honeypot @francineld @minxarcana @loganlaveau @ameliabareparts @varlavelour photos & design by @francinefoto     : joespub.com\n",
      "--------------------------------->\n",
      "<Transformed>:\n",
      "mar green queens new saturday night at @ drinking ! will you be there ? @ baristanet @ therealdjlito @ kodilee1111 @ diamondharding @ seedyedie @ seedyedie _ eq @ francineld @ minxarcana @ smoovebabii @ status @ salmon clothing & design by @ speedyromeo : hofbraeumuenchen . com\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "text = test_posts.text[test_posts.index[1]]\n",
    "print('<Original>:')\n",
    "print(text)\n",
    "print('--------------------------------->')\n",
    "print('<Transformed>:')\n",
    "print(predict(model, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Original>:\n",
      "ladies and gentlemen! we are almost fully booked for 2020 new year party but still have some availabilities, but literally couple of tables....literally  718-513-6004\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "ladies and gentlemen ! we are almost simply booked for 2020 new year party but still have some availabilities , but literally couple of tables . . . . literally 718 - 673 - 6004\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "a new perspective on an old favorite... that's what the new year can gift to you! good food and great  at @sistersbklyn (900 fulton). : @stefanieeesays\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "a new formation on an old favorite . . . that ' s what the new year can gift to you ! good food and great at @ clifton ( 900 fulton ) . : @ kohl\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "today was a blessing i got to see my family and my  sister\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "today was a lil i got to see my family and my soul\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "taboga  saturday 05/25 /19 apptetizer + main course + dessert [ + 2 hrs unlimited mimosa / sangria / punch ] only for $35.00 music by: ecraze stay_liifted pesao anthony rey free free hookah from 1pm-5pm . .. rsvp: 917-330-9248 tex .. taboga by oleaga restaurant . billiard . barbershop 421 w 202nd st, new york, ny 10034 .. ..\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "taboga saturday 05 / 25 / 19 apptetizer + main course + dessert [ + 2 hrs unlimited estylez / sangria / punch ] only for $ 35 . 00 music by : ecraze stay _ liifted pesao anthony rey free free hookah from 1pm - 5pm . . . rsvp : 917 - 330 - 9248 tex . . taboga by oleaga restaurant . billiard . barbershop 421 w 202nd st , new york , ny 10034 . . . .\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "it's officially summer  'call out mondays' @fortythirdstreetcafe with @djyoungfresh is the place to be!! open bar menu selection. (8pm-9pm)  free admission & $2 crabs. now that's a party! 1425 springfield ave. irvington, nj @bass_entertainment  & @scott2289 turn up the heat on a monday\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "it ' s officially summer ' call out mondays ' @ fortythirdstreetcafe with @ djyoungfresh is the place to be ! ! open bar menu selection . ( 8pm - 9pm ) free admission & $ 2 crabs . now that ' s a party ! 1425 springfield ave . irvington , nj @ bass _ entertainment & @ scott2289 turn up the heat on a monday\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "this saturday party with us at the dopest comedy show on the northern tip of manhattan. when? 23 feb 2019. seats @ 9:30p, first come! where? @theparkviewcafe the park view, 219 dyckman st, nyc. 2 items min. no cover! seats go fast; rsvp now w/ link in profile , or here: <url>   special guest host: @leevalentin nataly aukar @natyourcolor kevin berrey @berrey tayler yarish @tayleryarish drexton clemons @thisguydrex erik helewa @erik_helewa brittanie sheree @brittisfunny   !! !!!\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "this saturday party with us at the dopest comedy show on the northern tip of manhattan . when ? 23 feb 2019 . seats @ 9 : 30p , first come ! where ? @ theparkviewcafe the park view , 219 dyckman st , nyc . 2 items min . no cover ! seats go fast ; rsvp now w / link in profile , or here : < url > special guest tv : @ leesyatt adventurous italy @ natyourcolor kevin berrey @ berrey tayler yarish @ tayleryarish drexton clemons @\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "are you around nyc next weekend?  the vibrant and inspiring time of bushwick open studios is happening in synch with the fall equinox  daya will be participating and we have so many wonderful offerings coming your way! ! ! . . . fri 9/20 7p: 108 sun salutations to celebrate the fall equinox with ania lesniak @daya_mama 7-10p: art viewing . . sat 9/21 8a: cacao ceremony with erika laila @truthseekerdivinationnyc 2-5:30p: psychic fair ( tarot reading, natal chart reading, astrology reading, cupping & much more ) 6:30p: interactive performance with ania & mariya dimov @mariyadimov 7:45p: pierce boaz comedy 8-9p: interactive experience with michael doonan @michaeldoonan . . sun 9/22 block party in collaboration with house of yes 12-1p: kirtan with ania & carmina 1-2p: performative yoga with nikki ortiz @nikki_ortiz 2-3p: meditation for manifestation with diana & patrick @emily_cremona 3-4p: daya dance with ania 4-5p: sound bath with andrea baquero @soundandvibe . . art viewing 2-5p tarantella dance 7-10pm with alessendrana belloni @belloni.alessandra   . . photo by : @houseofyesnyc\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "are you around nyc next weekend ? the sweetest and ink time of mental open studios is happening in wonderland with the fall equinox daya will be phones and we have so many wonderful reviews bring your way ! ! ! . . . coloration 9 / 20 son : 108 son congratulations to celebrate the fall equinox with maria djbeluccinyc @ daya _ july 7 - 11 : art words . . pick 9 / 21 decent : cacao photo with maria maria @ pardon 2 - 5 : 30p\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "this sweetheart performs at this casita every friday at 11. join @leeburgos, her band and our familia, we guarantee you a fabulous night.\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "this buratta poets at this queen every friday at 11 . join @ leeburgos , her band and our familia , we cmlauriecumbo you a homemade night .\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "chef david and our talented team here at the caldwell bakery will help you design the perfect cake for any occasion, from weddings to birthdays and everything in between\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "chef david and our talented team here at the caldwell bakery will help you design the perfect cake for any occasion , from weddings to birthdays and everything in between\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "...even on a rainy day  check out our boutique for the latest & greatest!\n",
      "------------------------>\n",
      "<Transformed>:\n",
      ". . . even on a rainy day check out our boutique for the latest & soundbaths !\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "test_texts = test_posts.text\n",
    "for i in range(100, 110):\n",
    "    text = test_texts[test_posts.index[i]]\n",
    "    print('<Original>:')\n",
    "    print(text)\n",
    "    print('------------------------>')\n",
    "    print('<Transformed>:')\n",
    "    print(predict(model, text))\n",
    "    print('\\n------------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtags anonymization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SynTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nyc_posts_df.loc[nyc_posts_df['hashtags'].str.len() > 100, 'hashtags'][:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#EATDRINKPARTY #miercolesplayero #bronx #BottleSpecials #bestiakitchenbx #LaBestiaDelBronx #HappyHour #PartyPeople #FoodPorn #salsa #playero #retro #4thofjulyparty #preindependenceday #preindependencedayparty'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14349"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "s = set(chain.from_iterable(docs.str.split()))\n",
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_model = CountVectorizer(ngram_range=(1,1))\n",
    "X = count_model.fit_transform(docs)\n",
    "Xc = (X.T * X)\n",
    "Xc.setdiag(0)\n",
    "Xc = Xc.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5119884,\n",
       " matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 5, 5],\n",
       "         [0, 0, 0, ..., 5, 0, 5],\n",
       "         [0, 0, 0, ..., 5, 5, 0]]))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc.sum(), Xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13364, 13364)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.4684e-05, 7.4684e-05, 7.4684e-05,  ..., 7.4684e-05, 7.4684e-05,\n",
       "         7.4684e-05],\n",
       "        [7.4582e-05, 7.4582e-05, 7.4582e-05,  ..., 7.4582e-05, 7.4582e-05,\n",
       "         7.4582e-05],\n",
       "        [7.3181e-05, 7.3181e-05, 7.3181e-05,  ..., 7.3181e-05, 7.3181e-05,\n",
       "         7.3181e-05],\n",
       "        ...,\n",
       "        [3.0429e-07, 3.0429e-07, 3.0429e-07,  ..., 3.0429e-07, 4.5161e-05,\n",
       "         4.5161e-05],\n",
       "        [3.0429e-07, 3.0429e-07, 3.0429e-07,  ..., 4.5161e-05, 3.0429e-07,\n",
       "         4.5161e-05],\n",
       "        [3.0429e-07, 3.0429e-07, 3.0429e-07,  ..., 4.5161e-05, 4.5161e-05,\n",
       "         3.0429e-07]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc = torch.softmax(torch.from_numpy(Xc).float(), dim=-1)\n",
    "Xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0000), tensor(7.4684e-05))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc[0].sum(), Xc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "tfidf.fit(docs)\n",
    "doc_vecs = tfidf.transform(docs)\n",
    "doc_vecs = normalize(doc_vecs, norm='l1')\n",
    "words = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13364"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = fasttext.load_facebook_model(datapath('/mnt/ess_storage/DN_1/storage/home/vpanov/cc.en.300.bin.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc[count_model.vocabulary_['newyork']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13364, 13364)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vecs = [Xc[count_model.vocabulary_[word]].tolist()[0] for word in words]\n",
    "word_similarities = cosine_similarity(word_vecs, word_vecs)\n",
    "word_similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kgram_overlap(word1, word2, k):\n",
    "    a = set([word1[i:i+k] for i in range(0, len(word1) - k + 1)])\n",
    "    b = set([word2[i:i+k] for i in range(0, len(word2) - k + 1)])\n",
    "    inter = len(a.intersection(b))\n",
    "    return inter / (len(a) + len(b) - inter)\n",
    "\n",
    "def score(word1, word2):\n",
    "    idx1, idx2 = tfidf.vocabulary_[word1], tfidf.vocabulary_[word2]\n",
    "    return word_similarities[idx1, idx2] - 0.3 * kgram_overlap(word1, word2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likes4like ['turkiye']\n"
     ]
    }
   ],
   "source": [
    "def exponential_gen(x, R, u, sensitivity=1, epsilon=25.4):\n",
    "    # Calculate the score for each element of R\n",
    "    scores = [u(x, r) for r in R]\n",
    "    \n",
    "    # Calculate the probability for each element, based on its score\n",
    "    probabilities = [np.exp(epsilon * score / (2 * sensitivity)) for score in scores]\n",
    "    \n",
    "    # Normalize the probabilties so they sum to 1\n",
    "    probabilities = probabilities / np.linalg.norm(probabilities, ord=1)\n",
    "\n",
    "    # Choose an element from R based on the probabilities\n",
    "    return np.random.choice(R, 1, p=probabilities)\n",
    "\n",
    "num = 7000\n",
    "print(words[num], exponential_gen(words[num], words, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13364, 13364)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exponential(x, R, u, sensitivity=1, epsilon=25.4):\n",
    "    # Calculate the score for each element of R\n",
    "    scores = [u(x, r) for r in R]\n",
    "    \n",
    "    # Calculate the probability for each element, based on its score\n",
    "    probabilities = [np.exp(epsilon * score / (2 * sensitivity)) for score in scores]\n",
    "    \n",
    "    # Normalize the probabilties so they sum to 1\n",
    "    probabilities = probabilities / np.linalg.norm(probabilities, ord=1)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "word_replace_probs = []\n",
    "\n",
    "for idx, word in enumerate(words):\n",
    "    if idx % 100 == 0:\n",
    "        print(idx)\n",
    "    word_replace_probs.append(exponential(word, words, score))\n",
    "\n",
    "word_replace_probs = np.array(word_replace_probs)\n",
    "word_replace_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--ORIGINAL--\n",
      "#EATDRINKPARTY #miercolesplayero #bronx #BottleSpecials #bestiakitchenbx #LaBestiaDelBronx #HappyHour #PartyPeople #FoodPorn #salsa #playero #retro #4thofjulyparty #preindependenceday #preindependencedayparty\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "gaynightlife nbafinals2019 bachata miercolesplayero eatdrinkparty nbafinals2019 santiago 4thofjulyparty caucau 4thofjulyparty lentejitas nycdrinks ericktorres latino 4thofjulyparty\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "#914 #newrochelle #newrochelleny #ionacollege #westchester #westchesterny #westchestereats #westchesternyeats #westchestercountyny #westchestercounty #westchesterfood #westchesterfoodie #tuckahoeny #tuckahoe #eastchester #eastchesterny #larchmont #larchmontny #larchmontvillage #pelhamny #yonkers #yonkersny #bronxville #bronxvilleny #burgersandbeer #bestwings\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "westchestereats burgersandfries jameson yonkersny jameson latenightfood larchmontny larchmont yonkers yonkers panini phillycheesesteak tuckahoe titosvodka pelhammanor larchmontny bestwingsever jamesonwhiskey bestwings yonkers newrochelle burgersandfries salad westchesternyeats jamesonwhiskey yonkers\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "#effigies #forevergrounded #record #punk #1984 #theeffigies #records #vinyl #newyorkcity #recordsforsale #carrollgardens #redhook #chicago #punkrock #vinylporn #recordshop #hardcorepunk #vinyligclub #rock #almostreadyrecords #vinylforsale #webuyvinyl #buyselltrade #nyc #brooklyn #vinylrecord #enigma #lp\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "carlitosway stooges thebeatles almostready citoferminorchestra 33rpm 1970 effigies 1996 reissue thedictatorsnyc records mysaxophoneforchristmas modusoperandi doom thecity sealed almostchristmas miccitysons redhook redvinyl enigma effigies alifewithoutobstacles jamesbrown recordporn countryteasers ska\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "#10yearchallenge #tgif #1 #happyhour #78loungenj #drinks #food #birthday #turnup #party #goodlife #nightlife #dj #like4like #goodtime #friends #family #followme #instaselfie #swag #follow #newjersey #friday #flashbackfriday\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "followme 78lifestyle amazonbooks tournament 78loungenj theheavyhitterdjs sipandpaint friends niceandsmooth family friends lawenforcement goodtime ncaa favorite followme goodlife nightlife 78lounge stpattysday theheavyhitterdjs budin dj djcoolv\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "#birthdayparties #halloween #halloweenparty2019 #thecomplexnyc #birthday #bubbleball #bubbleballsoccer #halloweenpartylic #halloweenpartyastoria #bubbleballny #adults #bounce #astoria #lic #astoriaqueens #queens #birthdayparties #newyork #astoriaqueensny #astoriaqueens #queens #fun #kids #funkids #family #astoriasportscomplex #costumeparty #prizes #halloweenpartynyc #kidshalloweenparty #kidshalloweenparty2019 #halloweenpartyny #nychalloweenparty\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "birthdayparties funkids babysharkchallenge nerfgun halloweenpartynyc swag knockerballnyc halloweenpartynyc kids lic kidshalloweenparty2018 hocuspocustrivia animalshow magicshownyc costumeparty costumeparty funkids swimlessons funkids bubbleballsoccer bubbleballsoccer bubbleballsoccer halloweenpartyny astoriaqueensny bubbleballsoccer halloweenpartyny november bubblesoccer bubbleballsoccer indoors astoriaqueensny bubbleballnyc kidshalloweenparty2018\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for idx, doc in enumerate(docs[:5]):\n",
    "    print('--ORIGINAL--')\n",
    "    print(doc)\n",
    "    print('--GENERATED SEQUENCE (WITHOUT WORD ORDER)--')\n",
    "    words_count = len(doc.split())\n",
    "    words_ = np.random.choice(words, words_count, p=doc_vecs[idx].todense().tolist()[0])\n",
    "    for i in range(words_count):\n",
    "        word_idx = tfidf.vocabulary_[words_[i]]\n",
    "        words_[i] = np.random.choice(words, 1, p=word_replace_probs[word_idx])[0]\n",
    "    print(' '.join(words_))\n",
    "    print('-'*150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/gkhayes/author_attribution CNN AA model\n",
    "\n",
    "https://github.com/yunitata/continuous-n-gram-AA code for CNN AA experiments reproduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = tokenizer.batch_decode(tokenizer(train_posts.text.tolist(), return_tensors=\"pt\", max_length=128, padding='max_length', truncation=True).input_ids, skip_special_tokens=True)\n",
    "text_test = tokenizer.batch_decode(tokenizer(test_posts.text.tolist(), return_tensors=\"pt\", max_length=128, padding='max_length', truncation=True).input_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_n_grams(excerpt_list, n, vocab_size, seq_size):\n",
    "    \"\"\"Create a list of n-gram sequences\n",
    "    \n",
    "    Args:\n",
    "    excerpt_list: list of strings. List of normalized text excerpts.\n",
    "    n: int. Length of n-grams.\n",
    "    vocab_size: int. Size of n-gram vocab (used in one-hot encoding)\n",
    "    seq_size: int. Size of n-gram sequences\n",
    "    \n",
    "    Returns:\n",
    "    n_gram_array: array. Numpy array of one-hot encoded n-grams.\n",
    "    \"\"\"\n",
    "    n_gram_list = []\n",
    "\n",
    "    for excerpt in excerpt_list:\n",
    "        # Remove spaces\n",
    "        excerpt = excerpt.replace(\" \", \"\")\n",
    "\n",
    "        # Extract n-grams\n",
    "        n_grams = [excerpt[i:i + n] for i in range(len(excerpt) - n + 1)]\n",
    "\n",
    "        # Convert to a single string with spaces between n-grams\n",
    "        new_string = \" \".join(n_grams)\n",
    "\n",
    "        # One hot encode\n",
    "        hot = one_hot(new_string, round(vocab_size*1.3))\n",
    "\n",
    "        # Pad hot if necessary\n",
    "        hot_len = len(hot)\n",
    "        if hot_len >= seq_size:\n",
    "            hot = hot[0:seq_size]\n",
    "        else:\n",
    "            diff = seq_size - hot_len\n",
    "            extra = [0]*diff\n",
    "            hot = hot + extra\n",
    "\n",
    "        n_gram_list.append(hot)\n",
    "    \n",
    "    n_gram_array = np.array(n_gram_list)\n",
    "    \n",
    "    return n_gram_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_size(excerpt_list, n, seq_size):\n",
    "    \"\"\"Calculate size of n-gram vocab\n",
    "    \n",
    "    Args:\n",
    "    excerpt_list: list of strings. List of normalized text excerpts.\n",
    "    n: int. Length of n-grams.\n",
    "    seq_size: int. Size of n-gram sequences\n",
    "    \n",
    "    Returns:\n",
    "    vocab_size: int. Size of n-gram vocab.\n",
    "    \"\"\"\n",
    "    n_gram_list = []\n",
    "\n",
    "    for excerpt in excerpt_list:\n",
    "        # Remove spaces\n",
    "        excerpt = excerpt.replace(\" \", \"\")\n",
    "\n",
    "        # Extract n-grams           \n",
    "        n_grams = [excerpt[i:i + n] for i in range(len(excerpt) - n + 1)]\n",
    "\n",
    "        # Create list of n-grams\n",
    "        gram_len = len(n_grams)\n",
    "        if gram_len >= seq_size:\n",
    "            n_grams = n_grams[0:seq_size]\n",
    "        else:\n",
    "            diff = seq_size - gram_len\n",
    "            extra = [0]*diff\n",
    "            n_grams = n_grams + extra\n",
    "        \n",
    "        n_gram_list.append(n_grams)\n",
    "    \n",
    "    # Flatten n-gram list\n",
    "    n_gram_list = list(np.array(n_gram_list).flat)\n",
    "    \n",
    "    # Calculate vocab size\n",
    "    n_gram_cnt = Counter(n_gram_list)\n",
    "    vocab_size = len(n_gram_cnt)\n",
    "    \n",
    "    return vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size for n = 4334476665 is: 32208\n"
     ]
    }
   ],
   "source": [
    "vocab_size = get_vocab_size(text_train, 3, 128)\n",
    "print('Vocab size for n =', i, 'is:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17271, 128)\n",
      "(1000, 128)\n"
     ]
    }
   ],
   "source": [
    "# Create n-gram lists\n",
    "gram3_train = create_n_grams(text_train, 3, vocab_size, 128)\n",
    "gram3_test = create_n_grams(text_test, 3, vocab_size, 128)\n",
    "\n",
    "print(np.shape(gram3_train))\n",
    "print(np.shape(gram3_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum encoding value for 3-grams is:  41868\n"
     ]
    }
   ],
   "source": [
    "max_3gram = np.max(gram3_train)\n",
    "\n",
    "print('Maximum encoding value for 3-grams is: ', max_3gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture in keras\n",
    "# Code reference: https://machinelearningmastery.com/develop-n-gram-multichannel-convolutional-neural-network-sentiment-analysis/\n",
    "def define_model(input_len, output_size, vocab_size, embedding_dim, verbose = True,\n",
    "                drop_out_pct = 0.25, conv_filters = 500, activation_fn = 'relu', pool_size = 2, learning = 0.0001):\n",
    "    \"\"\"Define n-gram CNN\n",
    "    \n",
    "    Args:\n",
    "    input_len: int. Length of input sequences.\n",
    "    output_size: int. Number of output classes.\n",
    "    vocab_size: int. Maximum value of n-gram encoding.\n",
    "    embedding_dim: int. Size of embedding layer.\n",
    "    verbose: bool. Whether or not to print model summary.\n",
    "    drop_out_pct: float. Drop-out rate.\n",
    "    conv_filters: int. Number of filters in the conv layer.\n",
    "    activation_fn: string. Activation function to use in the convolutional layer.\n",
    "    pool_size: int. Pool size for the max pooling layer.\n",
    "    learning: float. Learning rate for the model optimizer.\n",
    "    \n",
    "    Returns:\n",
    "    model: keras model object. \n",
    "    \"\"\"\n",
    "    # Channel 1\n",
    "    inputs1 = Input(shape = (input_len,))\n",
    "    embedding1 = Embedding(vocab_size, embedding_dim)(inputs1)\n",
    "    drop1 = Dropout(drop_out_pct)(embedding1)\n",
    "    conv1 = Conv1D(filters = conv_filters, kernel_size = 3, activation = activation_fn)(drop1)\n",
    "    pool1 = MaxPooling1D(pool_size = pool_size)(conv1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    \n",
    "    # Channel 2\n",
    "    inputs2 = Input(shape = (input_len,))\n",
    "    embedding2 = Embedding(vocab_size, embedding_dim)(inputs2)\n",
    "    drop2 = Dropout(drop_out_pct)(embedding2)\n",
    "    conv2 = Conv1D(filters = conv_filters, kernel_size = 4, activation = activation_fn)(drop2)\n",
    "    pool2 = MaxPooling1D(pool_size = pool_size)(conv2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "\n",
    "    # Channel 3\n",
    "    inputs3 = Input(shape = (input_len,))\n",
    "    embedding3= Embedding(vocab_size, embedding_dim)(inputs3)\n",
    "    drop3 = Dropout(drop_out_pct)(embedding3)\n",
    "    conv3 = Conv1D(filters = conv_filters, kernel_size = 5, activation = activation_fn)(drop3)\n",
    "    pool3 = MaxPooling1D(pool_size = pool_size)(conv3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    \n",
    "    # Merge channels\n",
    "    merged = Concatenate()([flat1, flat2, flat3])\n",
    "    \n",
    "    # Create output layer\n",
    "    output = Dense(output_size, activation = 'softmax')(merged)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = [inputs1, inputs2, inputs3], outputs = output)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer = Adam(lr = learning), metrics=['accuracy'])\n",
    "    \n",
    "    if verbose:\n",
    "        print(model.summary())\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = preprocessing.LabelEncoder()\n",
    "\n",
    "author_train = lb.fit_transform(train_posts.authorid.values)\n",
    "author_train_hot = pd.get_dummies(author_train).values\n",
    "author_test = lb.transform(test_posts.authorid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 128, 600)     25121400    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 128, 600)     25121400    ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 128, 600)     25121400    ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128, 600)     0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128, 600)     0           ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 128, 600)     0           ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 126, 500)     900500      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 125, 500)     1200500     ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 124, 500)     1500500     ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 63, 500)      0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 62, 500)     0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 62, 500)     0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 31500)        0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 31000)        0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 31000)        0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 93500)        0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 50)           4675050     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 83,640,750\n",
      "Trainable params: 83,640,750\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create the 3-gram model\n",
    "gram3_model = define_model(128, len(train_posts.authorid.unique()), max_3gram + 1, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "432/432 [==============================] - 43s 84ms/step - loss: 3.4250 - accuracy: 0.2062 - val_loss: 2.9596 - val_accuracy: 0.3988\n",
      "Epoch 2/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 2.1771 - accuracy: 0.5316 - val_loss: 1.8056 - val_accuracy: 0.5902\n",
      "Epoch 3/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 1.0756 - accuracy: 0.7855 - val_loss: 1.2396 - val_accuracy: 0.6973\n",
      "Epoch 4/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.4933 - accuracy: 0.9173 - val_loss: 0.9964 - val_accuracy: 0.7465\n",
      "Epoch 5/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.2075 - accuracy: 0.9784 - val_loss: 0.8906 - val_accuracy: 0.7670\n",
      "Epoch 6/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0877 - accuracy: 0.9957 - val_loss: 0.8383 - val_accuracy: 0.7754\n",
      "Epoch 7/15\n",
      "432/432 [==============================] - 36s 84ms/step - loss: 0.0403 - accuracy: 0.9990 - val_loss: 0.8217 - val_accuracy: 0.7899\n",
      "Epoch 8/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.8080 - val_accuracy: 0.7887\n",
      "Epoch 9/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.8004 - val_accuracy: 0.7931\n",
      "Epoch 10/15\n",
      "432/432 [==============================] - 36s 82ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.8001 - val_accuracy: 0.7968\n",
      "Epoch 11/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.8027 - val_accuracy: 0.7977\n",
      "Epoch 12/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8060 - val_accuracy: 0.7962\n",
      "Epoch 13/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8111 - val_accuracy: 0.7974\n",
      "Epoch 14/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8191 - val_accuracy: 0.7977\n",
      "Epoch 15/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8237 - val_accuracy: 0.7991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5a5f6c2e0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram3_model.fit([gram3_train, gram3_train, gram3_train], author_train_hot, epochs=15, batch_size=32, \n",
    "                verbose = 1, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.769\n",
      "Ave. Precision: 0.7850834130833794\n",
      "Ave. Recall: 0.769\n",
      "Ave. F1 Score: 0.7724860715050913\n",
      "Prediction Time: 0.4052286148071289 seconds\n",
      "Confusion Matrix:\n",
      " [[17  1  0 ...  0  0  0]\n",
      " [ 0 15  0 ...  0  0  0]\n",
      " [ 0  0 19 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 15  1  0]\n",
      " [ 0  0  0 ...  0 16  0]\n",
      " [ 0  0  0 ...  0  0 20]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate Model 1 (3-gram CNN)\n",
    "\n",
    "# t0 = time.time()\n",
    "\n",
    "# # Fit model\n",
    "# model1 = define_model(128, len(train_posts.authorid.unique()), max_3gram + 1, 300)\n",
    "# model1.fit([gram3_train, gram3_train, gram3_train], author_train_hot, epochs=10, batch_size=32, \n",
    "#            verbose = 1, validation_split = 0.2)\n",
    "t1 = time.time()\n",
    "\n",
    "# Predict values for test set\n",
    "author_pred1 = gram3_model.predict([gram3_test, gram3_test, gram3_test]).argmax(-1)\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "# Evaluate\n",
    "accuracy = balanced_accuracy_score(author_test, author_pred1)\n",
    "precision, recall, f1, support = score(author_test, author_pred1, average='weighted')\n",
    "confusion = confusion_matrix(author_test, author_pred1)\n",
    "    \n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Ave. Precision:\", precision)\n",
    "print(\"Ave. Recall:\", recall)\n",
    "print(\"Ave. F1 Score:\", f1)\n",
    "# print(\"Training Time:\", (t1 - t0), \"seconds\")\n",
    "print(\"Prediction Time:\", (t2 - t1), \"seconds\")\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "\n",
    "with open('attacker.txt', 'w') as f:\n",
    "    print(\"Accuracy:\", accuracy, file=f)\n",
    "    print(\"Ave. Precision:\", precision, file=f)\n",
    "    print(\"Ave. Recall:\", recall, file=f)\n",
    "    print(\"Ave. F1 Score:\", f1, file=f)\n",
    "    print(\"Confusion Matrix:\\n\", confusion, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_states_batch(encoded, model, layers):\n",
    "    \"\"\"Push input IDs through model. Stack and sum `layers` (last four by default).\n",
    "        Select only those subword token outputs that belong to our word of interest\n",
    "        and average them.\"\"\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        states = model(**encoded).hidden_states\n",
    " \n",
    "    batch_res = []\n",
    "    \n",
    "    for i in range(len(states[0])):\n",
    "        token_ids_words = encoded.word_ids(i)\n",
    "        output = torch.stack([states[layer][i] for layer in layers]).sum(0).squeeze().cpu()\n",
    "\n",
    "        res = []\n",
    "        labels_count = []\n",
    "\n",
    "        for idx, (outp, label) in enumerate(zip(output, token_ids_words)):\n",
    "            if label is None or token_ids_words[idx - 1] is None or token_ids_words[idx - 1] != token_ids_words[idx]:\n",
    "                res.append(outp)\n",
    "                labels_count.append(1)\n",
    "            else: \n",
    "                res[-1] += outp\n",
    "                labels_count[-1] += 1\n",
    "\n",
    "        res = torch.vstack(res)\n",
    "        res = res / torch.tensor(labels_count).float().unsqueeze(1)\n",
    "        \n",
    "        batch_res.append(res)\n",
    "    batch_res = nn.utils.rnn.pad_sequence(batch_res, batch_first=True, padding_value=0.0)\n",
    "    return batch_res\n",
    "\n",
    "def get_word_vectors_batch(sents, tokenizer, model, layers):\n",
    "    \"\"\"Get a word vector by first tokenizing the input sentence, getting all token idxs\n",
    "        that make up the word of interest, and then `get_hidden_states`.\"\"\"\n",
    "    \n",
    "    encoded = tokenizer.batch_encode_plus(sents, return_tensors=\"pt\", max_length=128, padding='max_length', truncation=True)\n",
    "\n",
    "    hidden_states = get_hidden_states_batch(encoded, model, layers)\n",
    "    return hidden_states\n",
    "\n",
    "def get_embedding_batch(docs, model=bert):\n",
    "    \"Get embedding for each word\"\n",
    "    layers = [-4, -3, -2, -1]\n",
    "    return get_word_vectors_batch(docs, tokenizer, model, layers)\n",
    "\n",
    "def predict_batch(model, sents, seed=None, batch_size=32):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    def build_two_sets(probs, k=5):\n",
    "        # return lexical set and semantic set\n",
    "        probs = np.array(probs)\n",
    "        l_set = rng.choice(probs.shape[0], k, p=probs, replace=True)\n",
    "        l_set_probs = probs[l_set]\n",
    "\n",
    "        marks = np.ones(probs.shape[0], dtype=bool)\n",
    "        marks[l_set] = False\n",
    "\n",
    "        whole_idxs = np.arange(probs.shape[0])\n",
    "        s_set = whole_idxs[marks]\n",
    "        s_set_probs = probs[marks]\n",
    "\n",
    "        return l_set, s_set, l_set_probs, s_set_probs\n",
    "\n",
    "    def choose_set(l_set, s_set, l_set_probs, s_set_probs, eps=80):\n",
    "        probs = [0, 0]\n",
    "        probs[0] = np.sum(l_set_probs) / (np.sum(l_set_probs) + np.sum(s_set_probs))\n",
    "        probs[1] = 1 - probs[0]\n",
    "        probs = exponential_mechanism(probs, eps, 1)\n",
    "        po = [(l_set, l_set_probs), (s_set, s_set_probs)]\n",
    "        indxs = [0, 1]\n",
    "        indx = int(rng.choice(indxs, 1, p=probs))\n",
    "        return po[indx]\n",
    "    \n",
    "    o_pred = []\n",
    "    \n",
    "    for i in range(0, len(sents), batch_size):\n",
    "        batch = sents[i:i+batch_size]\n",
    "        inp = get_embedding_batch(batch)\n",
    "        with torch.no_grad():\n",
    "            logits = model(inp)\n",
    "\n",
    "        predicted_probs = torch.softmax(logits, dim=-1)\n",
    "    \n",
    "        for sent in predicted_probs:\n",
    "            res = []\n",
    "            for probs in sent:\n",
    "                # build set\n",
    "                l_set, s_set, l_set_probs, s_set_probs = build_two_sets(probs, k=5)\n",
    "\n",
    "                # choose set\n",
    "                c_set, c_set_probs = choose_set(l_set, s_set, l_set_probs, s_set_probs)\n",
    "\n",
    "                # choose token\n",
    "                token_eps = 0.1\n",
    "                c_set_probs = exponential_mechanism(c_set_probs, token_eps, 1)\n",
    "                token_idx = int(rng.choice(c_set, 1, p=c_set_probs))\n",
    "\n",
    "                if token_idx == EOS_TOKEN_ID:\n",
    "                    break\n",
    "                res.append(token_idx)\n",
    "        #     o_pred = tokenizer.decode(res, skip_special_tokens=True)\n",
    "            o_pred.append(' '.join(idx2token[idx] for idx in res[1:]))\n",
    "        \n",
    "        if i % 640 == 0:\n",
    "            print(i)\n",
    "\n",
    "    return o_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "160\n",
      "320\n",
      "480\n",
      "640\n",
      "800\n",
      "960\n",
      "1120\n",
      "1280\n",
      "1440\n",
      "1600\n",
      "1760\n",
      "1920\n",
      "2080\n",
      "2240\n",
      "2400\n",
      "2560\n",
      "2720\n",
      "2880\n",
      "3040\n",
      "3200\n",
      "3360\n",
      "3520\n",
      "3680\n",
      "3840\n",
      "4000\n",
      "4160\n",
      "4320\n",
      "4480\n",
      "4640\n",
      "4800\n",
      "4960\n",
      "5120\n",
      "5280\n",
      "5440\n",
      "5600\n",
      "5760\n",
      "5920\n",
      "6080\n",
      "6240\n",
      "6400\n",
      "6560\n",
      "6720\n",
      "6880\n",
      "7040\n",
      "7200\n",
      "7360\n",
      "7520\n",
      "7680\n",
      "7840\n",
      "8000\n",
      "8160\n",
      "8320\n",
      "8480\n",
      "8640\n",
      "8800\n",
      "8960\n",
      "9120\n",
      "9280\n",
      "9440\n",
      "9600\n",
      "9760\n",
      "9920\n",
      "10080\n",
      "10240\n",
      "10400\n",
      "10560\n",
      "10720\n",
      "10880\n",
      "11040\n",
      "11200\n",
      "11360\n",
      "11520\n",
      "11680\n",
      "11840\n",
      "12000\n",
      "12160\n",
      "12320\n",
      "12480\n",
      "12640\n",
      "12800\n",
      "12960\n",
      "13120\n",
      "13280\n",
      "13440\n",
      "13600\n",
      "13760\n",
      "13920\n",
      "14080\n",
      "14240\n",
      "14400\n",
      "14560\n",
      "14720\n",
      "14880\n",
      "15040\n",
      "15200\n",
      "15360\n",
      "15520\n",
      "15680\n",
      "15840\n",
      "16000\n",
      "16160\n",
      "16320\n",
      "16480\n",
      "16640\n",
      "16800\n",
      "16960\n",
      "17120\n"
     ]
    }
   ],
   "source": [
    "train__ = train_posts.text.tolist()\n",
    "model.eval()\n",
    "trans_train = predict_batch(model, train__, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_vocab_size = get_vocab_size(trans_train, 3, 128)\n",
    "trans_gram3_train = create_n_grams(trans_train, 3, trans_vocab_size, 128)\n",
    "trans_max_3gram = np.max(trans_gram3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 128, 600)     25560600    ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 128, 600)     25560600    ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 128, 600)     25560600    ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128, 600)     0           ['embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 128, 600)     0           ['embedding_4[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 128, 600)     0           ['embedding_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 126, 500)     900500      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 125, 500)     1200500     ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 124, 500)     1500500     ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 63, 500)     0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 62, 500)     0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 62, 500)     0           ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 31500)        0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 31000)        0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 31000)        0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 93500)        0           ['flatten_3[0][0]',              \n",
      "                                                                  'flatten_4[0][0]',              \n",
      "                                                                  'flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 50)           4675050     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 84,958,350\n",
      "Trainable params: 84,958,350\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "432/432 [==============================] - 36s 84ms/step - loss: 3.4157 - accuracy: 0.1999 - val_loss: 2.9769 - val_accuracy: 0.3375\n",
      "Epoch 2/15\n",
      "432/432 [==============================] - 36s 84ms/step - loss: 2.1766 - accuracy: 0.5357 - val_loss: 1.8308 - val_accuracy: 0.5601\n",
      "Epoch 3/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 1.0984 - accuracy: 0.7745 - val_loss: 1.2582 - val_accuracy: 0.6903\n",
      "Epoch 4/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.5071 - accuracy: 0.9176 - val_loss: 1.0265 - val_accuracy: 0.7418\n",
      "Epoch 5/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.2198 - accuracy: 0.9761 - val_loss: 0.9059 - val_accuracy: 0.7679\n",
      "Epoch 6/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0929 - accuracy: 0.9947 - val_loss: 0.8691 - val_accuracy: 0.7708\n",
      "Epoch 7/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0424 - accuracy: 0.9991 - val_loss: 0.8682 - val_accuracy: 0.7742\n",
      "Epoch 8/15\n",
      "432/432 [==============================] - 36s 84ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.8423 - val_accuracy: 0.7792\n",
      "Epoch 9/15\n",
      "432/432 [==============================] - 36s 84ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.8485 - val_accuracy: 0.7777\n",
      "Epoch 10/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.8484 - val_accuracy: 0.7789\n",
      "Epoch 11/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.8568 - val_accuracy: 0.7826\n",
      "Epoch 12/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8595 - val_accuracy: 0.7861\n",
      "Epoch 13/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8628 - val_accuracy: 0.7826\n",
      "Epoch 14/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8718 - val_accuracy: 0.7858\n",
      "Epoch 15/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8801 - val_accuracy: 0.7849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5a4da8310>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the 3-gram model\n",
    "trans_gram3_model = define_model(128, len(train_posts.authorid.unique()), trans_max_3gram + 1, 600)\n",
    "trans_gram3_model.fit([trans_gram3_train, trans_gram3_train, trans_gram3_train], author_train_hot, epochs=15, batch_size=32, \n",
    "                verbose = 1, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test_posts.text.tolist()\n",
    "model.eval()\n",
    "trans_test = predict_batch(model, test_texts, seed=42)\n",
    "true_values = author_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted scores\n",
      "F1 score for original text: 0.7724860715050913\n",
      "F1 score for transformed text with transformed model: 0.762846199717533\n",
      "F1 score for transformed text with orig model: 0.013651526249251188\n",
      "\n",
      "Macro averaged scores\n",
      "F1 score for original text: 0.7724860715050913\n",
      "F1 score for transformed text with transformed model: 0.762846199717533\n",
      "F1 score for transformed text with orig model: 0.013651526249251186\n"
     ]
    }
   ],
   "source": [
    "preds = gram3_model.predict([gram3_test, gram3_test, gram3_test]).argmax(-1)\n",
    "\n",
    "trans_vocab_size = get_vocab_size(trans_train, 3, 128)\n",
    "trans_gram3_test = create_n_grams(trans_test, 3, trans_vocab_size, 128)\n",
    "trans_preds = trans_gram3_model.predict([trans_gram3_test, trans_gram3_test, trans_gram3_test]).argmax(-1)\n",
    "\n",
    "vocab_size = get_vocab_size(text_train, 3, 128)\n",
    "orig_trans_gram3_test = create_n_grams(trans_test, 3, vocab_size, 128)\n",
    "orig_trans_preds = gram3_model.predict([trans_gram3_test, trans_gram3_test, trans_gram3_test]).argmax(-1)\n",
    "\n",
    "print('Weighted scores')\n",
    "print('F1 score for original text:', f1_score(true_values, preds, average='weighted'))\n",
    "print('F1 score for transformed text with transformed model:', f1_score(true_values, trans_preds, average='weighted'))\n",
    "print('F1 score for transformed text with orig model:', f1_score(true_values, orig_trans_preds, average='weighted'))\n",
    "print()\n",
    "print('Macro averaged scores')\n",
    "print('F1 score for original text:', f1_score(true_values, preds, average='macro'))\n",
    "print('F1 score for transformed text with transformed model:', f1_score(true_values, trans_preds, average='macro'))\n",
    "print('F1 score for transformed text with orig model:', f1_score(true_values, orig_trans_preds, average='macro'))\n",
    "\n",
    "with open('attacker_tests.txt', 'w') as f:\n",
    "    print('Weighted scores', file=f)\n",
    "    print('F1 score for original text:', f1_score(true_values, preds, average='weighted'), file=f)\n",
    "    print('F1 score for transformed text with transformed model:', f1_score(true_values, trans_preds, average='weighted'), file=f)\n",
    "    print('F1 score for transformed text with orig model:', f1_score(true_values, orig_trans_preds, average='weighted'), file=f)\n",
    "    print('', file=f)\n",
    "    print('Macro averaged scores', file=f)\n",
    "    print('F1 score for original text:', f1_score(true_values, preds, average='macro'), file=f)\n",
    "    print('F1 score for transformed text with transformed model:', f1_score(true_values, trans_preds, average='macro'), file=f)\n",
    "    print('F1 score for transformed text with orig model:', f1_score(true_values, orig_trans_preds, average='macro'), file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "attacker_name = 'bert-base-uncased'\n",
    "\n",
    "at_tokenizer = AutoTokenizer.from_pretrained(attacker_name)\n",
    "attacker = AutoModelForSequenceClassification.from_pretrained(attacker_name, num_labels=AUTHOR_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NYAttackDataset(Dataset):\n",
    "    def __init__(self, posts):\n",
    "        docs = posts.text.tolist()\n",
    "        self.inputs = tokenizer(docs, return_tensors=\"pt\", max_length=128, padding='max_length', truncation=True)\n",
    "        self.outputs = posts.authorid.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.outputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.inputs['input_ids'][idx],\n",
    "            'token_type_ids': self.inputs['token_type_ids'][idx],\n",
    "            'attention_mask': self.inputs['attention_mask'][idx],\n",
    "            'targets': self.outputs[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_BATCH_SIZE = 8\n",
    "\n",
    "class LitAttacker(pl.LightningModule):\n",
    "    def __init__(self, model, train, test, learning_rate=1e-3):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # We hardcode dataset specific stuff here.\n",
    "        self.train_dataset = train\n",
    "        self.test_dataset = test\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, **inputs):\n",
    "        return self.model(**inputs)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = {a: b for a, b in batch.items() if a != 'targets'}\n",
    "        y = batch['targets']\n",
    "        outputs = self(**x)\n",
    "        logits = outputs.logits\n",
    "        loss = self.loss_func(logits, y)\n",
    "        \n",
    "        f1 = f1_score(y.cpu(), logits.cpu().argmax(dim=-1), average='weighted')\n",
    "        \n",
    "        self.log(f'train_loss', loss)\n",
    "        self.log(f'avg_train_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log(f'train_f1', f1)\n",
    "        self.log(f'avg_train_f1', f1, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x = {a: b for a, b in batch.items() if a != 'targets'}\n",
    "        y = batch['targets']\n",
    "        outputs = self(**x)\n",
    "        logits = outputs.logits\n",
    "        loss = self.loss_func(logits, y)\n",
    "        \n",
    "        f1 = f1_score(y.cpu(), logits.cpu().argmax(dim=-1), average='weighted')\n",
    "        \n",
    "        self.log(f'val_loss', loss)\n",
    "        self.log(f'avg_val_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log(f'val_f1', f1)\n",
    "        self.log(f'avg_val_f1', f1, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def on_train_batch_end(self, outputs, batch, batch_idx, dataloader_idx):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "#         logger.info(f'Batch train loss {metrics}')\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        print(f'Train loss: {metrics[\"avg_train_loss\"]}')\n",
    "        print(f'Train f1: {metrics[\"avg_train_f1\"]}')\n",
    "\n",
    "    def on_validation_batch_end(self, outputs, batch, batch_idx, dataloader_idx):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "#         logger.info(f'Batch validation loss {metrics}')\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        print(f'Val loss: {metrics[\"avg_val_loss\"]}')\n",
    "        print(f'Val f1: {metrics[\"avg_val_f1\"]}')\n",
    "\n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "\n",
    "#     def prepare_data(self):\n",
    "#         self.data = nn.utils.rnn.pad_sequence(self.data)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            train_size = int(0.9 * len(self.train_dataset))\n",
    "            val_size = len(self.train_dataset) - train_size\n",
    "            self.data_train, self.data_val = random_split(self.train_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.data_test = self.test_dataset\n",
    "\n",
    "        self.loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.data_train, batch_size=BERT_BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.data_val, batch_size=BERT_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.data_test, batch_size=BERT_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "chechpoint_path_attack = \"checkpoints_attack\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:326: LightningDeprecationWarning: Base `LightningModule.on_train_batch_end` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:608: UserWarning: Checkpoint directory /home/jovyan/notebooks/checkpoints_attack exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                          | Params\n",
      "------------------------------------------------------------\n",
      "0 | model     | BertForSequenceClassification | 109 M \n",
      "1 | loss_func | CrossEntropyLoss              | 0     \n",
      "------------------------------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "438.237   Total estimated model params size (MB)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7245212ba9134ae9927c08f2f3b1711c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9567e0fa2ebe4771b01dcef14398dd94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 4.962314605712891\n",
      "Val f1: 0.015269841269841267\n",
      "Train loss: 4.130893707275391\n",
      "Train f1: 0.06327220618887293\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71fe80441c1e4f18b7acb91683e6e68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.488703727722168\n",
      "Val f1: 0.001555555555555556\n",
      "Train loss: 4.376155376434326\n",
      "Train f1: 0.02908244348244362\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52e41a08b8d43f2a1e3c8d06d054a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.70266580581665\n",
      "Val f1: 0.004133333333333334\n",
      "Train loss: 4.236965656280518\n",
      "Train f1: 0.03708091229757897\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad78a6b8c334c28b85cc2d32a7d9a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.495434284210205\n",
      "Val f1: 0.004133333333333334\n",
      "Train loss: 4.1508378982543945\n",
      "Train f1: 0.04244931056597718\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0081b956a8ba41fdba11be15c267bc3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.99934196472168\n",
      "Val f1: 0.004133333333333334\n",
      "Train loss: 4.099645137786865\n",
      "Train f1: 0.04496988135321463\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45397b5c4134d78a71dad0b62df596f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 5.608689308166504\n",
      "Val f1: 0.004133333333333334\n",
      "Train loss: 4.060793399810791\n",
      "Train f1: 0.047400873817540455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:724: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "train_dataset = NYAttackDataset(train_posts)\n",
    "test_dataset = NYAttackDataset(test_posts)\n",
    "attacker_pl = LitAttacker(attacker, train_dataset, test_dataset, 1e-4)\n",
    "attacker_pl.train()\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=chechpoint_path_attack, save_top_k=2, monitor=\"val_loss\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=10,\n",
    "    progress_bar_refresh_rate=20,\n",
    "    gpus=1,\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "trainer.fit(attacker_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacker_pl.stage = 'test'\n",
    "attacker_pl.eval()\n",
    "\n",
    "trainer.test(attacker_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test_posts.text\n",
    "transformed = []\n",
    "model.eval()\n",
    "for i in range(len(test_posts)):\n",
    "    text = test_texts[test_posts.index[i]]\n",
    "    transformed.append(predict(model, text))\n",
    "\n",
    "transformed_test_posts = test_posts.copy()\n",
    "transformed_test_posts.text = transformed\n",
    "transformed_test_dataset = NYAttackDataset(transformed_test_posts)\n",
    "\n",
    "attacker_pl.eval()\n",
    "preds = []\n",
    "transformed_preds = []\n",
    "true_values = []\n",
    "for i in range(len(test_dataset)):\n",
    "    items = test_dataset[i]\n",
    "    x = {a: b.unsqueeze(0) for a, b in items if a != 'targets'}\n",
    "    y = items['targets']\n",
    "    \n",
    "    trans_items = transformed_test_dataset[i]\n",
    "    x_ = {a: b.unsqueeze(0) for a, b in trans_items if a != 'targets'}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = self(**x)\n",
    "        outputs_ = self(**x_)\n",
    "    logits = outputs.logits[0]\n",
    "    pred = logits.argmax(dim=-1)\n",
    "    logits_ = outputs_.logits[0]\n",
    "    pred_ = logits_.argmax(dim=-1)\n",
    "    \n",
    "    preds.append(pred)\n",
    "    transformed_preds.append(pred_)\n",
    "    true_values.apepnd(y)\n",
    "\n",
    "print('Original:', f1_score(true_values, preds, average='weighted'))\n",
    "print('Transformed:', f1_score(true_values, transformed_preds, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
