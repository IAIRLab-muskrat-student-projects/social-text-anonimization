{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–∂–µ—Ç –ø–æ–ª—É—á–∏—Ç—å—Å—è –Ω–∞–π—Ç–∏ –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è —É–º–µ–µ—Ç –ª—É—á—à–µ –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –∞–≤—Ç–æ—Ä–∞ —Ç–µ–∫—Å—Ç–∞ (0.26 —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ) | Done\n",
    "\n",
    "–•–µ—à—Ç–µ–≥–∏:\n",
    "–ë–µ—Ä–µ–º –±–µ—Ä—Ç, –≤—ã—á–∏—Å–ª—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Å–µ—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —É—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ —Ö–µ—à—Ç–µ–≥–∞–º. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞—Ö–æ–¥–∏–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞. –ó–∞–º–µ–Ω—É –∏—â–µ–º –∏–∑ –±–ª–∏–∂–∞–π—à–∏—Ö –ø–æ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–º—É —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é, –Ω–æ —Ç–∞–∫–∂–µ –Ω–µ –±–ª–∏–∑–∫–∏—Ö –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é –ª–µ–≤–µ–Ω—à—Ç–∞–π–Ω–∞.\n",
    "\n",
    "–ü–æ—Å—á–∏—Ç–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –±–µ—Ä—Ç–∞ –Ω–∞ –∑–∞–¥–∞—á–∞—Ö MLM –∏ NSP –¥–ª—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –∏ –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö.\n",
    "–ü–æ—Å—á–∏—Ç–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –∑–∞–¥–∞—á–µ –æ—Ü–µ–Ω–∫–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏. –î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –∏–Ω—Å—Ç—ã –º–æ–∂–µ—Ç –ú–∏—à–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å, –µ—Å—Ç—å –≤ –∏–Ω–µ—Ç–µ —Ç–∞–∫–∂–µ –ø–æ —Ç–≤–∏—Ç—Ç–µ—Ä—É.\n",
    "\n",
    "–ö–∞–∫ –æ—Å—Ç–∞–≤–∏—Ç—å —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –¥—Ä—É–≥–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π? –ó–∞–º–µ–Ω–∏—Ç—å –∏—Ö –≤ —Ç–µ–∫—Å—Ç–µ –Ω–∞ <MASK> –Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ—Ç–æ–º –≤—Å—Ç–∞–≤–∏—Ç—å –Ω–∞ –º–µ—Å—Ç–æ —Ç–æ–∫–µ–Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "eng_stopwords = stopwords.words('english')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import fasttext as ft, Word2Vec\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "import fasttext\n",
    "\n",
    "from cleantext import clean\n",
    "\n",
    "from transformers import (\n",
    "    AutoModel, \n",
    "    AutoModelForMaskedLM,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from transformers import pipeline\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Embedding\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import re\n",
    "from itertools import chain, islice\n",
    "import logging\n",
    "import os\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "from utils import apply_clean, get_text_and_hashtags\n",
    "\n",
    "CORES = 10\n",
    "\n",
    "SEED = 42\n",
    "TRAIN_DOC_COUNT = 10000\n",
    "TEST_DOC_COUNT = 1000\n",
    "AUTHOR_COUNT = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü—Ä–µ–ø–æ—Ü–µ—Å—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö –∏–Ω—Å—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>shortcode</th>\n",
       "      <th>imageurl</th>\n",
       "      <th>isvideo</th>\n",
       "      <th>caption</th>\n",
       "      <th>commentscount</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>likescount</th>\n",
       "      <th>isad</th>\n",
       "      <th>authorid</th>\n",
       "      <th>locationid</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1964932330481107475</td>\n",
       "      <td>BtE14s-AcIT</td>\n",
       "      <td>https://scontent-frt3-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>f</td>\n",
       "      <td>Right or Left?\\n\\nBuffalo Chicken slice on the...</td>\n",
       "      <td>51</td>\n",
       "      <td>1548458208</td>\n",
       "      <td>2126</td>\n",
       "      <td>f</td>\n",
       "      <td>4640452414</td>\n",
       "      <td>1000622863426414</td>\n",
       "      <td>40.743070</td>\n",
       "      <td>-73.694770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1964802706070998220</td>\n",
       "      <td>BtEYaa1FozM</td>\n",
       "      <td>https://scontent-dfw5-2.cdninstagram.com/v/t51...</td>\n",
       "      <td>t</td>\n",
       "      <td>Friday‚Äôs at the office just got a little sweet...</td>\n",
       "      <td>1</td>\n",
       "      <td>1548443178</td>\n",
       "      <td>21</td>\n",
       "      <td>f</td>\n",
       "      <td>8486247913</td>\n",
       "      <td>399742559</td>\n",
       "      <td>40.645130</td>\n",
       "      <td>-74.283580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1964602177319379865</td>\n",
       "      <td>BtDq0V4FKOZ</td>\n",
       "      <td>https://scontent-vie1-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>f</td>\n",
       "      <td>The early bird gets the best sunrise pics.</td>\n",
       "      <td>2</td>\n",
       "      <td>1548418851</td>\n",
       "      <td>84</td>\n",
       "      <td>f</td>\n",
       "      <td>185562852</td>\n",
       "      <td>1002106456</td>\n",
       "      <td>40.725690</td>\n",
       "      <td>-74.004870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1964909162908823712</td>\n",
       "      <td>BtEwnkfFzCg</td>\n",
       "      <td>https://scontent-vie1-1.cdninstagram.com/v/t51...</td>\n",
       "      <td>f</td>\n",
       "      <td>Poor Cyndy!  This superstar massage therapist ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1548455447</td>\n",
       "      <td>20</td>\n",
       "      <td>f</td>\n",
       "      <td>247991751</td>\n",
       "      <td>1003846026</td>\n",
       "      <td>40.839720</td>\n",
       "      <td>-74.277380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1964909473806010794</td>\n",
       "      <td>BtEwsGCAcmq</td>\n",
       "      <td>https://instagram.fprg2-1.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>f</td>\n",
       "      <td>he hit the booty like a drum, yumyum.üòÄ why he ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1548455484</td>\n",
       "      <td>11</td>\n",
       "      <td>f</td>\n",
       "      <td>8102841338</td>\n",
       "      <td>1007014</td>\n",
       "      <td>40.747681</td>\n",
       "      <td>-73.987358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id    shortcode  \\\n",
       "0  1964932330481107475  BtE14s-AcIT   \n",
       "1  1964802706070998220  BtEYaa1FozM   \n",
       "2  1964602177319379865  BtDq0V4FKOZ   \n",
       "3  1964909162908823712  BtEwnkfFzCg   \n",
       "4  1964909473806010794  BtEwsGCAcmq   \n",
       "\n",
       "                                            imageurl isvideo  \\\n",
       "0  https://scontent-frt3-2.cdninstagram.com/v/t51...       f   \n",
       "1  https://scontent-dfw5-2.cdninstagram.com/v/t51...       t   \n",
       "2  https://scontent-vie1-1.cdninstagram.com/v/t51...       f   \n",
       "3  https://scontent-vie1-1.cdninstagram.com/v/t51...       f   \n",
       "4  https://instagram.fprg2-1.fna.fbcdn.net/v/t51....       f   \n",
       "\n",
       "                                             caption  commentscount  \\\n",
       "0  Right or Left?\\n\\nBuffalo Chicken slice on the...             51   \n",
       "1  Friday‚Äôs at the office just got a little sweet...              1   \n",
       "2         The early bird gets the best sunrise pics.              2   \n",
       "3  Poor Cyndy!  This superstar massage therapist ...              0   \n",
       "4  he hit the booty like a drum, yumyum.üòÄ why he ...              0   \n",
       "\n",
       "    timestamp  likescount isad    authorid        locationid        lat  \\\n",
       "0  1548458208        2126    f  4640452414  1000622863426414  40.743070   \n",
       "1  1548443178          21    f  8486247913         399742559  40.645130   \n",
       "2  1548418851          84    f   185562852        1002106456  40.725690   \n",
       "3  1548455447          20    f   247991751        1003846026  40.839720   \n",
       "4  1548455484          11    f  8102841338           1007014  40.747681   \n",
       "\n",
       "         lon  \n",
       "0 -73.694770  \n",
       "1 -74.283580  \n",
       "2 -74.004870  \n",
       "3 -74.277380  \n",
       "4 -73.987358  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['shortcode', 'caption', 'authorid', 'timestamp']\n",
    "\n",
    "nyc_posts_df = pd.read_csv('/mnt/ess_storage/DN_1/storage/home/vpanov/instagram_posts/data/nyc_posts_2019.csv', nrows=10000000)\n",
    "nyc_posts_df = nyc_posts_df.dropna(axis=0)\n",
    "nyc_posts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_posts_df_march = nyc_posts_df[(nyc_posts_df.timestamp >= 1551398400) & (nyc_posts_df.timestamp <= 1553990400)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1546300802, 1577750398)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_posts_df['timestamp'].min(), nyc_posts_df['timestamp'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_posts_df = nyc_posts_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2422245"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nyc_posts_df['authorid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2422245"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nyc_posts_df['authorid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215811234     405\n",
       "31033532      404\n",
       "581325206     404\n",
       "6612357200    404\n",
       "2206015241    403\n",
       "             ... \n",
       "7370266134    374\n",
       "2048298231    374\n",
       "1303589730    374\n",
       "6160517766    373\n",
       "1291658614    373\n",
       "Name: authorid, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –±–µ—Ä—É –∞–≤—Ç–æ—Ä–æ–≤ –Ω–µ –∏–∑ —Ç–æ–ø–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—É–±–ª–∏–∫–∞—Ü–∏–π, –ø–æ—Ç–æ–º—É —á—Ç–æ –≤ —Ç–æ–ø–µ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è —Ä–µ–∫–ª–∞–º–Ω—ã–µ –∞–∫–∫–∞—É–Ω—Ç—ã\n",
    "offset = 500\n",
    "nyc_posts_df['authorid'].value_counts()[offset:offset+AUTHOR_COUNT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortcode</th>\n",
       "      <th>caption</th>\n",
       "      <th>authorid</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4948208</th>\n",
       "      <td>BxukN2rHPbE</td>\n",
       "      <td>Modern heirlooms for the modern woman @foundra...</td>\n",
       "      <td>181922576</td>\n",
       "      <td>1558448165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4396455</th>\n",
       "      <td>ByA70V0Aoch</td>\n",
       "      <td>Need to get your brain recharged after the hol...</td>\n",
       "      <td>4529154010</td>\n",
       "      <td>1559064519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9020890</th>\n",
       "      <td>B0DtBE6nC0n</td>\n",
       "      <td>Today's specials!  Come out of the rain and en...</td>\n",
       "      <td>9059101974</td>\n",
       "      <td>1563452389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5729673</th>\n",
       "      <td>BsGwlNDgxQf</td>\n",
       "      <td>First #run of the #newyear done! #workoutevery...</td>\n",
       "      <td>1220954110</td>\n",
       "      <td>1546375052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6363897</th>\n",
       "      <td>B2g7DemjkYM</td>\n",
       "      <td>Tomorrow night live @techyfatule @sobsnyc @pab...</td>\n",
       "      <td>3185099171</td>\n",
       "      <td>1568727795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           shortcode                                            caption  \\\n",
       "4948208  BxukN2rHPbE  Modern heirlooms for the modern woman @foundra...   \n",
       "4396455  ByA70V0Aoch  Need to get your brain recharged after the hol...   \n",
       "9020890  B0DtBE6nC0n  Today's specials!  Come out of the rain and en...   \n",
       "5729673  BsGwlNDgxQf  First #run of the #newyear done! #workoutevery...   \n",
       "6363897  B2g7DemjkYM  Tomorrow night live @techyfatule @sobsnyc @pab...   \n",
       "\n",
       "           authorid   timestamp  \n",
       "4948208   181922576  1558448165  \n",
       "4396455  4529154010  1559064519  \n",
       "9020890  9059101974  1563452389  \n",
       "5729673  1220954110  1546375052  \n",
       "6363897  3185099171  1568727795  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_productive_authors = nyc_posts_df['authorid'].value_counts()[offset:offset+AUTHOR_COUNT].index.values\n",
    "nyc_posts_authors_df = nyc_posts_df[nyc_posts_df.authorid.isin(most_productive_authors)].sample(frac=1.0, random_state=SEED)\n",
    "nyc_posts_authors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_posts_authors_df.caption = nyc_posts_authors_df.caption.apply(apply_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortcode</th>\n",
       "      <th>caption</th>\n",
       "      <th>authorid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4948208</th>\n",
       "      <td>BxukN2rHPbE</td>\n",
       "      <td>modern heirlooms for the modern woman @foundra...</td>\n",
       "      <td>181922576</td>\n",
       "      <td>1558448165</td>\n",
       "      <td>modern heirlooms for the modern woman @foundrae</td>\n",
       "      <td>#foundrae #finejewelry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4396455</th>\n",
       "      <td>ByA70V0Aoch</td>\n",
       "      <td>need to get your brain recharged after the hol...</td>\n",
       "      <td>4529154010</td>\n",
       "      <td>1559064519</td>\n",
       "      <td>need to get your brain recharged after the hol...</td>\n",
       "      <td>#trivia #pubquiz #trivianight #bedstuyquiz #be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9020890</th>\n",
       "      <td>B0DtBE6nC0n</td>\n",
       "      <td>today's specials! come out of the rain and enj...</td>\n",
       "      <td>9059101974</td>\n",
       "      <td>1563452389</td>\n",
       "      <td>today's specials! come out of the rain and enj...</td>\n",
       "      <td>#food #seeyouagain #breakfast #loveofgrub #are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5729673</th>\n",
       "      <td>BsGwlNDgxQf</td>\n",
       "      <td>first #run of the #newyear done! #workoutevery...</td>\n",
       "      <td>1220954110</td>\n",
       "      <td>1546375052</td>\n",
       "      <td>first  of the  done!  january challenge is in ...</td>\n",
       "      <td>#run #newyear #workouteveryday #fitnessislife ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6363897</th>\n",
       "      <td>B2g7DemjkYM</td>\n",
       "      <td>tomorrow night live @techyfatule @sobsnyc @pab...</td>\n",
       "      <td>3185099171</td>\n",
       "      <td>1568727795</td>\n",
       "      <td>tomorrow night live @techyfatule @sobsnyc @pab...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           shortcode                                            caption  \\\n",
       "4948208  BxukN2rHPbE  modern heirlooms for the modern woman @foundra...   \n",
       "4396455  ByA70V0Aoch  need to get your brain recharged after the hol...   \n",
       "9020890  B0DtBE6nC0n  today's specials! come out of the rain and enj...   \n",
       "5729673  BsGwlNDgxQf  first #run of the #newyear done! #workoutevery...   \n",
       "6363897  B2g7DemjkYM  tomorrow night live @techyfatule @sobsnyc @pab...   \n",
       "\n",
       "           authorid   timestamp  \\\n",
       "4948208   181922576  1558448165   \n",
       "4396455  4529154010  1559064519   \n",
       "9020890  9059101974  1563452389   \n",
       "5729673  1220954110  1546375052   \n",
       "6363897  3185099171  1568727795   \n",
       "\n",
       "                                                      text  \\\n",
       "4948208    modern heirlooms for the modern woman @foundrae   \n",
       "4396455  need to get your brain recharged after the hol...   \n",
       "9020890  today's specials! come out of the rain and enj...   \n",
       "5729673  first  of the  done!  january challenge is in ...   \n",
       "6363897  tomorrow night live @techyfatule @sobsnyc @pab...   \n",
       "\n",
       "                                                  hashtags  \n",
       "4948208                             #foundrae #finejewelry  \n",
       "4396455  #trivia #pubquiz #trivianight #bedstuyquiz #be...  \n",
       "9020890  #food #seeyouagain #breakfast #loveofgrub #are...  \n",
       "5729673  #run #newyear #workouteveryday #fitnessislife ...  \n",
       "6363897                                                     "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –¥–µ–ª—é –Ω–∞ —Ç–µ–∫—Å—Ç –∏ —Ö—ç—à—Ç–µ–≥–∏ –æ—Ç–¥–µ–ª—å–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É—é —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç\n",
    "nyc_posts_authors_df[['text', 'hashtags']] = nyc_posts_authors_df.apply(get_text_and_hashtags, axis=1, result_type='expand')\n",
    "nyc_posts_authors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38795"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nyc_posts_authors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25901"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nyc_posts_authors_df[nyc_posts_authors_df.text.str.len() > 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nyc_posts_authors_df[nyc_posts_authors_df.text.str.len() > 50].authorid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10579934087    403\n",
       "182549672      399\n",
       "1706798002     398\n",
       "2112186305     392\n",
       "10198719       392\n",
       "1795862337     392\n",
       "2040926754     391\n",
       "215811234      389\n",
       "477908643      386\n",
       "270846038      386\n",
       "643127146      385\n",
       "2421664219     383\n",
       "1317549717     382\n",
       "299818632      382\n",
       "228791166      381\n",
       "480519937      380\n",
       "7291939241     379\n",
       "340711336      378\n",
       "582872531      377\n",
       "2906490331     375\n",
       "4978535758     375\n",
       "1303589730     373\n",
       "1291658614     373\n",
       "1814837251     373\n",
       "1411792405     373\n",
       "9059101974     372\n",
       "10192579486    372\n",
       "655934981      370\n",
       "4529154010     369\n",
       "31033532       368\n",
       "450551504      366\n",
       "3165744688     365\n",
       "6612357200     364\n",
       "7624638307     361\n",
       "581325206      358\n",
       "257267175      356\n",
       "3282508444     351\n",
       "39037837       349\n",
       "21452784       346\n",
       "1514849890     342\n",
       "213882856      340\n",
       "3050309989     330\n",
       "1125451713     329\n",
       "4473522466     327\n",
       "488134907      316\n",
       "6160517766     314\n",
       "32219305       314\n",
       "1920983937     312\n",
       "217402170      310\n",
       "4334476665     305\n",
       "Name: authorid, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_posts_authors_df[nyc_posts_authors_df.text.str.len() > 50].authorid.value_counts()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_authors = 50\n",
    "least_long = 50\n",
    "\n",
    "long_posts = nyc_posts_authors_df[nyc_posts_authors_df.text.str.len() > least_long]\n",
    "authors_posts_count = long_posts.authorid.value_counts()\n",
    "authors = authors_posts_count[:max_authors].index.tolist()\n",
    "min_posts = authors_posts_count.values[max_authors - 1]\n",
    "median_posts = int(authors_posts_count.median())\n",
    "\n",
    "train_posts = []\n",
    "test_posts = []\n",
    "\n",
    "for i in authors:\n",
    "    author_i_posts = nyc_posts_authors_df[(nyc_posts_authors_df.text.str.len() > least_long) & (nyc_posts_authors_df.authorid == i)]\n",
    "    l = len(author_i_posts)\n",
    "    train_posts.append(author_i_posts[:l - 20])\n",
    "    test_posts.append(author_i_posts[l - 20:])\n",
    "\n",
    "train_posts = pd.concat(train_posts).sample(frac=1.0, random_state=SEED)\n",
    "test_posts = pd.concat(test_posts).sample(frac=1.0, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û—Ü–µ–Ω–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–æ—Å—Ç–æ–≤ –ø–æ —è–∑—ã–∫–∞–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "lang_ft = fasttext.load_model('/mnt/ess_storage/DN_1/storage/home/vpanov/lang/lid.176.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_func(text):\n",
    "    return lang_ft.predict(apply_clean(text), k=1)[0][0][9:]\n",
    "\n",
    "nyc_posts_df_march['lang'] = nyc_posts_df_march.caption.apply(lang_func)\n",
    "\n",
    "from collections import Counter\n",
    "c = Counter(nyc_posts_df_march.lang.tolist())\n",
    "# c.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('en', 629351),\n",
       " ('es', 21942),\n",
       " ('pt', 5341),\n",
       " ('fr', 4182),\n",
       " ('it', 3624),\n",
       " ('de', 3087),\n",
       " ('nl', 1451),\n",
       " ('ja', 1239),\n",
       " ('zh', 1134),\n",
       " ('sv', 1059)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11270"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(num for lang, num in c.items() if num < 1059)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_func(text):\n",
    "    return lang_ft.predict(text, k=1)[0][0][9:]\n",
    "\n",
    "train_posts['lang'] = train_posts.caption.apply(lang_func)\n",
    "test_posts['lang'] = test_posts.caption.apply(lang_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('en', 17900), ('pt', 237), ('es', 127), ('de', 5), ('it', 1), ('hu', 1)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c = Counter(train_posts.lang.tolist()) + Counter(test_posts.lang.tolist())\n",
    "c.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç—Ä–µ–π–Ω-—Ç–µ—Å—Ç –≤—ã–±–æ—Ä–æ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_authors = 50\n",
    "least_long = 50\n",
    "\n",
    "long_posts = nyc_posts_authors_df[nyc_posts_authors_df.text.str.len() > least_long]\n",
    "authors_posts_count = long_posts.authorid.value_counts()\n",
    "authors = authors_posts_count[:max_authors].index.tolist()\n",
    "min_posts = authors_posts_count.values[max_authors - 1]\n",
    "median_posts = int(authors_posts_count.median())\n",
    "\n",
    "train_posts = []\n",
    "test_posts = []\n",
    "\n",
    "for i in authors:\n",
    "    author_i_posts = nyc_posts_authors_df[(nyc_posts_authors_df.text.str.len() > least_long) & (nyc_posts_authors_df.authorid == i)]\n",
    "    l = len(author_i_posts)\n",
    "    train_posts.append(author_i_posts[:l - 20])\n",
    "    test_posts.append(author_i_posts[l - 20:])\n",
    "\n",
    "train_posts = pd.concat(train_posts).sample(frac=1.0, random_state=SEED)\n",
    "test_posts = pd.concat(test_posts).sample(frac=1.0, random_state=SEED)\n",
    "\n",
    "train_posts.to_csv('/home/jovyan/notebooks/vk/train_posts.csv', index=None)\n",
    "test_posts.to_csv('/home/jovyan/notebooks/vk/test_posts.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text anonymization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SynTF method\n",
    "–º–µ—Ç–æ–¥ –Ω–µ –º–æ–π, –ø–æ—á–∏—Ç–∞—Ç—å –ø—Ä–æ –Ω–µ–≥–æ –º–æ–∂–Ω–æ —Ç—É—Ç https://arxiv.org/abs/1805.00904\n",
    "\n",
    "–µ—Å–ª–∏ –∫—Ä–∞—Ç–∫–æ, —Ç–æ —Ç—É—Ç –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è tfidf –≤–µ–∫—Ç–æ—Ä–∞, —á—Ç–æ–±—ã –≤—ã—á–∏—Å–ª–∏—Ç—å —á–∞—Å—Ç–æ—Ç—ã –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤, –∑–∞—Ç–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ–∫—Ç–æ—Ä–æ–≤ –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –Ω–æ–≤—ã–µ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç—Å—è –≤ tfidf –≤–µ–∫—Ç–æ—Ä–∞\n",
    "\n",
    "—Ç–æ–ª—å–∫–æ –≤ —ç—Ç–æ–º –∫–æ–¥–µ –≤—Ç–æ—Ä–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ tfidf –≤–µ–∫—Ç–æ—Ä –Ω–µ –¥–µ–ª–∞–µ—Ç—Å—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SYNSETS = False\n",
    "TEXT_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_docs = train_posts['text'].tolist()\n",
    "original_docs.extend(test_posts['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'@\\w+', ' ', text.lower())\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    words = text.split()\n",
    "    words = filter(lambda x: x not in eng_stopwords, words)\n",
    "    return ' '.join(lemmatizer.lemmatize(x) for x in words)\n",
    "\n",
    "def get_synonyms(uniq_words):\n",
    "    all_synonyms = set()\n",
    "    for word in uniq_words:\n",
    "        synonyms = wordnet.synsets(word)\n",
    "        all_synonyms.update(chain.from_iterable([word.lemma_names() for word in synonyms]))\n",
    "    return all_synonyms\n",
    "\n",
    "docs = [preprocess(doc) for doc in original_docs]\n",
    "if USE_SYNSETS:\n",
    "    uniq_words = set(chain.from_iterable([doc.split() for doc in docs]))\n",
    "    synonyms = ' '.join(get_synonyms(uniq_words))\n",
    "    docs_with_synonyms = [*docs, synonyms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "if USE_SYNSETS:\n",
    "    tfidf.fit(docs_with_synonyms)\n",
    "else:\n",
    "    tfidf.fit(docs)\n",
    "doc_vecs = tfidf.transform(docs)\n",
    "doc_vecs = normalize(doc_vecs, norm='l1')\n",
    "words = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_vecs(docs, use_synsets=USE_SYNSETS, vocabulary=None):\n",
    "    tfidf = TfidfVectorizer(vocabulary=vocabulary, norm='l1')\n",
    "    if use_synsets:\n",
    "        tfidf.fit(docs_with_synonyms)\n",
    "    else:\n",
    "        tfidf.fit(docs)\n",
    "    doc_vecs = tfidf.transform(docs)\n",
    "    return doc_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21397"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = ft.load_facebook_model(datapath('/mnt/ess_storage/DN_1/storage/home/vpanov/cc.en.300.bin.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21397, 21397)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vecs = [ft.wv[word] for word in words]\n",
    "word_similarities = cosine_similarity(word_vecs, word_vecs)\n",
    "word_similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kgram_overlap(word1, word2, k):\n",
    "    a = set([word1[i:i+k] for i in range(0, len(word1) - k + 1)])\n",
    "    b = set([word2[i:i+k] for i in range(0, len(word2) - k + 1)])\n",
    "    inter = len(a.intersection(b))\n",
    "    return inter / (len(a) + len(b) - inter)\n",
    "\n",
    "def score(word1, word2):\n",
    "    idx1, idx2 = tfidf.vocabulary_[word1], tfidf.vocabulary_[word2]\n",
    "    return word_similarities[idx1, idx2] - 0.3 * kgram_overlap(word1, word2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://programming-dp.com/notebooks/ch9.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endometriosis ['soooo']\n"
     ]
    }
   ],
   "source": [
    "def exponential_gen(x, R, u, sensitivity=1, epsilon=25.4):\n",
    "    # Calculate the score for each element of R\n",
    "    scores = [u(x, r) for r in R]\n",
    "    \n",
    "    # Calculate the probability for each element, based on its score\n",
    "    probabilities = [np.exp(epsilon * score / (2 * sensitivity)) for score in scores]\n",
    "    \n",
    "    # Normalize the probabilties so they sum to 1\n",
    "    probabilities = probabilities / np.linalg.norm(probabilities, ord=1)\n",
    "\n",
    "    # Choose an element from R based on the probabilities\n",
    "    return np.random.choice(R, 1, p=probabilities)\n",
    "\n",
    "num = 7000\n",
    "print(words[num], exponential_gen(words[num], words, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd574a01b7e24956991765f8e0782826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(21397, 21397)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exponential(x, R, u, sensitivity=1, epsilon=25.4):\n",
    "    # Calculate the score for each element of R\n",
    "    scores = [u(x, r) for r in R]\n",
    "    \n",
    "    # Calculate the probability for each element, based on its score\n",
    "    probabilities = [np.exp(epsilon * score / (2 * sensitivity)) for score in scores]\n",
    "    \n",
    "    # Normalize the probabilties so they sum to 1\n",
    "    probabilities = probabilities / np.linalg.norm(probabilities, ord=1)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "word_replace_probs = []\n",
    "\n",
    "for word in tqdm(words):\n",
    "    word_replace_probs.append(exponential(word, words, score))\n",
    "\n",
    "word_replace_probs = np.array(word_replace_probs)\n",
    "word_replace_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--ORIGINAL--\n",
      "Right or Left?\n",
      "\n",
      "Buffalo Chicken slice on the right and Chicken, Bacon(beef), Ranch on the left from @saucny, all new halal pizza spot in New Hyde Park.\n",
      "--PREPROCESSED--\n",
      "right left buffalo chicken slice right chicken bacon beef ranch left new halal pizza spot new hyde park\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "freshwater bend fish horn lyndhurst cabbage placed rice priestley proof goat rippon bacon inside pork nearby spot though\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "Poor Cyndy!  This superstar massage therapist had to endure an hour of Amy's special playlist with The Sky treatment to break a 4 day cuckoo migraine.  Wow, this treatment works!  But, Cyndy will never ever want to listen to Pearl Jam, DMB or REM again.\n",
      "--PREPROCESSED--\n",
      "poor cyndy superstar massage therapist endure hour amy special playlist sky treatment break 4 day cuckoo migraine wow treatment work cyndy never ever want listen pearl jam dmb rem\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "spray elizabeth falling karen occasion atlanta visited soft revamped heidi superstar else crush tech scott blue elizabeth nice folklore kitt edwin programing tmn defiantly waking rosie drummer twelve product\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "he hit the booty like a drum, yumyum.üòÄ why he wanna stutter and he know he wanna butter my buns and have all of my sons. got them young and old like yang hyun suk and bang yong guk and my baby knows how to cook, red suit,  korean look.  startin all them trends in the mercedes benz playin that kpop, that jrock, i'm playin with that cüêàüêìk he likes a chick that plays wu tang that's how we bang, loves to talk slang knows how to freestyle knows how to get buckwild. he's a little bit of bruce lee doin karate, he a hottie he pulls out the shottie and we keep it sexual, also intellectual they askin what the dragon  do! üêâüî•üî•üî•                   üçéüçè          üòò‚õ≤üòúüí±üì≥üåÉüíöüí´\n",
      "--PREPROCESSED--\n",
      "hit booty like drum yumyum wanna stutter know wanna butter bun son got young old like yang hyun suk bang yong guk baby know cook red suit korean look startin trend mercedes benz playin kpop jrock playin c k like chick play wu tang bang love talk slang know freestyle know get buckwild little bit bruce lee doin karate hottie pull shottie keep sexual also intellectual askin dragon\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "jen strangely booty dj bruce pulling ndido guk intellectual infant whine garlic alright ssi hackensack slang let nicole heavy blvd heat samantha stutter look giant husband jummah ure bagel everywhere bjj echt enrichment second mater charming hell trans rts adversity push uch sobre new chunky true zou pointed verlo streammiter rhd conozcas sportin girl nenhum farm ah medical seriously tof little firsties sky naomi suk cheryl bit key\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "First cocktail of the day ‚Äî Three Hearts ‚Äî featuring Kansas distilled spirit. And our bartender just finished writing her first play.\n",
      "--PREPROCESSED--\n",
      "first cocktail day three heart featuring kansa distilled spirit bartender finished writing first play\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "twice fourth summer timing kansa finishing allowing second seven includes snack clase unfinished named\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "Just a week away we are welcoming all the youth from ages 14-18 !!! Let us start this year with God !\n",
      "--PREPROCESSED--\n",
      "week away welcoming youth age 14 18 let u start year god\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "34 23 welcoming god joyous hating pursuing adult month 30 true announcing\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for idx, doc in enumerate(docs[:5]):\n",
    "    print('--ORIGINAL--')\n",
    "    print(original_docs[original_docs.index[idx]])\n",
    "    print('--PREPROCESSED--')\n",
    "    print(doc)\n",
    "    print('--GENERATED SEQUENCE (WITHOUT WORD ORDER)--')\n",
    "    words_count = len(doc.split())\n",
    "    words_ = np.random.choice(words, words_count, p=doc_vecs[idx].todense().tolist()[0])\n",
    "    for i in range(words_count):\n",
    "        word_idx = tfidf.vocabulary_[words_[i]]\n",
    "        words_[i] = np.random.choice(words, 1, p=word_replace_probs[word_idx])[0]\n",
    "    print(' '.join(words_))\n",
    "    print('-'*150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymize(doc, doc_vec):\n",
    "    p = doc_vec.todense()\n",
    "    p = p / np.linalg.norm(p, ord=1)\n",
    "    words_count = len(doc.split())\n",
    "    words_ = np.random.choice(words, words_count, p=doc_vec.todense().tolist()[0])\n",
    "    for i in range(words_count):\n",
    "        word_idx = tfidf.vocabulary_[words_[i]]\n",
    "        words_[i] = np.random.choice(words, 1, p=word_replace_probs[word_idx])[0]\n",
    "    return ' '.join(words_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ER-AE\n",
    "\n",
    "–≤ –ø—Ä–∏–Ω—Ü–∏–ø–µ —ç—Ç–æ –∏ –µ—Å—Ç—å mucaat: –∑–∞ –æ—Å–Ω–æ–≤—É –≤–∑—è—Ç –º–µ—Ç–æ–¥ [ER-AE](https://arxiv.org/abs/1907.08736), –Ω–æ —Å –∞–¥–∞–ø—Ç–∞—Ü–∏–µ–π –ø–æ–¥ —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏, –ø–æ–¥—Ä–æ–±–Ω–µ–µ –≤ —Å—Ç–∞—Ç—å–µ [mucaat](https://www.sciencedirect.com/science/article/pii/S1877050922017070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å\n",
    "model_name = 'distilbert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bert = AutoModel.from_pretrained(model_name, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 146, 11850, 24109, 15703, 119, 12689, 72894, 11268, 119, 102] [CLS] I like pigs. And apples. [SEP]\n",
      "[101, 177, 11850, 24109, 15703, 119, 10111, 72894, 11268, 119, 102] [CLS] i like pigs. and apples. [SEP]\n",
      "[101, 177, 11850, 24109, 15703, 119, 10111, 72894, 11268, 119, 102] [CLS] i like pigs. and apples. [SEP]\n"
     ]
    }
   ],
   "source": [
    "# –ø—Ä–æ—Å—Ç–æ —á–µ–∫–∞—é –µ—Å—Ç—å –ª–∏ —Ä–∞–∑–ª–∏—á–∏–µ –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏ —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤–æ–π –∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ\n",
    "print(tokenizer.encode('I like pigs. And apples.'), tokenizer.decode(tokenizer.encode('I like pigs. And apples.')))\n",
    "print(tokenizer.encode('i like pigs. and apples.'), tokenizer.decode(tokenizer.encode('i like pigs. and apples.')))\n",
    "print(tokenizer.encode('i like pigs . and apples .'), tokenizer.decode(tokenizer.encode('i like pigs . and apples .')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –Ω–∞—Ö–æ–∂—É –∫–∞–∫–∏–µ –µ—Å—Ç—å —Ç–æ–∫–µ–Ω—ã –≤ —Å–ª–æ–≤–∞—Ä–µ –º–æ–¥–µ–ª–∏\n",
    "\n",
    "def get_words(doc):\n",
    "    doc = tokenizer.decode(tokenizer.encode(doc, max_length=128, padding='max_length', truncation=True))\n",
    "#     doc = tokenizer.decode(tokenizer.encode(doc))\n",
    "    doc = re.sub(r'([\\.,\\'‚Äô\\\"\\-!\\?\\(\\)])', r' \\1 ', doc)\n",
    "    doc = re.sub('\\s', ' ', doc)\n",
    "    return doc.split()\n",
    "\n",
    "unique_tokens = set(chain.from_iterable([*train_posts.text.apply(get_words).tolist(),\n",
    "                                       *test_posts.text.apply(get_words).tolist()]))\n",
    "\n",
    "token2idx = {token: idx for idx, token in enumerate(unique_tokens)}\n",
    "idx2token = {idx: token for idx, token in enumerate(unique_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_TOKEN_ID = token2idx['[CLS]']\n",
    "EOS_TOKEN_ID = token2idx['[SEP]']\n",
    "PAD_TOKEN_ID = token2idx['[PAD]']\n",
    "\n",
    "VOCAB_SIZE = len(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26641"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# —É—Å—Ä–µ–¥–Ω—è—é –Ω–µ—Å–∫–æ–ª—å–∫–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤, –æ—Ç–Ω–æ—Å—è—â–∏—Ö—Å—è –∫ —Ç–æ–∫–µ–Ω–∞–º –æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞, –≤ –æ–¥–∏–Ω —ç–º–±–µ–¥–¥–∏–Ω–≥\n",
    "\n",
    "def get_word_idx(sent: str, word: str):\n",
    "    return sent.split(\" \").index(word)\n",
    "\n",
    "def get_hidden_states(encoded, token_ids_words, model, layers):\n",
    "    \"\"\"Push input IDs through model. Stack and sum `layers` (last four by default).\n",
    "        Select only those subword token outputs that belong to our word of interest\n",
    "        and average them.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded)\n",
    " \n",
    "    # Get all hidden states\n",
    "    states = output.hidden_states\n",
    "    # Stack and sum all requested layers\n",
    "    output = torch.stack([states[i] for i in layers]).sum(0).squeeze()\n",
    "    res = []\n",
    "    labels_count = []\n",
    "    \n",
    "    for idx, (outp, label) in enumerate(zip(output, token_ids_words)):\n",
    "        if label is None or token_ids_words[idx - 1] is None or token_ids_words[idx - 1] != token_ids_words[idx]:\n",
    "            res.append(outp)\n",
    "            labels_count.append(1)\n",
    "        else: \n",
    "            res[-1] += outp\n",
    "            labels_count[-1] += 1\n",
    "    res = torch.vstack(res)\n",
    "    res = res / torch.tensor(labels_count).float().unsqueeze(1)\n",
    " \n",
    "    return res\n",
    "\n",
    "\n",
    "def get_word_vectors(sent, tokenizer, model, layers):\n",
    "    \"\"\"Get a word vector by first tokenizing the input sentence, getting all token idxs\n",
    "        that make up the word of interest, and then `get_hidden_states`.\"\"\"\n",
    "    encoded = tokenizer.encode_plus(sent, return_tensors=\"pt\", max_length=128, padding='max_length', truncation=True)\n",
    "    return get_hidden_states(encoded, encoded.word_ids(), model, layers)\n",
    "\n",
    "\n",
    "def exmpl(layers=None):\n",
    "    # Use last four layers by default\n",
    "    layers = [-4, -3, -2, -1] if layers is None else layers\n",
    "\n",
    "    sent = train_posts.text[train_posts.index[23]]\n",
    "\n",
    "    word_embedding = get_word_vectors(sent, tokenizer, bert, layers)\n",
    "\n",
    "    return word_embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exmpl().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "['[CLS]', 'outpour', 'is', 'here', 'all', 'the', 'vlogs', 'led', 'us', 'to', 'this', '!', 'you', 'don', \"'\", 't', 'want', 'to', 'miss', 'what', 'we', 'have', 'prepared', 'for', 'you', '.', 'come', 'expecting', '!', 'doors', 'open', 'at', '6', ':', '30pm', ',', 'come', 'early', 'and', 'get', 'our', 'new', 'merch', 'at', 'the', 'pop', 'up', 'shop', '!', 'special', 'guests', ':', '@', 'havilahcunnington', '@', 'annagoldenmusic', '@', 'waynefrancis', '@', 'degroves', 'wednesday', '/', '/', '7pm', 'thursday', '/', '/', '7pm', 'friday', '/', '/', '7pm', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (97) must match the existing size (98) at non-singleton dimension 0.  Target sizes: [97, 768].  Tensor sizes: [98, 1]\n",
      "688\n",
      "['[CLS]', 'help', 'barc', 'out', '!', '!', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', 'for', 'next', '15', 'days', 'only', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (114) must match the existing size (115) at non-singleton dimension 0.  Target sizes: [114, 768].  Tensor sizes: [115, 1]\n",
      "1054\n",
      "['[CLS]', 'come', 'check', 'out', 'my', 'day', 'time', 'bar', 'star', '@', 'andrellamaringa', 'as', 'she', 'create', 'her', 'signature', 'cocktails', '@', 'chefdomcreates', '@', 'larouge', '_', 'restaurant', '_', 'lounge', 'we', 'don', \"'\", 't', 'own', 'the', 'rights', 'to', 'this', 'song', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (116) must match the existing size (117) at non-singleton dimension 0.  Target sizes: [116, 768].  Tensor sizes: [117, 1]\n",
      "1294\n",
      "['[CLS]', '1', 'more', 'days', 'till', 'the', 'biggest', 'birthday', 'celebration', '@', 'empireloungenj', '@', 'chefdomcreates', '@', 'unclevinrock', '@', 'larouge', '_', 'restaurant', '_', 'lounge', '@', 'sa', '_', 'kye', '_', 'dom', '@', 'djsupadice', '@', 'mrdjovaflow', '@', 'judexmrgoodlife', 'chef', 'dom', \"'\", 's', 'birthday', 'celebration', '!', '!', '!', 'bottle', 'service', ',', 'hookah', ',', 'food', 'will', 'be', 'catered', 'by', 'no', 'other', 'but', 'me', 'lol', ',', 'vip', 'section', 'available', '.', '.', '.', '.', '.', '.', 'stay', 'tune', 'for', 'more', 'details', '\"', 'i', 'don', \"'\", 't', 'own', 'the', 'copyright', 'to', 'this', 'song', '\"', 'empire', 'lounge', 'vip', 'section', 'still', 'available', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (95) must match the existing size (96) at non-singleton dimension 0.  Target sizes: [95, 768].  Tensor sizes: [96, 1]\n",
      "1757\n",
      "['[CLS]', 'new', 'collection', 'alert', '.', '.', 'an', 'exclusive', 'sneak', 'peek', 'from', 'amici', 'by', 'baci', 'we', 'have', 'just', 'received', '!', 'this', 'is', 'one', 'collection', 'you', 'don', \"'\", 't', 'want', 'to', 'miss', '!', '.', '.', '.', 'you', 'can', 'contact', 'amici', 'through', 'baci', 'via', 'the', 'link', 'in', 'our', 'bio', 'for', 'more', 'information', 'about', 'the', 'line', '.', '.', 'hudson', 'mercantile', ',', 'february', '24', '-', '26', '2019', ',', 'studio', 'atelier', 'nyc', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (117) must match the existing size (118) at non-singleton dimension 0.  Target sizes: [117, 768].  Tensor sizes: [118, 1]\n",
      "2078\n",
      "['[CLS]', 'missing', 'dog', ':', 'lily', ',', 'still', 'with', 'leash', 'and', 'harness', ',', 'last', 'seen', 'on', 'prospect', 'park', 'west', 'and', '5th', 'street', '.', 'don', \"'\", 't', 'chase', 'if', 'seen', '!', '!', '!', 'call', 'lindsey', 'at', '917', '-', '515', '-', '4355', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (120) must match the existing size (121) at non-singleton dimension 0.  Target sizes: [120, 768].  Tensor sizes: [121, 1]\n",
      "2087\n",
      "['[CLS]', 'enough', 'with', 'the', 'hamburger', 'and', 'hotdogs', '.', '.', '.', '.', 'come', 'eat', 'some', 'real', 'food', 'and', 'drinks', 'at', 'larouge', 'lounge', 'and', 'restaurant', '972', 'broad', 'street', 'newark', 'nj', '@', 'chefdomcreates', '@', 'larouge', '_', 'restaurant', '_', 'lounge', 'kitchen', 'open', '6', '-', '12am', 'today', 'i', 'don', \"'\", 't', 'own', 'the', 'right', 'to', 'the', 'songs', 'playing', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (112) must match the existing size (113) at non-singleton dimension 0.  Target sizes: [112, 768].  Tensor sizes: [113, 1]\n",
      "2663\n",
      "['[CLS]', 'enough', 'with', 'the', 'hamburger', 'and', 'hotdogs', '.', '.', '.', '.', 'come', 'eat', 'some', 'real', 'food', 'and', 'drinks', 'at', 'larouge', 'lounge', 'and', 'restaurant', '972', 'broad', 'street', 'newark', 'nj', '@', 'chefdomcreates', '@', 'larouge', '_', 'restaurant', '_', 'lounge', 'kitchen', 'open', '6', '-', '12am', 'today', 'i', 'don', \"'\", 't', 'own', 'the', 'right', 'to', 'the', 'songs', 'playing', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (112) must match the existing size (113) at non-singleton dimension 0.  Target sizes: [112, 768].  Tensor sizes: [113, 1]\n",
      "2706\n",
      "['[CLS]', 'copper', 'has', 'had', 'a', 'very', 'exhausting', 'day', 'meeting', 'his', 'new', 'family', ',', 'friends', ',', 'home', ',', 'and', 'hang', 'out', 'spots', '!', 'please', 'don', \"'\", 't', 'wake', 'him', 'from', 'his', 'nap', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (124) must match the existing size (125) at non-singleton dimension 0.  Target sizes: [124, 768].  Tensor sizes: [125, 1]\n",
      "2944\n",
      "['[CLS]', 'caries', 'are', 'true', 'cavities', 'in', 'animals', '.', 'they', 'are', 'caused', 'by', 'consumption', 'of', 'carbohydrates', 'such', 'as', 'peas', ',', 'carrots', ',', 'green', 'beans', ',', 'and', 'sweet', 'potatoes', '.', 'unlike', 'people', ',', 'we', 'don', \"'\", 't', 'fill', 'cavities', ',', 'the', 'treatment', 'would', 'be', 'extraction', 'of', 'the', 'tooth', '.', 'brushing', 'can', 'help', 'remove', 'food', 'particles', 'stuck', 'in', 'teeth', 'that', 'may', 'contribute', 'to', 'cavities', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (108) must match the existing size (109) at non-singleton dimension 0.  Target sizes: [108, 768].  Tensor sizes: [109, 1]\n",
      "3130\n",
      "['[CLS]', 'show', 'your', 'support', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', 'for', 'next', '25', 'days', 'only', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (115) must match the existing size (116) at non-singleton dimension 0.  Target sizes: [115, 768].  Tensor sizes: [116, 1]\n",
      "3184\n",
      "['[CLS]', 'heatwave', 'in', 'effect', 'the', 'next', 'couple', 'days', '.', 'keep', 'your', 'pets', 'safe', '.', 'don', \"'\", 't', 'pour', 'water', 'on', 'them', 'outside', 'in', 'the', 'heat', ',', 'you', 'are', 'cooking', 'their', 'skin', '.', 'stay', 'indoors', '!', '!', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (125) must match the existing size (126) at non-singleton dimension 0.  Target sizes: [125, 768].  Tensor sizes: [126, 1]\n",
      "3506\n",
      "['[CLS]', 'help', 'barc', 'out', '!', '!', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', '9', 'days', 'only', 'left', 'on', 'this', 'fundraiser', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (112) must match the existing size (113) at non-singleton dimension 0.  Target sizes: [112, 768].  Tensor sizes: [113, 1]\n",
      "3545\n",
      "['[CLS]', 'spots', 'are', 'going', 'fast', 'for', 'our', 'next', 'on', 'march', '16', '!', '!', '!', 'be', 'sure', 'to', 'call', 'our', 'store', 'to', 'pre', '-', 'register', '.', 'we', 'will', 'be', 'donating', 'the', 'proceeds', 'we', 'get', 'from', 'the', 'venue', 'fee', 'to', 'the', '@', 'americancancersociety', ',', 'so', 'please', 'spread', 'the', 'word', '.', 'all', 'donations', 'are', 'welcome', '.', 'you', 'don', \"'\", 't', 'have', 'to', 'be', 'a', 'participate', 'to', 'donate', '.', 'we', 'are', 'also', 'accepting', 'sign', '-', 'ups', 'for', 'our', 'doubles', 'tournament', 'on', 'march', '23rd', '!', 'you', 'must', 'pre', '-', 'register', 'both', 'yourself', 'and', 'your', 'partner', 'when', 'you', 'call', '.', 'thank', 'you', '!', 'for', 'more', 'info', 'on', 'our', 'policies', 'and', 'rulesets', ',', 'please', 'visit', 'sidescroller', '[SEP]']\n",
      "The expanded size of the tensor (109) must match the existing size (110) at non-singleton dimension 0.  Target sizes: [109, 768].  Tensor sizes: [110, 1]\n",
      "3626\n",
      "['[CLS]', '\"', 'microchips', 'greatly', 'increase', 'the', 'chances', 'that', 'pets', 'will', 'be', 'reuinted', 'with', 'their', 'families', 'if', 'they', 'are', 'lost', 'or', 'stolen', ',', 'but', 'a', 'microchip', 'only', 'works', 'if', 'its', 'registration', 'information', 'is', 'accurate', '.', '\"', 'when', 'we', 'place', 'a', 'microchip', '@', 'abingdonsquarevet', 'we', 'register', 'the', 'chip', 'for', 'you', 'but', 'you', 'need', 'to', 'keep', 'the', 'info', 'up', 'to', 'date', '!', 'if', 'your', 'pet', 'already', 'has', 'a', 'chip', ',', 'we', 'can', 'scan', 'it', 'and', 'provide', 'you', 'the', 'number', '.', '<', 'url', '>', 'can', 'be', 'helpful', 'if', 'you', 'know', 'the', 'microchip', 'number', 'but', 'don', \"'\", 't', 'know', 'what', 'company', 'to', 'register', 'your', 'pet', \"'\", 's', 'microchip', '!', '[SEP]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (107) must match the existing size (108) at non-singleton dimension 0.  Target sizes: [107, 768].  Tensor sizes: [108, 1]\n",
      "3640\n",
      "['[CLS]', '5', 'days', 'remaining', '!', '!', 'help', 'barc', 'out', ',', 'only', '6', 'days', 'left', '!', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', '5', 'days', 'only', 'left', 'on', 'this', 'fundraiser', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]']\n",
      "The expanded size of the tensor (112) must match the existing size (113) at non-singleton dimension 0.  Target sizes: [112, 768].  Tensor sizes: [113, 1]\n",
      "3642\n",
      "['[CLS]', 'all', 'of', 'our', 'services', 'are', 'by', 'appointment', 'only', '.', 'we', 'don', \"'\", 't', 'take', 'any', 'walk', '-', 'ins', '.', 'we', 'want', 'to', 'ensure', 'that', 'no', 'one', 'is', 'waiting', 'and', 'that', 'everyone', 'may', 'have', 'a', 'wonderful', 'experience', 'with', 'us', 'at', 'gorgeous', 'spa', '.', 'send', 'us', 'a', 'direct', 'message', 'or', 'call', 'us', 'at', '(', '347', ')', '460', '-', '6006', '.', 'we', 'look', 'forward', 'to', 'hearing', 'from', 'you', 'gorgeous', '!', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (120) must match the existing size (121) at non-singleton dimension 0.  Target sizes: [120, 768].  Tensor sizes: [121, 1]\n",
      "3762\n",
      "['[CLS]', 'we', 'don', \"'\", 't', 'cross', 'our', 'arms', 'to', 'rest', ',', 'only', 'just', 'to', 'show', 'our', 'wonders', 'of', 'design', 'fingerless', 'gloves', 'de', 'main', '145', 'front', 'st', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (124) must match the existing size (125) at non-singleton dimension 0.  Target sizes: [124, 768].  Tensor sizes: [125, 1]\n",
      "4122\n",
      "['[CLS]', 'join', 'us', 'friday', ',', 'june', '21st', 'at', '8', ':', '15pm', 'for', 'our', 'kickoff', 'to', 'summer', 'black', 'light', 'class', '!', 'this', '90', 'minute', 'class', 'with', 'feature', '2', 'surprise', 'trainers', '!', 'if', 'you', 'would', 'like', 'an', 'official', 'cko', 'black', 'light', 'shirt', ',', 'preorder', 'yours', 'at', 'the', 'front', 'desk', 'for', '$', '15', 'by', 'sunday', ',', 'june', '9th', '!', '!', 'wear', 'neon', 'or', 'white', 'shirts', 'if', 'you', 'don', \"'\", 't', 'purchase', 'a', 'cko', 'shirt', '.', 'reserve', 'your', 'bag', 'at', 'the', 'front', 'desk', 'or', 'dm', 'to', 'reserve', 'your', 'spot', '!', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (112) must match the existing size (113) at non-singleton dimension 0.  Target sizes: [112, 768].  Tensor sizes: [113, 1]\n",
      "4181\n",
      "['[CLS]', 'robell', 'is', 'everyday', '-', 'luxury', 'for', 'women', 'who', 'don', \"'\", 't', 'want', 'to', 'compromise', 'when', 'it', 'comes', 'to', 'look', 'or', 'comfort', '.', '.', 'if', 'you', 'buy', 'a', 'pair', 'of', 'robell', 'trousers', ',', 'you', 'are', 'guaranteed', 'a', 'high', 'quality', '-', 'at', 'reasonable', 'prices', '.', '.', 'robell', 'knows', 'that', 'each', 'woman', 'is', 'different', '.', 'therefore', ',', 'you', 'will', 'find', 'the', 'trousers', 'and', 'jeans', 'in', 'different', 'styles', 'in', 'a', 'number', 'of', 'colours', 'and', 'fashionable', 'prints', '-', 'whether', 'you', 'prefer', 'a', 'classical', 'or', 'a', 'more', 'stylish', 'look', '.', '.', '.', 'you', 'can', 'contact', 'robell', 'through', 'godske', 'group', 'via', '.', '.', 'hudson', 'mercantile', ',', 'february', '24', '-', '26', '[SEP]']\n",
      "The expanded size of the tensor (104) must match the existing size (105) at non-singleton dimension 0.  Target sizes: [104, 768].  Tensor sizes: [105, 1]\n",
      "4354\n",
      "['[CLS]', '1', 'more', 'days', 'till', 'the', 'biggest', 'birthday', 'celebration', '@', 'empireloungenj', '@', 'chefdomcreates', '@', 'unclevinrock', '@', 'larouge', '_', 'restaurant', '_', 'lounge', '@', 'sa', '_', 'kye', '_', 'dom', '@', 'djsupadice', '@', 'mrdjovaflow', '@', 'judexmrgoodlife', 'chef', 'dom', \"'\", 's', 'birthday', 'celebration', '!', '!', '!', 'bottle', 'service', ',', 'hookah', ',', 'food', 'will', 'be', 'catered', 'by', 'no', 'other', 'but', 'me', 'lol', ',', 'vip', 'section', 'available', '.', '.', '.', '.', '.', '.', 'stay', 'tune', 'for', 'more', 'details', '\"', 'i', 'don', \"'\", 't', 'own', 'the', 'copyright', 'to', 'this', 'song', '\"', 'empire', 'lounge', 'vip', 'section', 'still', 'available', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (95) must match the existing size (96) at non-singleton dimension 0.  Target sizes: [95, 768].  Tensor sizes: [96, 1]\n",
      "4423\n",
      "['[CLS]', 'did', 'you', 'make', 'our', 'last', 'black', 'light', 'class', '?', 'if', 'not', '.', '.', '.', 'join', 'us', 'friday', ',', 'june', '21st', 'at', '8', ':', '15pm', 'for', 'our', 'kickoff', 'to', 'summer', 'black', 'light', 'class', '!', 'if', 'you', 'would', 'like', 'an', 'official', 'cko', 'black', 'light', 'shirt', ',', 'preorder', 'yours', 'at', 'the', 'front', 'desk', 'for', '$', '15', 'by', 'sunday', ',', 'june', '9th', '!', '!', '!', 'wear', 'neon', 'or', 'white', 'shirts', 'if', 'you', 'don', \"'\", 't', 'purchase', 'a', 'cko', 'shirt', '.', 'reserve', 'your', 'spot', 'at', 'the', 'front', 'desk', 'or', 'by', 'dm', '!', 'don', \"'\", 't', 'forget', 'after', 'party', 'at', 'cj', \"'\", 's', 'at', '10pm', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (110) must match the existing size (111) at non-singleton dimension 0.  Target sizes: [110, 768].  Tensor sizes: [111, 1]\n",
      "4590\n",
      "['[CLS]', 'lost', 'dog', 'named', 'murphy', ',', 'slipped', 'out', 'of', 'her', 'harness', 'around', 'gates', 'and', 'marcy', 'avenue', ',', 'brooklyn', '.', 'don', \"'\", 't', 'chase', '!', 'offer', 'treats', '!', 'any', 'sightings', 'or', 'information', ',', 'call', '301', '-', '956', '-', '6937', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (116) must match the existing size (117) at non-singleton dimension 0.  Target sizes: [116, 768].  Tensor sizes: [117, 1]\n",
      "4661\n",
      "['[CLS]', '\"', 'don', \"'\", 'thing', 'from', 'selfish', 'ambition', 'or', 'conceit', ',', 'but', 'in', 'humility', 'count', 'others', 'more', 'significant', 'than', 'yourselves', '.', '\"', '-', 'philippians', '2', ':', '3', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (117) must match the existing size (118) at non-singleton dimension 0.  Target sizes: [117, 768].  Tensor sizes: [118, 1]\n",
      "5221\n",
      "['[CLS]', 'friends', ',', 'please', 'don', \"'\", 't', 'forget', 'to', 'reserve', 'your', 'table', 'for', 'fathers', 'day', 'for', 'this', 'sunday', '!', 'we', 'still', 'have', 'some', 'tables', 'available', ',', 'but', 'please', 'rush', '!', 'happy', 'fathers', 'day', 'guys', '!', '347', '-', '673', '-', '5411', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (117) must match the existing size (118) at non-singleton dimension 0.  Target sizes: [117, 768].  Tensor sizes: [118, 1]\n",
      "6001\n",
      "['[CLS]', 'barc', 'shelter', 'just', 'updated', 'our', 'wishlist', 'on', 'amazon', ',', 'and', 'we', 'are', 'out', 'of', 'stock', 'on', 'these', 'items', '.', 'if', 'you', 'would', 'like', 'to', 'donate', ',', 'go', 'to', '@', 'barcshelter', 'and', 'on', 'our', 'profile', 'you', 'will', 'see', 'our', 'amazon', 'wishlist', '.', 'if', 'you', 'don', \"'\", 't', 'want', 'to', 'purchase', 'through', 'amazon', ',', 'you', 'can', 'also', 'get', 'it', 'through', 'costco', '/', 'target', 'or', 'buy', 'it', 'locally', 'and', 'drop', 'it', 'off', '.', 'every', 'little', 'thing', 'helps', '.', 'thank', 'you', 'for', 'your', 'kind', 'heart', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (116) must match the existing size (117) at non-singleton dimension 0.  Target sizes: [116, 768].  Tensor sizes: [117, 1]\n",
      "6910\n",
      "['[CLS]', 'every', 'week', 'we', 'get', 'submissions', 'from', 'people', 'from', 'around', 'the', 'world', 'for', 'a', 'segment', 'of', 'our', 'open', 'mic', 'called', '\"', 'read', 'my', 'lines', '.', '\"', 'this', 'allows', 'artists', 'to', 'submit', 'their', 'work', 'whenever', 'they', 'cannot', 'attend', 'our', 'events', 'or', 'if', 'they', 'don', \"'\", 't', 'live', 'in', 'our', 'country', 'or', 'state', 'or', 'if', 'they', 'have', 'stage', 'fright', 'but', 'still', 'want', 'their', 'voice', 'heard', ',', 'and', 'a', 'volunteer', 'will', 'be', 'recorded', 'reading', 'their', 'work', '.', '.', 'we', 'would', 'like', 'to', 'give', 'a', 'big', 'shoutout', 'to', '@', 'shay', '_', 'marie', '_', 'g', 'for', 'an', 'awesome', 'job', 'reading', '@', 'kingcesar1583', 'erotic', 'short', 'story', '.', 'special', 'thank', 'you', 'to', '@', 'kingcesar1583', '[SEP]']\n",
      "The expanded size of the tensor (107) must match the existing size (108) at non-singleton dimension 0.  Target sizes: [107, 768].  Tensor sizes: [108, 1]\n",
      "7412\n",
      "['[CLS]', 'did', 'you', 'make', 'our', 'last', 'black', 'light', 'class', '?', 'if', 'not', '.', '.', '.', 'join', 'us', 'friday', ',', 'june', '21st', 'at', '8', ':', '15pm', 'for', 'our', 'kickoff', 'to', 'summer', 'black', 'light', 'class', '!', 'if', 'you', 'would', 'like', 'an', 'official', 'cko', 'black', 'light', 'shirt', ',', 'preorder', 'yours', 'at', 'the', 'front', 'desk', 'for', '$', '15', 'by', 'sunday', ',', 'june', '9th', '!', '!', '!', 'wear', 'neon', 'or', 'white', 'shirts', 'if', 'you', 'don', \"'\", 't', 'purchase', 'a', 'cko', 'shirt', '.', 'reserve', 'your', 'spot', 'at', 'the', 'front', 'desk', 'or', 'by', 'dm', '!', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (113) must match the existing size (114) at non-singleton dimension 0.  Target sizes: [113, 768].  Tensor sizes: [114, 1]\n",
      "7800\n",
      "['[CLS]', '~', 'where', 'can', 'you', 'relax', 'and', 'fully', 'be', 'yourself', '~', '.', '~', 'where', 'can', 'you', 'go', 'and', 'feel', 'loved', 'and', 'safe', '?', '~', '.', '~', 'where', 'is', 'the', 'place', 'you', 'can', 'go', 'and', 'heal', 'from', 'the', 'areas', 'in', 'which', 'you', 'don', \"'\", 't', 'feel', 'supported', '?', '~', '.', 'it', 'can', 'be', 'hard', 'to', 'find', 'a', 'place', 'like', 'that', 'and', 'when', 'you', 'do', '.', '.', '.', 'hold', 'onto', 'it', '.', '.', 'join', 'us', 'tonight', 'for', 'a', 'healing', 'soundbath', 'with', 'shunny', '@', 'sounddreamsnyc', '.', 'last', 'sound', 'bath', 'of', 'the', 'decade', 'learning', 'how', 'to', 'manifest', 'our', 'realities', 'and', 'find', 'happiness', 'within', 'ourselves', 'amongst', 'a', 'wild', 'continuously', 'moving', 'and', 'chaotic', 'world', '[SEP]']\n",
      "The expanded size of the tensor (108) must match the existing size (109) at non-singleton dimension 0.  Target sizes: [108, 768].  Tensor sizes: [109, 1]\n",
      "8582\n",
      "['[CLS]', 'barc', 'shelter', 'is', 'almost', 'out', 'of', 'these', 'cleaning', 'items', '.', 'if', 'you', 'would', 'like', 'to', 'donate', ',', 'go', 'to', '@', 'barcshelter', 'and', 'on', 'our', 'profile', 'you', 'will', 'see', 'our', 'amazon', 'wishlist', '.', 'if', 'you', 'don', \"'\", 't', 'want', 'to', 'purchase', 'through', 'amazon', ',', 'you', 'can', 'also', 'get', 'it', 'through', 'costco', ',', 'or', 'buy', 'it', 'locally', 'and', 'drop', 'it', 'off', '.', 'every', 'little', 'thing', 'helps', '.', 'thank', 'you', 'for', 'your', 'kind', 'heart', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (117) must match the existing size (118) at non-singleton dimension 0.  Target sizes: [117, 768].  Tensor sizes: [118, 1]\n",
      "8758\n",
      "['[CLS]', 'how', 'did', 'we', 'not', 'respect', 'this', '.', '.', '.', 'we', 'complain', 'about', 'but', 'we', 'don', \"'\", 't', 'keep', 'shit', 'up', '?', '?', '!', '!', 'let', \"'\", 's', 'talk', 'about', 'it', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (126) must match the existing size (127) at non-singleton dimension 0.  Target sizes: [126, 768].  Tensor sizes: [127, 1]\n",
      "8800\n",
      "['[CLS]', 'snow', 'is', 'in', 'the', 'forecast', ',', 'but', 'please', 'don', \"'\", 't', 'confuse', 'cute', 'zorro', 'with', 'a', 'snowflake', '.', '@', 'zorro', '_', 'maltese', '_', 'puppy', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (115) must match the existing size (116) at non-singleton dimension 0.  Target sizes: [115, 768].  Tensor sizes: [116, 1]\n",
      "8932\n",
      "['[CLS]', 'help', 'barc', 'out', '!', '!', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', 'for', 'next', '16', 'days', 'only', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (114) must match the existing size (115) at non-singleton dimension 0.  Target sizes: [114, 768].  Tensor sizes: [115, 1]\n",
      "9199\n",
      "['[CLS]', 'tomorrow', 'is', 'saturday', 'at', '!', 'our', 'event', 'will', 'begin', 'at', '5pm', '.', 'register', 'over', 'at', 'smash', '.', 'gg', '(', 'link', 'in', 'bio', ')', '.', 'walk', '-', 'ins', 'are', 'welcome', '.', 'if', 'you', 'don', \"'\", 't', 'have', 'a', 'smash', '.', 'gg', 'account', ',', 'you', 'can', 'make', 'one', 'for', 'free', 'at', 'time', 'of', 'sign', '-', 'up', '.', 'you', 'can', 'find', 'our', 'rules', 'on', 'our', 'smash', '.', 'gg', 'page', 'as', 'well', 'as', 'our', 'website', 'sidescrollersnj', '.', 'com', '/', 'tournaments', 'please', 'note', ':', 'our', 'shop', 'will', 'have', 'a', 'delayed', 'opening', 'at', '2pm', '.', 'the', 'will', 'be', 'closed', 'off', 'to', 'non', '-', 'participants', 'during', 'the', 'tournament', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (109) must match the existing size (110) at non-singleton dimension 0.  Target sizes: [109, 768].  Tensor sizes: [110, 1]\n",
      "9313\n",
      "['[CLS]', 'the', 'best', 'part', 'by', 'living', 'by', 'this', 'view', '&', 'comin', 'home', 'straight', 'after', 'work', 'is', 'that', 'its', 'peaceful', ',', 'a', 'blessing', '&', 'a', 'spot', 'to', 'clear', 'ur', 'mind', '&', 'think', 'about', 'alot', 'of', 'things', 'and', 'relex', 'when', 'u', 'alone', 'but', 'the', 'hardest', 'part', 'about', 'it', 'is', 'when', 'u', 'take', 'the', 'time', 'to', 'think', 'about', 'someone', 'you', 'really', 'miss', '&', 'love', 'but', 'cant', 'don', \"'\", 'thing', 'about', 'it', 'to', 'show', 'them', 'or', 'prove', 'to', 'them', 'what', 'you', 'mean', 'to', 'then', '&', 'l', '@', 'djeasynyc', '@', 'djeasycalderon', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (113) must match the existing size (114) at non-singleton dimension 0.  Target sizes: [113, 768].  Tensor sizes: [114, 1]\n",
      "10910\n",
      "['[CLS]', 'it', \"'\", 's', 'too', 'this', 'week', ',', 'protect', 'your', 'pets', '!', 'also', 'don', \"'\", 't', 'pour', 'water', 'on', 'your', 'pets', 'outside', 'in', 'this', 'heat', ',', 'you', 'will', 'be', 'cooking', 'them', ',', 'walk', 'in', 'the', 'shade', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (125) must match the existing size (126) at non-singleton dimension 0.  Target sizes: [125, 768].  Tensor sizes: [126, 1]\n",
      "10925\n",
      "['[CLS]', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (115) must match the existing size (116) at non-singleton dimension 0.  Target sizes: [115, 768].  Tensor sizes: [116, 1]\n",
      "11052\n",
      "['[CLS]', 'when', 'you', \"'\", 're', 'trapped', 'in', 'the', 'black', 'lodge', ',', 'how', 'long', 'does', 'it', 'take', 'for', 'you', 'to', 'realized', 'you', \"'\", 're', 'stuck', 'in', 'there', '?', '25', 'years', '?', 'it', \"'\", 's', 'hard', 'to', 'say', 'how', 'or', 'why', ',', 'but', 'my', 'burlesque', 'accounts', 'don', \"'\", 't', 'get', 'seen', 'much', 'these', 'days', '.', 'please', 'give', 'us', 'a', 'like', 'and', 'maybe', 'a', 'comment', '?', 'pretty', 'please', '?', 'help', 'me', 'get', 'released', '!', '@', 'thepinkroomburlesque', 'call', 'for', 'help', '!', 'we', \"'\", 're', 'trapped', 'in', 'the', 'black', 'lodge', 'and', 'we', 'cant', 'get', 'out', '!', '@', 'thepinkroomburlesque', 'appears', 'to', 'be', 'under', 'the', 'effects', 'of', 'shadowban', '[SEP]']\n",
      "The expanded size of the tensor (101) must match the existing size (102) at non-singleton dimension 0.  Target sizes: [101, 768].  Tensor sizes: [102, 1]\n",
      "11168\n",
      "['[CLS]', 'barc', 'shelter', 'is', 'almost', 'out', 'of', 'these', 'items', '.', 'if', 'you', 'would', 'like', 'to', 'donate', ',', 'go', 'to', '@', 'barcshelter', 'and', 'on', 'our', 'profile', 'you', 'will', 'see', 'our', 'amazon', 'wishlist', '.', 'if', 'you', 'don', \"'\", 't', 'want', 'to', 'purchase', 'through', 'amazon', ',', 'you', 'can', 'also', 'get', 'it', 'through', 'costco', ',', 'or', 'buy', 'it', 'locally', 'and', 'drop', 'it', 'off', '.', 'every', 'little', 'thing', 'helps', '.', 'thank', 'you', 'for', 'your', 'kind', 'heart', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (118) must match the existing size (119) at non-singleton dimension 0.  Target sizes: [118, 768].  Tensor sizes: [119, 1]\n",
      "11291\n",
      "['[CLS]', 'friends', ',', 'please', 'don', \"'\", 't', 'forget', 'to', 'reserve', 'your', 'table', 'for', 'fathers', 'day', 'for', 'this', 'sunday', '!', 'we', 'still', 'have', 'some', 'tables', 'available', ',', 'but', 'please', 'rush', '!', 'happy', 'fathers', 'day', 'guys', '!', '347', '-', '673', '-', '5411', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (117) must match the existing size (118) at non-singleton dimension 0.  Target sizes: [117, 768].  Tensor sizes: [118, 1]\n",
      "11456\n",
      "['[CLS]', 'help', 'barc', 'out', '!', '!', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', 'for', 'next', '20', 'days', 'only', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (114) must match the existing size (115) at non-singleton dimension 0.  Target sizes: [114, 768].  Tensor sizes: [115, 1]\n",
      "13096\n",
      "['[CLS]', 'help', 'barc', 'out', ',', 'only', '6', 'days', 'left', '!', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', '6', 'days', 'only', 'left', 'on', 'this', 'fundraiser', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (112) must match the existing size (113) at non-singleton dimension 0.  Target sizes: [112, 768].  Tensor sizes: [113, 1]\n",
      "13811\n",
      "['[CLS]', 'barc', 'shelter', 'is', 'running', 'out', 'of', 'litter', 'in', 'our', 'cat', 'loft', '.', 'if', 'you', 'would', 'like', 'to', 'donate', ',', 'go', 'to', '@', 'barcshelter', 'and', 'on', 'our', 'profile', 'you', 'will', 'see', 'our', 'amazon', 'wishlist', '.', 'if', 'you', 'don', \"'\", 't', 'want', 'to', 'purchase', 'through', 'amazon', ',', 'you', 'can', 'also', 'get', 'it', 'through', 'costco', ',', 'or', 'buy', 'it', 'locally', 'and', 'drop', 'it', 'off', '.', 'every', 'little', 'thing', 'helps', '.', 'thank', 'you', 'for', 'your', 'kind', 'heart', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (116) must match the existing size (117) at non-singleton dimension 0.  Target sizes: [116, 768].  Tensor sizes: [117, 1]\n",
      "14493\n",
      "['[CLS]', 'all', 'of', 'our', 'services', 'are', 'by', 'appointment', 'only', '.', 'we', 'don', \"'\", 't', 'take', 'any', 'walk', '-', 'ins', '.', 'we', 'want', 'to', 'ensure', 'that', 'no', 'one', 'is', 'waiting', 'and', 'that', 'everyone', 'may', 'have', 'a', 'wonderful', 'experience', 'with', 'us', 'at', 'gorgeous', 'spa', '.', 'send', 'us', 'a', 'direct', 'message', 'or', 'call', 'us', 'at', '(', '347', ')', '460', '-', '6006', '.', 'we', 'look', 'forward', 'to', 'hearing', 'from', 'you', 'gorgeous', '!', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (120) must match the existing size (121) at non-singleton dimension 0.  Target sizes: [120, 768].  Tensor sizes: [121, 1]\n",
      "14945\n",
      "['[CLS]', 'friends', ',', 'please', 'don', \"'\", 't', 'forget', 'to', 'reserve', 'your', 'table', 'for', 'fathers', 'day', 'this', 'sunday', '!', 'we', 'still', 'have', 'some', 'tables', 'available', ',', 'but', 'the', 'holiday', 'is', 'literally', 'tomorrow', '!', 'and', 'happy', 'fathers', 'day', '718', '-', '513', '-', '6004', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (119) must match the existing size (120) at non-singleton dimension 0.  Target sizes: [119, 768].  Tensor sizes: [120, 1]\n",
      "15596\n",
      "['[CLS]', 'barc', 'shelter', 'is', 'almost', 'out', 'of', 'these', 'items', '.', 'if', 'you', 'would', 'like', 'to', 'donate', ',', 'go', 'to', '@', 'barcshelter', 'and', 'on', 'our', 'profile', 'you', 'will', 'see', 'our', 'amazon', 'wishlist', '.', 'if', 'you', 'don', \"'\", 't', 'want', 'to', 'purchase', 'through', 'amazon', ',', 'you', 'can', 'also', 'get', 'it', 'through', 'costco', ',', 'or', 'buy', 'it', 'locally', 'and', 'drop', 'it', 'off', '.', 'every', 'little', 'thing', 'helps', '.', 'thank', 'you', 'for', 'your', 'kind', 'heart', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (118) must match the existing size (119) at non-singleton dimension 0.  Target sizes: [118, 768].  Tensor sizes: [119, 1]\n",
      "15778\n",
      "['[CLS]', 'friends', ',', 'please', 'don', \"'\", 't', 'forget', 'to', 'reserve', 'your', 'table', 'for', 'fathers', 'day', 'for', 'this', 'sunday', '!', 'we', 'still', 'have', 'some', 'tables', 'available', ',', 'but', 'please', 'rush', '!', 'happy', 'fathers', 'day', 'guys', '!', '347', '-', '673', '-', '5411', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (117) must match the existing size (118) at non-singleton dimension 0.  Target sizes: [117, 768].  Tensor sizes: [118, 1]\n",
      "16167\n",
      "['[CLS]', 'friends', ',', 'please', 'don', \"'\", 't', 'forget', 'to', 'reserve', 'your', 'table', 'for', 'fathers', 'day', 'this', 'sunday', '!', 'we', 'still', 'have', 'some', 'tables', 'available', ',', 'but', 'the', 'holiday', 'is', 'literally', 'tomorrow', '!', 'and', 'happy', 'fathers', 'day', '718', '-', '513', '-', '6004', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (119) must match the existing size (120) at non-singleton dimension 0.  Target sizes: [119, 768].  Tensor sizes: [120, 1]\n",
      "16201\n",
      "['[CLS]', 'is', 'it', 'still', 'moonday', '?', 'how', 'luck', 'am', 'i', 'that', 'i', 'get', 'to', 'don', \"'\", 't', 'one', 'butt', 'two', 'shows', 'with', '@', 'mspussnboots', 'this', 'week', '?', 'catch', 'me', 'on', 'tuesday', 'at', '@', 'naughtynoirshow', \"'\", 's', '5th', 'anniversary', 'at', '@', 'thedelancey', 'thursday', 'at', '@', 'stachenovak', \"'\", 's', 'midnight', 'fingers', 'at', '@', 'slipperroomnyc', 'for', 'a', 'lynchian', 'night', 'that', \"'\", 's', 'gonna', 'have', 'you', 'up', 'in', 'flames', 'then', 'stay', 'turned', 'for', '@', 'thepinkroomburlesque', 'to', 'release', 'tickets', 'real', 'soon', 'for', 'our', 'oct', '19th', 'costume', 'party', 'at', '@', 'bedlamnyc', '!', '[SEP]']\n",
      "The expanded size of the tensor (86) must match the existing size (87) at non-singleton dimension 0.  Target sizes: [86, 768].  Tensor sizes: [87, 1]\n",
      "16724\n",
      "['[CLS]', 'don', \"'\", 't', 'let', 'the', 'cold', 'stop', 'you', 'from', 'what', 'you', 'love', '!', '.', 'class', 'with', '@', 'daya', '_', 'mama', 'tomorrow', 'at', '8am', '.', 'if', 'you', 'miss', ',', 'it', \"'\", 's', 'ok', '!', 'we', 'have', 'classes', 'all', 'day', '!', 'come', 'by', 'for', 'some', 'yoga', 'and', 'tea', 'and', 'smiles', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (123) must match the existing size (124) at non-singleton dimension 0.  Target sizes: [123, 768].  Tensor sizes: [124, 1]\n"
     ]
    }
   ],
   "source": [
    "# –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å–ª–æ–≤ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "def get_word_vectors(sent, tokenizer, model, layers):\n",
    "    \"\"\"Get a word vector by first tokenizing the input sentence, getting all token idxs\n",
    "        that make up the word of interest, and then `get_hidden_states`.\"\"\"\n",
    "    \n",
    "    encoded = tokenizer.encode_plus(sent, return_tensors=\"pt\", max_length=128, padding='max_length', truncation=True)\n",
    "#     encoded = tokenizer.encode_plus(sent, return_tensors=\"pt\")\n",
    "    \n",
    "    input_ids = list(map(lambda x: token2idx[x], get_words(sent)))\n",
    "    input_ids = torch.tensor(input_ids).unsqueeze(0)\n",
    "    return get_hidden_states(encoded, encoded.word_ids(), model, layers).cpu(), input_ids\n",
    "\n",
    "def get_embedding(doc, model=bert):\n",
    "    \"Get embedding for each word\"\n",
    "    layers = [-4, -3, -2, -1]\n",
    "    return get_word_vectors(doc, tokenizer, model, layers)\n",
    "\n",
    "embeddings = []\n",
    "input_ids = []\n",
    "\n",
    "token_embeddings = torch.zeros((VOCAB_SIZE, 768))\n",
    "token_count = torch.zeros((VOCAB_SIZE,))\n",
    "\n",
    "for idx, doc in enumerate(train_posts.text):\n",
    "    try:\n",
    "        embedding, ids = get_embedding(doc)\n",
    "        embeddings.append(embedding)\n",
    "        input_ids.append(ids)\n",
    "        token_embeddings.scatter_add_(0, ids[0].unsqueeze(1).expand(embedding.shape), embedding)\n",
    "        token_count.scatter_add_(0, ids[0], torch.ones_like(ids[0]).float())\n",
    "    except Exception as e:\n",
    "        print(idx)\n",
    "        print(get_words(doc))\n",
    "        print(e)\n",
    "\n",
    "token_embeddings = torch.nan_to_num(torch.div(token_embeddings, token_count.unsqueeze(1).expand(token_embeddings.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26641, 768])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# —Ç–æ–∂–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "token_similarities = cosine_similarity(token_embeddings, token_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85      , 0.56472343, 0.33764276, ..., 0.62420136, 0.62081015,\n",
       "        0.5720375 ],\n",
       "       [0.56472343, 0.85      , 0.30267996, ..., 0.5240807 , 0.5224425 ,\n",
       "        0.54111636],\n",
       "       [0.33764276, 0.30267996, 0.85      , ..., 0.25307572, 0.32413712,\n",
       "        0.29881054],\n",
       "       ...,\n",
       "       [0.62420136, 0.5240807 , 0.25307572, ..., 0.85      , 0.57771885,\n",
       "        0.64851695],\n",
       "       [0.62081015, 0.5224425 , 0.32413712, ..., 0.57771885, 0.85      ,\n",
       "        0.5793119 ],\n",
       "       [0.5720375 , 0.54111636, 0.29881054, ..., 0.64851695, 0.5793119 ,\n",
       "        0.85      ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# —Ç–æ–∂–µ –Ω—É–∂–Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "token_similarities.clip(max=0.85, out=token_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26641, 26641)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_similarities.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–±—É—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NYDataset(Dataset):\n",
    "    def __init__(self, embeddings, input_ids):\n",
    "        self.embeddings = embeddings\n",
    "        self.input_ids = list(map(lambda x: x.squeeze(), input_ids))\n",
    "        \n",
    "        self.embeddings = nn.utils.rnn.pad_sequence(self.embeddings, batch_first=True, padding_value=0)\n",
    "        self.input_ids = nn.utils.rnn.pad_sequence(self.input_ids, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return embeddings[idx], input_ids[idx].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.6976)\n",
      "tensor(49383264.)\n",
      "tensor(24694528.)\n"
     ]
    }
   ],
   "source": [
    "# —Å–≤–æ–∏ –ª–æ—Å—Å—ã, —É—á–∏—Ç—ã–≤–∞—é—â–∏–µ –ø–æ—Ö–æ–∂–µ—Å—Ç—å —Å–ª–æ–≤\n",
    "\n",
    "gen = torch.randn(64, 128, VOCAB_SIZE)\n",
    "orig = torch.randint(0, VOCAB_SIZE, (64, 1, 128))\n",
    "\n",
    "# LOSS FUNCTIONS\n",
    "\n",
    "def recon_loss(inp, targ):\n",
    "    \"Loss of first stage\"\n",
    "    return F.cross_entropy(inp.view(-1, VOCAB_SIZE), targ.reshape(-1))\n",
    "\n",
    "def doc_embed_loss(gen_doc, orig_doc, k=5):\n",
    "    topk_values, topk_indices = torch.topk(gen_doc, k, dim=-1)\n",
    "    rand_indices = torch.randint(0, VOCAB_SIZE, (gen_doc.shape[0], k))\n",
    "    doc_loss = 0\n",
    "    \n",
    "    for i in range(gen_doc.shape[0]):\n",
    "        rand_values = torch.index_select(gen_doc, -1, rand_indices[i])\n",
    "        doc_loss += (topk_values * token_similarities[orig_doc[i].item(), topk_indices[i]]).sum()\n",
    "        doc_loss += (rand_values * token_similarities[orig_doc[i].item(), rand_indices[i]]).sum()\n",
    "\n",
    "    return doc_loss\n",
    "\n",
    "def embed_loss(inp, targ, k=5):\n",
    "    loss = 0\n",
    "    inp = F.log_softmax(inp, dim=-1)\n",
    "    for i in range(inp.shape[0]):\n",
    "        loss += doc_embed_loss(inp[i], targ[i][0], k=k)\n",
    "    return -loss\n",
    "\n",
    "def total_loss(inp, targ, alpha=1, beta=0.5, k=5):\n",
    "    \"Loss of second stage\"\n",
    "    return alpha * recon_loss(inp, targ) + beta * embed_loss(inp, targ, k)\n",
    "\n",
    "print(recon_loss(gen, orig))\n",
    "print(embed_loss(gen, orig))\n",
    "print(total_loss(gen, orig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch-lightning.readthedocs.io/en/latest/notebooks/lightning_examples/datamodules.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª pytorch lightning –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, –ø–æ—ç—Ç–æ–º—É –Ω–∞–ø–∏—Å–∞–Ω –∫–ª–∞—Å—Å –¥–ª—è –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ —ç—Ç–æ—Ç —Ñ—Ä–µ–π–º–≤–æ—Ä–∫\n",
    "\n",
    "def collate_fn(samples):\n",
    "    x = [sample[0] for sample in samples]\n",
    "    y = [sample[1].squeeze() for sample in samples]\n",
    "    \n",
    "    x = nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=0.0)\n",
    "    y = nn.utils.rnn.pad_sequence(y, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "    \n",
    "    if x.shape[1] < y.shape[1]:\n",
    "        y = y[:, :x.shape[1]]\n",
    "    \n",
    "#     print(x.shape, y.shape)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "class LitERAE(pl.LightningModule):\n",
    "    def __init__(self, data, emb_size=768, hidden_size=512, num_layers=2, act_type=None, learning_rate=1e-3, batch_size=64):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # We hardcode dataset specific stuff here.\n",
    "        self.data = data\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏, –ø–æ–¥—Ä–æ–±–Ω–µ–µ –ø—Ä–æ –Ω–µ—ë –≤ —Å—Ç–∞—Ç—å–µ MuCAAT\n",
    "        self.gru_1 = nn.GRU(emb_size, hidden_size, num_layers, bidirectional=True, batch_first=True)\n",
    "        if act_type == None:\n",
    "            self.act_1 = nn.Identity()\n",
    "        if act_type == 'ReLU':\n",
    "            self.act_1 = nn.ReLU()\n",
    "        self.linear_1 = nn.Linear(hidden_size * 2, emb_size)\n",
    "        self.gru_2 = nn.GRU(emb_size, hidden_size, num_layers, bidirectional=True, batch_first=True)\n",
    "        self.linear_2 = nn.Linear(hidden_size * 2, VOCAB_SIZE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, hidden = self.gru_1(x)\n",
    "        x = self.act_1(x)\n",
    "        x = self.linear_1(x)\n",
    "        x, _ = self.gru_2(x, hidden)\n",
    "        x = self.act_1(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_func(logits, y)\n",
    "        \n",
    "        self.log(f'train_loss', loss)\n",
    "        self.log(f'avg_train_loss', loss, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_func(logits, y)\n",
    "        \n",
    "        self.log(f'val_loss', loss)\n",
    "        self.log(f'avg_val_loss', loss, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        lr_scheduler = {\"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, verbose=True), \"monitor\": \"avg_val_loss\"}\n",
    "        return {'optimizer': optimizer, 'lr_shceduler': lr_scheduler}\n",
    "\n",
    "    def on_train_batch_end(self, outputs, batch, batch_idx):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "#         logger.info(f'Batch train loss {metrics}')\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        print(f'Train loss: {metrics[\"avg_train_loss\"]}')\n",
    "\n",
    "    def on_validation_batch_end(self, outputs, batch, batch_idx):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "#         logger.info(f'Batch validation loss {metrics}')\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        print(f'Val loss: {metrics[\"avg_val_loss\"]}')\n",
    "\n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "\n",
    "#     def prepare_data(self):\n",
    "#         self.data = nn.utils.rnn.pad_sequence(self.data)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            train_size = int(0.9 * len(self.data))\n",
    "            val_size = len(self.data) - train_size\n",
    "            self.data_train, self.data_val = random_split(self.data, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "            self.loss_func = recon_loss\n",
    "        \n",
    "        if stage == 'fit_2':\n",
    "            train_size = int(0.9 * self.data.shape[1])\n",
    "            val_size = self.data.shape[1] - train_size\n",
    "            self.data_train, self.data_val = random_split(self.data, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "            self.loss_func = total_loss\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "#         if stage == \"test\" or stage is None:\n",
    "#             self.data_test\n",
    "#             self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.data_train, batch_size=self.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.data_val, batch_size=self.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "#     def test_dataloader(self):\n",
    "#         return DataLoader(self.mnist_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chechpoint_path = \"checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ø–µ—Ä–≤—ã–π —ç—Ç–∞–ø –æ–±—É—á–µ–Ω–∏—è\n",
    "data = NYDataset(embeddings, input_ids)\n",
    "model = LitERAE(data)\n",
    "model.train()\n",
    "\n",
    "# —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –ª—É—á—à–∏–µ –ø–æ –º–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=chechpoint_path, save_top_k=2, monitor=\"val_loss\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=20,\n",
    "    num_nodes=1,\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitERAE.load_from_checkpoint(checkpoint_path=checkpoint_callback.best_model_path, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –≤—Ç–æ—Ä–æ–π —ç—Ç–∞–ø –æ–±—É—á–µ–Ω–∏—è\n",
    "model.stage = 'fit_2'\n",
    "model.train()\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=chechpoint_path, save_top_k=2, monitor=\"val_loss\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=20,\n",
    "    progress_bar_refresh_rate=20,\n",
    "    gpus=1,\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitERAE.load_from_checkpoint(checkpoint_path=checkpoint_callback.best_model_path, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'epoch=0-step=243-v1.ckpt'  'epoch=19-step=4860-v1.ckpt'\n",
      "'epoch=0-step=243.ckpt'     'epoch=19-step=4860.ckpt'\n",
      "'epoch=14-step=3645.ckpt'   'epoch=3-step=972.ckpt'\n",
      "'epoch=18-step=4617.ckpt'   'epoch=5-step=1458.ckpt'\n"
     ]
    }
   ],
   "source": [
    "# !ls checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = NYDataset(embeddings, input_ids)\n",
    "model = LitERAE.load_from_checkpoint(checkpoint_path='checkpoints/epoch=19-step=4860-v1.ckpt', data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π —Å–ª–æ–≤ –∏–∑ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "\n",
    "–ø—Ä–æ –Ω–µ—ë –ø–æ–¥—Ä–æ–±–Ω–µ–µ –ª—É—á—à–µ –ø–æ—á–∏—Ç–∞—Ç—å –≤ —Å—Ç–∞—Ç—å–µ ER-AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_mechanism(pho, epsilon, delta):\n",
    "    pho = np.array(pho)\n",
    "    temp = np.exp(epsilon / (2 * delta) * pho)\n",
    "    return temp / np.sum(temp)\n",
    "\n",
    "\n",
    "def predict(model, sent, seed=None):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    inp = get_embedding(sent)[0].unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        logits = model(inp)[0]\n",
    "    \n",
    "    predicted_probs = torch.softmax(logits, dim=-1)\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    def build_two_sets(probs, k=5):\n",
    "        # return lexical set and semantic set\n",
    "        probs = np.array(probs)\n",
    "        l_set = rng.choice(probs.shape[0], k, p=probs, replace=True)\n",
    "        l_set_probs = probs[l_set]\n",
    "\n",
    "        marks = np.ones(probs.shape[0], dtype=bool)\n",
    "        marks[l_set] = False\n",
    "\n",
    "        whole_idxs = np.arange(probs.shape[0])\n",
    "        s_set = whole_idxs[marks]\n",
    "        s_set_probs = probs[marks]\n",
    "\n",
    "        return l_set, s_set, l_set_probs, s_set_probs\n",
    "\n",
    "    def choose_set(l_set, s_set, l_set_probs, s_set_probs, eps=80):\n",
    "        probs = [0, 0]\n",
    "        probs[0] = np.sum(l_set_probs) / (np.sum(l_set_probs) + np.sum(s_set_probs))\n",
    "        probs[1] = 1 - probs[0]\n",
    "        probs = exponential_mechanism(probs, eps, 1)\n",
    "        po = [(l_set, l_set_probs), (s_set, s_set_probs)]\n",
    "        indxs = [0, 1]\n",
    "        indx = int(rng.choice(indxs, 1, p=probs))\n",
    "        return po[indx]\n",
    "\n",
    "    for probs in predicted_probs:\n",
    "        # build set\n",
    "        l_set, s_set, l_set_probs, s_set_probs = build_two_sets(probs, k=5)\n",
    "\n",
    "        # choose set\n",
    "        c_set, c_set_probs = choose_set(l_set, s_set, l_set_probs, s_set_probs)\n",
    "\n",
    "        # choose token\n",
    "        token_eps = 0.1\n",
    "        c_set_probs = exponential_mechanism(c_set_probs, token_eps, 1)\n",
    "        token_idx = int(rng.choice(c_set, 1, p=c_set_probs))\n",
    "\n",
    "        if token_idx == EOS_TOKEN_ID:\n",
    "            break\n",
    "        res.append(token_idx)\n",
    "#     o_pred = ' '.join([self.params['idx2word'][idx] for idx in res])\n",
    "#     o_pred = tokenizer.decode(res, skip_special_tokens=True)\n",
    "    o_pred = ' '.join(idx2token[idx] for idx in res[1:])\n",
    "    return o_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Original>:\n",
      "miss twin peaksis next saturday night at @joespub ! will you be there? @schafferthedarklord @revlegsmalone @bunnybuxom @booboodarlin @seedyedie @holly_honeypot @francineld @minxarcana @loganlaveau @ameliabareparts @varlavelour photos & design by @francinefoto     : joespub.com\n",
      "--------------------------------->\n",
      "<Transformed>:\n",
      "mar green queens new saturday night at @ drinking ! will you be there ? @ baristanet @ therealdjlito @ kodilee1111 @ diamondharding @ seedyedie @ seedyedie _ eq @ francineld @ minxarcana @ smoovebabii @ status @ salmon clothing & design by @ speedyromeo : hofbraeumuenchen . com\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "text = test_posts.text[test_posts.index[1]]\n",
    "print('<Original>:')\n",
    "print(text)\n",
    "print('--------------------------------->')\n",
    "print('<Transformed>:')\n",
    "print(predict(model, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Original>:\n",
      "ladies and gentlemen! we are almost fully booked for 2020 new year party but still have some availabilities, but literally couple of tables....literally  718-513-6004\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "ladies and gentlemen ! we are almost simply booked for 2020 new year party but still have some availabilities , but literally couple of tables . . . . literally 718 - 673 - 6004\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "a new perspective on an old favorite... that's what the new year can gift to you! good food and great  at @sistersbklyn (900 fulton). : @stefanieeesays\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "a new formation on an old favorite . . . that ' s what the new year can gift to you ! good food and great at @ clifton ( 900 fulton ) . : @ kohl\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "today was a blessing i got to see my family and my  sister\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "today was a lil i got to see my family and my soul\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "taboga  saturday 05/25 /19 apptetizer + main course + dessert [ + 2 hrs unlimited mimosa / sangria / punch ] only for $35.00 music by: ecraze stay_liifted pesao anthony rey free free hookah from 1pm-5pm . .. rsvp: 917-330-9248 tex .. taboga by oleaga restaurant . billiard . barbershop 421 w 202nd st, new york, ny 10034 .. ..\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "taboga saturday 05 / 25 / 19 apptetizer + main course + dessert [ + 2 hrs unlimited estylez / sangria / punch ] only for $ 35 . 00 music by : ecraze stay _ liifted pesao anthony rey free free hookah from 1pm - 5pm . . . rsvp : 917 - 330 - 9248 tex . . taboga by oleaga restaurant . billiard . barbershop 421 w 202nd st , new york , ny 10034 . . . .\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "it's officially summer  'call out mondays' @fortythirdstreetcafe with @djyoungfresh is the place to be!! open bar menu selection. (8pm-9pm)  free admission & $2 crabs. now that's a party! 1425 springfield ave. irvington, nj @bass_entertainment  & @scott2289 turn up the heat on a monday\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "it ' s officially summer ' call out mondays ' @ fortythirdstreetcafe with @ djyoungfresh is the place to be ! ! open bar menu selection . ( 8pm - 9pm ) free admission & $ 2 crabs . now that ' s a party ! 1425 springfield ave . irvington , nj @ bass _ entertainment & @ scott2289 turn up the heat on a monday\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "this saturday party with us at the dopest comedy show on the northern tip of manhattan. when? 23 feb 2019. seats @ 9:30p, first come! where? @theparkviewcafe the park view, 219 dyckman st, nyc. 2 items min. no cover! seats go fast; rsvp now w/ link in profile , or here: <url>   special guest host: @leevalentin nataly aukar @natyourcolor kevin berrey @berrey tayler yarish @tayleryarish drexton clemons @thisguydrex erik helewa @erik_helewa brittanie sheree @brittisfunny   !! !!!\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "this saturday party with us at the dopest comedy show on the northern tip of manhattan . when ? 23 feb 2019 . seats @ 9 : 30p , first come ! where ? @ theparkviewcafe the park view , 219 dyckman st , nyc . 2 items min . no cover ! seats go fast ; rsvp now w / link in profile , or here : < url > special guest tv : @ leesyatt adventurous italy @ natyourcolor kevin berrey @ berrey tayler yarish @ tayleryarish drexton clemons @\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "are you around nyc next weekend?  the vibrant and inspiring time of bushwick open studios is happening in synch with the fall equinox  daya will be participating and we have so many wonderful offerings coming your way! ! ! . . . fri 9/20 7p: 108 sun salutations to celebrate the fall equinox with ania lesniak @daya_mama 7-10p: art viewing . . sat 9/21 8a: cacao ceremony with erika laila @truthseekerdivinationnyc 2-5:30p: psychic fair ( tarot reading, natal chart reading, astrology reading, cupping & much more ) 6:30p: interactive performance with ania & mariya dimov @mariyadimov 7:45p: pierce boaz comedy 8-9p: interactive experience with michael doonan @michaeldoonan . . sun 9/22 block party in collaboration with house of yes 12-1p: kirtan with ania & carmina 1-2p: performative yoga with nikki ortiz @nikki_ortiz 2-3p: meditation for manifestation with diana & patrick @emily_cremona 3-4p: daya dance with ania 4-5p: sound bath with andrea baquero @soundandvibe . . art viewing 2-5p tarantella dance 7-10pm with alessendrana belloni @belloni.alessandra   . . photo by : @houseofyesnyc\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "are you around nyc next weekend ? the sweetest and ink time of mental open studios is happening in wonderland with the fall equinox daya will be phones and we have so many wonderful reviews bring your way ! ! ! . . . coloration 9 / 20 son : 108 son congratulations to celebrate the fall equinox with maria djbeluccinyc @ daya _ july 7 - 11 : art words . . pick 9 / 21 decent : cacao photo with maria maria @ pardon 2 - 5 : 30p\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "this sweetheart performs at this casita every friday at 11. join @leeburgos, her band and our familia, we guarantee you a fabulous night.\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "this buratta poets at this queen every friday at 11 . join @ leeburgos , her band and our familia , we cmlauriecumbo you a homemade night .\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "chef david and our talented team here at the caldwell bakery will help you design the perfect cake for any occasion, from weddings to birthdays and everything in between\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "chef david and our talented team here at the caldwell bakery will help you design the perfect cake for any occasion , from weddings to birthdays and everything in between\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "...even on a rainy day  check out our boutique for the latest & greatest!\n",
      "------------------------>\n",
      "<Transformed>:\n",
      ". . . even on a rainy day check out our boutique for the latest & soundbaths !\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "test_texts = test_posts.text\n",
    "for i in range(100, 110):\n",
    "    text = test_texts[test_posts.index[i]]\n",
    "    print('<Original>:')\n",
    "    print(text)\n",
    "    print('------------------------>')\n",
    "    print('<Transformed>:')\n",
    "    print(predict(model, text))\n",
    "    print('\\n------------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtags anonymization\n",
    "\n",
    "–ø—Ä–æ–±–æ–≤–∞–ª –¥–µ–ª–∞—Ç—å –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—é —Ö—ç—à—Ç–µ–≥–æ–≤, –Ω–æ –¥–∞–ª—å—à–µ –Ω–µ –ø–æ—à–ª–æ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SynTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nyc_posts_authors_df.loc[nyc_posts_authors_df['hashtags'].str.len() > 50, 'hashtags'][:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#bike #bikes #bikelife #shopride #shoplife #myfavoritebikeshop #bikeclub #bikenyc #bikeny #croton #crotonaqueduct #gravelgrinder #gravel #gravelride #offroad'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18078"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "s = set(chain.from_iterable(docs.str.split()))\n",
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_model = CountVectorizer(ngram_range=(1,1))\n",
    "X = count_model.fit_transform(docs)\n",
    "Xc = (X.T * X)\n",
    "Xc.setdiag(0)\n",
    "Xc = Xc.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5119884,\n",
       " matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 5, 5],\n",
       "         [0, 0, 0, ..., 5, 0, 5],\n",
       "         [0, 0, 0, ..., 5, 5, 0]]))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc.sum(), Xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13364, 13364)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.4684e-05, 7.4684e-05, 7.4684e-05,  ..., 7.4684e-05, 7.4684e-05,\n",
       "         7.4684e-05],\n",
       "        [7.4582e-05, 7.4582e-05, 7.4582e-05,  ..., 7.4582e-05, 7.4582e-05,\n",
       "         7.4582e-05],\n",
       "        [7.3181e-05, 7.3181e-05, 7.3181e-05,  ..., 7.3181e-05, 7.3181e-05,\n",
       "         7.3181e-05],\n",
       "        ...,\n",
       "        [3.0429e-07, 3.0429e-07, 3.0429e-07,  ..., 3.0429e-07, 4.5161e-05,\n",
       "         4.5161e-05],\n",
       "        [3.0429e-07, 3.0429e-07, 3.0429e-07,  ..., 4.5161e-05, 3.0429e-07,\n",
       "         4.5161e-05],\n",
       "        [3.0429e-07, 3.0429e-07, 3.0429e-07,  ..., 4.5161e-05, 4.5161e-05,\n",
       "         3.0429e-07]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc = torch.softmax(torch.from_numpy(Xc).float(), dim=-1)\n",
    "Xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0000), tensor(7.4684e-05))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc[0].sum(), Xc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "tfidf.fit(docs)\n",
    "doc_vecs = tfidf.transform(docs)\n",
    "doc_vecs = normalize(doc_vecs, norm='l1')\n",
    "words = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18063"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1405975, 5131770)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft = fasttext.load_facebook_model(datapath('/mnt/ess_storage/DN_1/storage/home/vpanov/cc.en.300.bin.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc[count_model.vocabulary_['newyork']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13364, 13364)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vecs = [Xc[count_model.vocabulary_[word]].tolist()[0] for word in words]\n",
    "word_similarities = cosine_similarity(word_vecs, word_vecs)\n",
    "word_similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kgram_overlap(word1, word2, k):\n",
    "    a = set([word1[i:i+k] for i in range(0, len(word1) - k + 1)])\n",
    "    b = set([word2[i:i+k] for i in range(0, len(word2) - k + 1)])\n",
    "    inter = len(a.intersection(b))\n",
    "    return inter / (len(a) + len(b) - inter)\n",
    "\n",
    "def score(word1, word2):\n",
    "    idx1, idx2 = tfidf.vocabulary_[word1], tfidf.vocabulary_[word2]\n",
    "    return word_similarities[idx1, idx2] - 0.3 * kgram_overlap(word1, word2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likes4like ['turkiye']\n"
     ]
    }
   ],
   "source": [
    "def exponential_gen(x, R, u, sensitivity=1, epsilon=25.4):\n",
    "    # Calculate the score for each element of R\n",
    "    scores = [u(x, r) for r in R]\n",
    "    \n",
    "    # Calculate the probability for each element, based on its score\n",
    "    probabilities = [np.exp(epsilon * score / (2 * sensitivity)) for score in scores]\n",
    "    \n",
    "    # Normalize the probabilties so they sum to 1\n",
    "    probabilities = probabilities / np.linalg.norm(probabilities, ord=1)\n",
    "\n",
    "    # Choose an element from R based on the probabilities\n",
    "    return np.random.choice(R, 1, p=probabilities)\n",
    "\n",
    "num = 7000\n",
    "print(words[num], exponential_gen(words[num], words, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13364, 13364)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exponential(x, R, u, sensitivity=1, epsilon=25.4):\n",
    "    # Calculate the score for each element of R\n",
    "    scores = [u(x, r) for r in R]\n",
    "    \n",
    "    # Calculate the probability for each element, based on its score\n",
    "    probabilities = [np.exp(epsilon * score / (2 * sensitivity)) for score in scores]\n",
    "    \n",
    "    # Normalize the probabilties so they sum to 1\n",
    "    probabilities = probabilities / np.linalg.norm(probabilities, ord=1)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "word_replace_probs = []\n",
    "\n",
    "for idx, word in enumerate(words):\n",
    "    if idx % 1000 == 0:\n",
    "        print(idx)\n",
    "    word_replace_probs.append(exponential(word, words, score))\n",
    "\n",
    "word_replace_probs = np.array(word_replace_probs)\n",
    "word_replace_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--ORIGINAL--\n",
      "#EATDRINKPARTY #miercolesplayero #bronx #BottleSpecials #bestiakitchenbx #LaBestiaDelBronx #HappyHour #PartyPeople #FoodPorn #salsa #playero #retro #4thofjulyparty #preindependenceday #preindependencedayparty\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "gaynightlife nbafinals2019 bachata miercolesplayero eatdrinkparty nbafinals2019 santiago 4thofjulyparty caucau 4thofjulyparty lentejitas nycdrinks ericktorres latino 4thofjulyparty\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "#914 #newrochelle #newrochelleny #ionacollege #westchester #westchesterny #westchestereats #westchesternyeats #westchestercountyny #westchestercounty #westchesterfood #westchesterfoodie #tuckahoeny #tuckahoe #eastchester #eastchesterny #larchmont #larchmontny #larchmontvillage #pelhamny #yonkers #yonkersny #bronxville #bronxvilleny #burgersandbeer #bestwings\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "westchestereats burgersandfries jameson yonkersny jameson latenightfood larchmontny larchmont yonkers yonkers panini phillycheesesteak tuckahoe titosvodka pelhammanor larchmontny bestwingsever jamesonwhiskey bestwings yonkers newrochelle burgersandfries salad westchesternyeats jamesonwhiskey yonkers\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "#effigies #forevergrounded #record #punk #1984 #theeffigies #records #vinyl #newyorkcity #recordsforsale #carrollgardens #redhook #chicago #punkrock #vinylporn #recordshop #hardcorepunk #vinyligclub #rock #almostreadyrecords #vinylforsale #webuyvinyl #buyselltrade #nyc #brooklyn #vinylrecord #enigma #lp\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "carlitosway stooges thebeatles almostready citoferminorchestra 33rpm 1970 effigies 1996 reissue thedictatorsnyc records mysaxophoneforchristmas modusoperandi doom thecity sealed almostchristmas miccitysons redhook redvinyl enigma effigies alifewithoutobstacles jamesbrown recordporn countryteasers ska\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "#10yearchallenge #tgif #1 #happyhour #78loungenj #drinks #food #birthday #turnup #party #goodlife #nightlife #dj #like4like #goodtime #friends #family #followme #instaselfie #swag #follow #newjersey #friday #flashbackfriday\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "followme 78lifestyle amazonbooks tournament 78loungenj theheavyhitterdjs sipandpaint friends niceandsmooth family friends lawenforcement goodtime ncaa favorite followme goodlife nightlife 78lounge stpattysday theheavyhitterdjs budin dj djcoolv\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "#birthdayparties #halloween #halloweenparty2019 #thecomplexnyc #birthday #bubbleball #bubbleballsoccer #halloweenpartylic #halloweenpartyastoria #bubbleballny #adults #bounce #astoria #lic #astoriaqueens #queens #birthdayparties #newyork #astoriaqueensny #astoriaqueens #queens #fun #kids #funkids #family #astoriasportscomplex #costumeparty #prizes #halloweenpartynyc #kidshalloweenparty #kidshalloweenparty2019 #halloweenpartyny #nychalloweenparty\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "birthdayparties funkids babysharkchallenge nerfgun halloweenpartynyc swag knockerballnyc halloweenpartynyc kids lic kidshalloweenparty2018 hocuspocustrivia animalshow magicshownyc costumeparty costumeparty funkids swimlessons funkids bubbleballsoccer bubbleballsoccer bubbleballsoccer halloweenpartyny astoriaqueensny bubbleballsoccer halloweenpartyny november bubblesoccer bubbleballsoccer indoors astoriaqueensny bubbleballnyc kidshalloweenparty2018\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for idx, doc in enumerate(docs[:5]):\n",
    "    print('--ORIGINAL--')\n",
    "    print(doc)\n",
    "    print('--GENERATED SEQUENCE (WITHOUT WORD ORDER)--')\n",
    "    words_count = len(doc.split())\n",
    "    words_ = np.random.choice(words, words_count, p=doc_vecs[idx].todense().tolist()[0])\n",
    "    for i in range(words_count):\n",
    "        word_idx = tfidf.vocabulary_[words_[i]]\n",
    "        words_[i] = np.random.choice(words, 1, p=word_replace_probs[word_idx])[0]\n",
    "    print(' '.join(words_))\n",
    "    print('-'*150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtags magic\n",
    "–ü—ã—Ç–∞–ª—Å—è —Å–¥–µ–ª–∞—Ç—å –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—é —Ö—ç—à—Ç–µ–≥–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ SynTF, –¥–∞–ª—å—à–µ –Ω–µ –ø–æ—à–ª–æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nyc_posts_authors_df.loc[nyc_posts_authors_df['hashtags'].str.len() > 50, 'hashtags'][:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3536335, 10212810)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags = docs.str.split().tolist()\n",
    "\n",
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=5,\n",
    "                     vector_size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=10)\n",
    "w2v_model.build_vocab(hashtags, progress_per=1000)\n",
    "w2v_model.train(hashtags, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#tagforlikes', 0.747814416885376),\n",
       " ('#wedding', 0.7455034255981445),\n",
       " ('#like', 0.7374163866043091),\n",
       " ('#barmitzvah', 0.7349600791931152),\n",
       " ('#aniversary', 0.7308018803596497),\n",
       " ('#selfie', 0.7256142497062683),\n",
       " ('#foody', 0.7172373533248901),\n",
       " ('#picoftheday', 0.7157788276672363),\n",
       " ('#restaurants', 0.7054566740989685),\n",
       " ('#happy', 0.7051026225090027)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('#newyork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#birthday', 0.9645171165466309),\n",
       " ('#aniversary', 0.9628538489341736),\n",
       " ('#restaurants', 0.9571098685264587),\n",
       " ('#barmitzvah', 0.954374372959137),\n",
       " ('#tagforlikes', 0.932794451713562),\n",
       " ('#sushi', 0.9251395463943481),\n",
       " ('#foody', 0.921452522277832),\n",
       " ('#like', 0.9046717882156372),\n",
       " ('#selfie', 0.885693371295929),\n",
       " ('#appetizer', 0.8824301958084106)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('#wedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/\n",
    "\n",
    "def levenshteinDistanceDP(token1, token2):\n",
    "    distances = numpy.zeros((len(token1) + 1, len(token2) + 1))\n",
    "\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "#     printDistances(distances, len(token1), len(token2))\n",
    "    return distances[len(token1)][len(token2)]\n",
    "\n",
    "def kgram_overlap(word1, word2, k):\n",
    "    a = set([word1[i:i+k] for i in range(0, len(word1) - k + 1)])\n",
    "    b = set([word2[i:i+k] for i in range(0, len(word2) - k + 1)])\n",
    "    inter = len(a.intersection(b))\n",
    "    return inter / (len(a) + len(b) - inter + 1)\n",
    "\n",
    "def score(word1, word2):\n",
    "    return w2v_model.wv.similarity(word1, word2) - 0.5 * kgram_overlap(word1, word2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#newyork ['#happy']\n"
     ]
    }
   ],
   "source": [
    "# def get_replace(word, k=5, seed=None):\n",
    "#     repls = [(repl, score(word, repl)) for repl, _ in w2v_model.wv.most_similar(word, topn=k)]\n",
    "#     repls.sort(key=lambda x: x[1], reverse=True)\n",
    "#     rng = np.random.default_rng(seed)\n",
    "#     return rng.choice(repls, p=[score for _, score in repls])[0]\n",
    "\n",
    "# get_replace('#newyork')\n",
    "\n",
    "words = list(w2v_model.wv.key_to_index.keys())\n",
    "\n",
    "def exponential_gen(x, R, u, sensitivity=1, epsilon=25.4, seed=None):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    # Calculate the score for each element of R\n",
    "    scores = [u(x, r) for r in R]\n",
    "    \n",
    "    # Calculate the probability for each element, based on its score\n",
    "    probabilities = [np.exp(epsilon * score / (2 * sensitivity)) for score in scores]\n",
    "    \n",
    "    # Normalize the probabilties so they sum to 1\n",
    "    probabilities = probabilities / np.linalg.norm(probabilities, ord=1)\n",
    "\n",
    "    # Choose an element from R based on the probabilities\n",
    "    return rng.choice(R, 1, p=probabilities)\n",
    "\n",
    "word = '#newyork'\n",
    "print(word, exponential_gen(word, words, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2242, 2242)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exponential(x, R, u, sensitivity=1, epsilon=25.4, seed=None):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # Calculate the score for each element of R\n",
    "    scores = [u(x, r) for r in R]\n",
    "    \n",
    "    # Calculate the probability for each element, based on its score\n",
    "    probabilities = [np.exp(epsilon * score / (2 * sensitivity)) for score in scores]\n",
    "    \n",
    "    # Normalize the probabilties so they sum to 1\n",
    "    probabilities = probabilities / np.linalg.norm(probabilities, ord=1)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "word_replace_probs = []\n",
    "\n",
    "for idx, word in enumerate(words):\n",
    "    if idx % 1000 == 0:\n",
    "        print(idx)\n",
    "    word_replace_probs.append(exponential(word, words, score))\n",
    "\n",
    "word_replace_probs = np.array(word_replace_probs)\n",
    "word_replace_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--ORIGINAL--\n",
      "#bike #bikes #bikelife #shopride #shoplife #myfavoritebikeshop #bikeclub #bikenyc #bikeny #croton #crotonaqueduct #gravelgrinder #gravel #gravelride #offroad\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "#bike #cycling #movesale #shopride #shoplife #myfavoritebikeshop #bikeclub #bikenyc #bikeny #croton #crotonaqueduct #gravelgrinder #gravel #gravelride #offroad\n",
      "----------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "#76ers #raptors #blazers #nuggets #labatt #genesse #molson #nba #nbaplayoffs #nba2019 #basketball #hoops #nbafirstround #beerandhoops #brooklynsportsbar\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "#76ers #warriors #blazers #nuggets #labatt #genesse #molson #nbaleaguepass #nbaplayoffs #nba2019 #basketball #hoops #nbafirstround #nba2019 #brooklynsportsbar\n",
      "----------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "#comicartsbrooklyn #prattinstitute #gianthand #art #fun\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "#comicartsbrooklyn #prattinstitute #gianthand #art #ff\n",
      "----------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "#spendinglabordaylaboring #creativelylaboring #lovemyjob #howmisskatiespendsholidays\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "#spendinglabordaylaboring #creativelylaboring #lovemyjob #howmisskatiespendsholidays\n",
      "----------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "#rolex #custom #diamonds #nj #store #ship #unmated #value #textme\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "#rolex #quality #unmatched #nj #refrigeradora #rolex #unmated #unmatched #diamonds\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "\n",
    "for idx, doc in enumerate(docs[:5]):\n",
    "    print('--ORIGINAL--')\n",
    "    print(doc)\n",
    "    print('--GENERATED SEQUENCE (WITHOUT WORD ORDER)--')\n",
    "    words_ = doc.split()\n",
    "    for i in range(len(words_)):\n",
    "        if rng.random() < 0.5 and words_[i] in w2v_model.wv:\n",
    "            word_idx = w2v_model.wv.key_to_index[words_[i]]\n",
    "            words_[i] = rng.choice(words, 1, p=word_replace_probs[word_idx])[0]\n",
    "    print(' '.join(words_))\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/gkhayes/author_attribution CNN AA model\n",
    "\n",
    "https://github.com/yunitata/continuous-n-gram-AA code for CNN AA experiments reproduce\n",
    "\n",
    "–ó–¥–µ—Å—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –∫–æ–¥ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π –¥–ª—è –∑–∞–¥–∞—á–∏ Author Identification. –°—É—Ç—å –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ –ø—Ä–æ–≤–µ—Ä–∫–µ, —á—Ç–æ –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –º–æ–¥–µ–ª—å—é –¥–ª—è Authorship Identification, –æ–±—É—á–µ–Ω–Ω–æ–π –Ω–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.\n",
    "\n",
    "–ö–æ–¥ –º–æ–¥–µ–ª–∏ –≤–∑—è—Ç –∏–∑ –ø–µ—Ä–≤–æ–π —Å—Å—ã–ª–∫–∏ –≤—ã—à–µ –∏ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = tokenizer.batch_decode(tokenizer(train_posts.text.tolist(), return_tensors=\"pt\", max_length=128, padding='max_length', truncation=True).input_ids, skip_special_tokens=True)\n",
    "text_test = tokenizer.batch_decode(tokenizer(test_posts.text.tolist(), return_tensors=\"pt\", max_length=128, padding='max_length', truncation=True).input_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_n_grams(excerpt_list, n, vocab_size, seq_size):\n",
    "    \"\"\"Create a list of n-gram sequences\n",
    "    \n",
    "    Args:\n",
    "    excerpt_list: list of strings. List of normalized text excerpts.\n",
    "    n: int. Length of n-grams.\n",
    "    vocab_size: int. Size of n-gram vocab (used in one-hot encoding)\n",
    "    seq_size: int. Size of n-gram sequences\n",
    "    \n",
    "    Returns:\n",
    "    n_gram_array: array. Numpy array of one-hot encoded n-grams.\n",
    "    \"\"\"\n",
    "    n_gram_list = []\n",
    "\n",
    "    for excerpt in excerpt_list:\n",
    "        # Remove spaces\n",
    "        excerpt = excerpt.replace(\" \", \"\")\n",
    "\n",
    "        # Extract n-grams\n",
    "        n_grams = [excerpt[i:i + n] for i in range(len(excerpt) - n + 1)]\n",
    "\n",
    "        # Convert to a single string with spaces between n-grams\n",
    "        new_string = \" \".join(n_grams)\n",
    "\n",
    "        # One hot encode\n",
    "        hot = one_hot(new_string, round(vocab_size*1.3))\n",
    "\n",
    "        # Pad hot if necessary\n",
    "        hot_len = len(hot)\n",
    "        if hot_len >= seq_size:\n",
    "            hot = hot[0:seq_size]\n",
    "        else:\n",
    "            diff = seq_size - hot_len\n",
    "            extra = [0]*diff\n",
    "            hot = hot + extra\n",
    "\n",
    "        n_gram_list.append(hot)\n",
    "    \n",
    "    n_gram_array = np.array(n_gram_list)\n",
    "    \n",
    "    return n_gram_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_size(excerpt_list, n, seq_size):\n",
    "    \"\"\"Calculate size of n-gram vocab\n",
    "    \n",
    "    Args:\n",
    "    excerpt_list: list of strings. List of normalized text excerpts.\n",
    "    n: int. Length of n-grams.\n",
    "    seq_size: int. Size of n-gram sequences\n",
    "    \n",
    "    Returns:\n",
    "    vocab_size: int. Size of n-gram vocab.\n",
    "    \"\"\"\n",
    "    n_gram_list = []\n",
    "\n",
    "    for excerpt in excerpt_list:\n",
    "        # Remove spaces\n",
    "        excerpt = excerpt.replace(\" \", \"\")\n",
    "\n",
    "        # Extract n-grams           \n",
    "        n_grams = [excerpt[i:i + n] for i in range(len(excerpt) - n + 1)]\n",
    "\n",
    "        # Create list of n-grams\n",
    "        gram_len = len(n_grams)\n",
    "        if gram_len >= seq_size:\n",
    "            n_grams = n_grams[0:seq_size]\n",
    "        else:\n",
    "            diff = seq_size - gram_len\n",
    "            extra = [0]*diff\n",
    "            n_grams = n_grams + extra\n",
    "        \n",
    "        n_gram_list.append(n_grams)\n",
    "    \n",
    "    # Flatten n-gram list\n",
    "    n_gram_list = list(np.array(n_gram_list).flat)\n",
    "    \n",
    "    # Calculate vocab size\n",
    "    n_gram_cnt = Counter(n_gram_list)\n",
    "    vocab_size = len(n_gram_cnt)\n",
    "    \n",
    "    return vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size for n = 4334476665 is: 32208\n"
     ]
    }
   ],
   "source": [
    "vocab_size = get_vocab_size(text_train, 3, 128)\n",
    "print('Vocab size for n =', i, 'is:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17271, 128)\n",
      "(1000, 128)\n"
     ]
    }
   ],
   "source": [
    "# Create n-gram lists\n",
    "gram3_train = create_n_grams(text_train, 3, vocab_size, 128)\n",
    "gram3_test = create_n_grams(text_test, 3, vocab_size, 128)\n",
    "\n",
    "print(np.shape(gram3_train))\n",
    "print(np.shape(gram3_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum encoding value for 3-grams is:  41868\n"
     ]
    }
   ],
   "source": [
    "max_3gram = np.max(gram3_train)\n",
    "\n",
    "print('Maximum encoding value for 3-grams is: ', max_3gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture in keras\n",
    "# Code reference: https://github.com/gkhayes/author_attribution\n",
    "def define_model(input_len, output_size, vocab_size, embedding_dim, verbose = True,\n",
    "                drop_out_pct = 0.25, conv_filters = 500, activation_fn = 'relu', pool_size = 2, learning = 0.0001):\n",
    "    \"\"\"Define n-gram CNN\n",
    "    \n",
    "    Args:\n",
    "    input_len: int. Length of input sequences.\n",
    "    output_size: int. Number of output classes.\n",
    "    vocab_size: int. Maximum value of n-gram encoding.\n",
    "    embedding_dim: int. Size of embedding layer.\n",
    "    verbose: bool. Whether or not to print model summary.\n",
    "    drop_out_pct: float. Drop-out rate.\n",
    "    conv_filters: int. Number of filters in the conv layer.\n",
    "    activation_fn: string. Activation function to use in the convolutional layer.\n",
    "    pool_size: int. Pool size for the max pooling layer.\n",
    "    learning: float. Learning rate for the model optimizer.\n",
    "    \n",
    "    Returns:\n",
    "    model: keras model object. \n",
    "    \"\"\"\n",
    "    # Channel 1\n",
    "    inputs1 = Input(shape = (input_len,))\n",
    "    embedding1 = Embedding(vocab_size, embedding_dim)(inputs1)\n",
    "    drop1 = Dropout(drop_out_pct)(embedding1)\n",
    "    conv1 = Conv1D(filters = conv_filters, kernel_size = 3, activation = activation_fn)(drop1)\n",
    "    pool1 = MaxPooling1D(pool_size = pool_size)(conv1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    \n",
    "    # Channel 2\n",
    "    inputs2 = Input(shape = (input_len,))\n",
    "    embedding2 = Embedding(vocab_size, embedding_dim)(inputs2)\n",
    "    drop2 = Dropout(drop_out_pct)(embedding2)\n",
    "    conv2 = Conv1D(filters = conv_filters, kernel_size = 4, activation = activation_fn)(drop2)\n",
    "    pool2 = MaxPooling1D(pool_size = pool_size)(conv2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "\n",
    "    # Channel 3\n",
    "    inputs3 = Input(shape = (input_len,))\n",
    "    embedding3= Embedding(vocab_size, embedding_dim)(inputs3)\n",
    "    drop3 = Dropout(drop_out_pct)(embedding3)\n",
    "    conv3 = Conv1D(filters = conv_filters, kernel_size = 5, activation = activation_fn)(drop3)\n",
    "    pool3 = MaxPooling1D(pool_size = pool_size)(conv3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    \n",
    "    # Merge channels\n",
    "    merged = Concatenate()([flat1, flat2, flat3])\n",
    "    \n",
    "    # Create output layer\n",
    "    output = Dense(output_size, activation = 'softmax')(merged)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = [inputs1, inputs2, inputs3], outputs = output)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer = Adam(lr = learning), metrics=['accuracy'])\n",
    "    \n",
    "    if verbose:\n",
    "        print(model.summary())\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = preprocessing.LabelEncoder()\n",
    "\n",
    "author_train = lb.fit_transform(train_posts.authorid.values)\n",
    "author_train_hot = pd.get_dummies(author_train).values\n",
    "author_test = lb.transform(test_posts.authorid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 128, 600)     25121400    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 128, 600)     25121400    ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 128, 600)     25121400    ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128, 600)     0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128, 600)     0           ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 128, 600)     0           ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 126, 500)     900500      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 125, 500)     1200500     ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 124, 500)     1500500     ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 63, 500)      0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 62, 500)     0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 62, 500)     0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 31500)        0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 31000)        0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 31000)        0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 93500)        0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 50)           4675050     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 83,640,750\n",
      "Trainable params: 83,640,750\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create the 3-gram model\n",
    "gram3_model = define_model(128, len(train_posts.authorid.unique()), max_3gram + 1, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "432/432 [==============================] - 43s 84ms/step - loss: 3.4250 - accuracy: 0.2062 - val_loss: 2.9596 - val_accuracy: 0.3988\n",
      "Epoch 2/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 2.1771 - accuracy: 0.5316 - val_loss: 1.8056 - val_accuracy: 0.5902\n",
      "Epoch 3/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 1.0756 - accuracy: 0.7855 - val_loss: 1.2396 - val_accuracy: 0.6973\n",
      "Epoch 4/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.4933 - accuracy: 0.9173 - val_loss: 0.9964 - val_accuracy: 0.7465\n",
      "Epoch 5/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.2075 - accuracy: 0.9784 - val_loss: 0.8906 - val_accuracy: 0.7670\n",
      "Epoch 6/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0877 - accuracy: 0.9957 - val_loss: 0.8383 - val_accuracy: 0.7754\n",
      "Epoch 7/15\n",
      "432/432 [==============================] - 36s 84ms/step - loss: 0.0403 - accuracy: 0.9990 - val_loss: 0.8217 - val_accuracy: 0.7899\n",
      "Epoch 8/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.8080 - val_accuracy: 0.7887\n",
      "Epoch 9/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.8004 - val_accuracy: 0.7931\n",
      "Epoch 10/15\n",
      "432/432 [==============================] - 36s 82ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.8001 - val_accuracy: 0.7968\n",
      "Epoch 11/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.8027 - val_accuracy: 0.7977\n",
      "Epoch 12/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8060 - val_accuracy: 0.7962\n",
      "Epoch 13/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8111 - val_accuracy: 0.7974\n",
      "Epoch 14/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8191 - val_accuracy: 0.7977\n",
      "Epoch 15/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8237 - val_accuracy: 0.7991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5a5f6c2e0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram3_model.fit([gram3_train, gram3_train, gram3_train], author_train_hot, epochs=15, batch_size=32, \n",
    "                verbose = 1, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.769\n",
      "Ave. Precision: 0.7850834130833794\n",
      "Ave. Recall: 0.769\n",
      "Ave. F1 Score: 0.7724860715050913\n",
      "Prediction Time: 0.4052286148071289 seconds\n",
      "Confusion Matrix:\n",
      " [[17  1  0 ...  0  0  0]\n",
      " [ 0 15  0 ...  0  0  0]\n",
      " [ 0  0 19 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 15  1  0]\n",
      " [ 0  0  0 ...  0 16  0]\n",
      " [ 0  0  0 ...  0  0 20]]\n"
     ]
    }
   ],
   "source": [
    "# —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è Autorship Identification –Ω–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª\n",
    "\n",
    "# t0 = time.time()\n",
    "\n",
    "# # Fit model\n",
    "# model1 = define_model(128, len(train_posts.authorid.unique()), max_3gram + 1, 300)\n",
    "# model1.fit([gram3_train, gram3_train, gram3_train], author_train_hot, epochs=10, batch_size=32, \n",
    "#            verbose = 1, validation_split = 0.2)\n",
    "t1 = time.time()\n",
    "\n",
    "# Predict values for test set\n",
    "author_pred1 = gram3_model.predict([gram3_test, gram3_test, gram3_test]).argmax(-1)\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "# Evaluate\n",
    "accuracy = balanced_accuracy_score(author_test, author_pred1)\n",
    "precision, recall, f1, support = score(author_test, author_pred1, average='weighted')\n",
    "confusion = confusion_matrix(author_test, author_pred1)\n",
    "    \n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Ave. Precision:\", precision)\n",
    "print(\"Ave. Recall:\", recall)\n",
    "print(\"Ave. F1 Score:\", f1)\n",
    "# print(\"Training Time:\", (t1 - t0), \"seconds\")\n",
    "print(\"Prediction Time:\", (t2 - t1), \"seconds\")\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "\n",
    "with open('attacker.txt', 'w') as f:\n",
    "    print(\"Accuracy:\", accuracy, file=f)\n",
    "    print(\"Ave. Precision:\", precision, file=f)\n",
    "    print(\"Ave. Recall:\", recall, file=f)\n",
    "    print(\"Ave. F1 Score:\", f1, file=f)\n",
    "    print(\"Confusion Matrix:\\n\", confusion, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_states_batch(encoded, model, layers):\n",
    "    \"\"\"Push input IDs through model. Stack and sum `layers` (last four by default).\n",
    "        Select only those subword token outputs that belong to our word of interest\n",
    "        and average them.\"\"\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        states = model(**encoded).hidden_states\n",
    " \n",
    "    batch_res = []\n",
    "    \n",
    "    for i in range(len(states[0])):\n",
    "        token_ids_words = encoded.word_ids(i)\n",
    "        output = torch.stack([states[layer][i] for layer in layers]).sum(0).squeeze().cpu()\n",
    "\n",
    "        res = []\n",
    "        labels_count = []\n",
    "\n",
    "        for idx, (outp, label) in enumerate(zip(output, token_ids_words)):\n",
    "            if label is None or token_ids_words[idx - 1] is None or token_ids_words[idx - 1] != token_ids_words[idx]:\n",
    "                res.append(outp)\n",
    "                labels_count.append(1)\n",
    "            else: \n",
    "                res[-1] += outp\n",
    "                labels_count[-1] += 1\n",
    "\n",
    "        res = torch.vstack(res)\n",
    "        res = res / torch.tensor(labels_count).float().unsqueeze(1)\n",
    "        \n",
    "        batch_res.append(res)\n",
    "    batch_res = nn.utils.rnn.pad_sequence(batch_res, batch_first=True, padding_value=0.0)\n",
    "    return batch_res\n",
    "\n",
    "def get_word_vectors_batch(sents, tokenizer, model, layers):\n",
    "    \"\"\"Get a word vector by first tokenizing the input sentence, getting all token idxs\n",
    "        that make up the word of interest, and then `get_hidden_states`.\"\"\"\n",
    "    \n",
    "    encoded = tokenizer.batch_encode_plus(sents, return_tensors=\"pt\", max_length=128, padding='max_length', truncation=True)\n",
    "\n",
    "    hidden_states = get_hidden_states_batch(encoded, model, layers)\n",
    "    return hidden_states\n",
    "\n",
    "def get_embedding_batch(docs, model=bert):\n",
    "    \"Get embedding for each word\"\n",
    "    layers = [-4, -3, -2, -1]\n",
    "    return get_word_vectors_batch(docs, tokenizer, model, layers)\n",
    "\n",
    "def predict_batch(model, sents, seed=None, batch_size=32, verbose=False, print_step=20):\n",
    "    model.eval()\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    def build_two_sets(probs, k=5):\n",
    "        # return lexical set and semantic set\n",
    "        probs = np.array(probs)\n",
    "        l_set = rng.choice(probs.shape[0], k, p=probs, replace=True)\n",
    "        l_set_probs = probs[l_set]\n",
    "\n",
    "        marks = np.ones(probs.shape[0], dtype=bool)\n",
    "        marks[l_set] = False\n",
    "\n",
    "        whole_idxs = np.arange(probs.shape[0])\n",
    "        s_set = whole_idxs[marks]\n",
    "        s_set_probs = probs[marks]\n",
    "\n",
    "        return l_set, s_set, l_set_probs, s_set_probs\n",
    "\n",
    "    def choose_set(l_set, s_set, l_set_probs, s_set_probs, eps=80):\n",
    "        probs = [0, 0]\n",
    "        probs[0] = np.sum(l_set_probs) / (np.sum(l_set_probs) + np.sum(s_set_probs))\n",
    "        probs[1] = 1 - probs[0]\n",
    "        probs = exponential_mechanism(probs, eps, 1)\n",
    "        po = [(l_set, l_set_probs), (s_set, s_set_probs)]\n",
    "        indxs = [0, 1]\n",
    "        indx = int(rng.choice(indxs, 1, p=probs))\n",
    "        return po[indx]\n",
    "    \n",
    "    o_pred = []\n",
    "    \n",
    "    for i in range(0, len(sents), batch_size):\n",
    "        batch = sents[i:i+batch_size]\n",
    "        inp = get_embedding_batch(batch)\n",
    "        with torch.no_grad():\n",
    "            logits = model(inp)\n",
    "\n",
    "        predicted_probs = torch.softmax(logits, dim=-1)\n",
    "    \n",
    "        for sent in predicted_probs:\n",
    "            res = []\n",
    "            for probs in sent:\n",
    "                # build set\n",
    "                l_set, s_set, l_set_probs, s_set_probs = build_two_sets(probs, k=5)\n",
    "\n",
    "                # choose set\n",
    "                c_set, c_set_probs = choose_set(l_set, s_set, l_set_probs, s_set_probs)\n",
    "\n",
    "                # choose token\n",
    "                token_eps = 0.1\n",
    "                c_set_probs = exponential_mechanism(c_set_probs, token_eps, 1)\n",
    "                token_idx = int(rng.choice(c_set, 1, p=c_set_probs))\n",
    "\n",
    "                if token_idx == EOS_TOKEN_ID:\n",
    "                    break\n",
    "                res.append(token_idx)\n",
    "        #     o_pred = tokenizer.decode(res, skip_special_tokens=True)\n",
    "            o_pred.append(' '.join(idx2token[idx] for idx in res[1:]))\n",
    "        \n",
    "        if verbose and (i % (print_step * batch_size)) == 0:\n",
    "            print(i)\n",
    "\n",
    "    return o_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "640\n",
      "1280\n",
      "1920\n",
      "2560\n",
      "3200\n",
      "3840\n",
      "4480\n",
      "5120\n",
      "5760\n",
      "6400\n",
      "7040\n",
      "7680\n",
      "8320\n",
      "8960\n",
      "9600\n",
      "10240\n",
      "10880\n",
      "11520\n",
      "12160\n",
      "12800\n",
      "13440\n",
      "14080\n",
      "14720\n",
      "15360\n",
      "16000\n",
      "16640\n"
     ]
    }
   ],
   "source": [
    "# –∞–Ω–æ–∏–º–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤, –∑–∞–Ω–∏–º–∞–µ—Ç –≥–¥–µ-—Ç–æ –ø–æ–ª—á–∞—Å–∞\n",
    "\n",
    "train__ = train_posts.text.tolist()\n",
    "model.eval()\n",
    "trans_train = predict_batch(model, train__, seed=42, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_vocab_size = get_vocab_size(trans_train, 3, 128)\n",
    "trans_gram3_train = create_n_grams(trans_train, 3, trans_vocab_size, 128)\n",
    "trans_max_3gram = np.max(trans_gram3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 128, 600)     25560600    ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 128, 600)     25560600    ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 128, 600)     25560600    ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128, 600)     0           ['embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 128, 600)     0           ['embedding_4[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 128, 600)     0           ['embedding_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 126, 500)     900500      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 125, 500)     1200500     ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 124, 500)     1500500     ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 63, 500)     0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 62, 500)     0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 62, 500)     0           ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 31500)        0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 31000)        0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 31000)        0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 93500)        0           ['flatten_3[0][0]',              \n",
      "                                                                  'flatten_4[0][0]',              \n",
      "                                                                  'flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 50)           4675050     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 84,958,350\n",
      "Trainable params: 84,958,350\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "432/432 [==============================] - 36s 84ms/step - loss: 3.4157 - accuracy: 0.1999 - val_loss: 2.9769 - val_accuracy: 0.3375\n",
      "Epoch 2/15\n",
      "432/432 [==============================] - 36s 84ms/step - loss: 2.1766 - accuracy: 0.5357 - val_loss: 1.8308 - val_accuracy: 0.5601\n",
      "Epoch 3/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 1.0984 - accuracy: 0.7745 - val_loss: 1.2582 - val_accuracy: 0.6903\n",
      "Epoch 4/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.5071 - accuracy: 0.9176 - val_loss: 1.0265 - val_accuracy: 0.7418\n",
      "Epoch 5/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.2198 - accuracy: 0.9761 - val_loss: 0.9059 - val_accuracy: 0.7679\n",
      "Epoch 6/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0929 - accuracy: 0.9947 - val_loss: 0.8691 - val_accuracy: 0.7708\n",
      "Epoch 7/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0424 - accuracy: 0.9991 - val_loss: 0.8682 - val_accuracy: 0.7742\n",
      "Epoch 8/15\n",
      "432/432 [==============================] - 36s 84ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.8423 - val_accuracy: 0.7792\n",
      "Epoch 9/15\n",
      "432/432 [==============================] - 36s 84ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.8485 - val_accuracy: 0.7777\n",
      "Epoch 10/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.8484 - val_accuracy: 0.7789\n",
      "Epoch 11/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.8568 - val_accuracy: 0.7826\n",
      "Epoch 12/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8595 - val_accuracy: 0.7861\n",
      "Epoch 13/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8628 - val_accuracy: 0.7826\n",
      "Epoch 14/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8718 - val_accuracy: 0.7858\n",
      "Epoch 15/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8801 - val_accuracy: 0.7849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5a4da8310>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the 3-gram model\n",
    "trans_gram3_model = define_model(128, len(train_posts.authorid.unique()), trans_max_3gram + 1, 600)\n",
    "trans_gram3_model.fit([trans_gram3_train, trans_gram3_train, trans_gram3_train], author_train_hot, epochs=15, batch_size=32, \n",
    "                verbose = 1, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test_posts.text.tolist()\n",
    "model.eval()\n",
    "trans_test = predict_batch(model, test_texts, seed=42)\n",
    "true_values = author_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted scores\n",
      "F1 score for original text: 0.7724860715050913\n",
      "F1 score for transformed text with transformed model: 0.762846199717533\n",
      "F1 score for transformed text with orig model: 0.013651526249251188\n",
      "\n",
      "Macro averaged scores\n",
      "F1 score for original text: 0.7724860715050913\n",
      "F1 score for transformed text with transformed model: 0.762846199717533\n",
      "F1 score for transformed text with orig model: 0.013651526249251186\n"
     ]
    }
   ],
   "source": [
    "# —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö, –¥–≤–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞: \n",
    "# 1) –º–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –ø—ã—Ç–∞–µ—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "# 2) –º–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –ø—ã—Ç–∞–µ—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –∞–Ω–æ–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "\n",
    "preds = gram3_model.predict([gram3_test, gram3_test, gram3_test]).argmax(-1)\n",
    "\n",
    "trans_vocab_size = get_vocab_size(trans_train, 3, 128)\n",
    "trans_gram3_test = create_n_grams(trans_test, 3, trans_vocab_size, 128)\n",
    "trans_preds = trans_gram3_model.predict([trans_gram3_test, trans_gram3_test, trans_gram3_test]).argmax(-1)\n",
    "\n",
    "vocab_size = get_vocab_size(text_train, 3, 128)\n",
    "orig_trans_gram3_test = create_n_grams(trans_test, 3, vocab_size, 128)\n",
    "orig_trans_preds = gram3_model.predict([trans_gram3_test, trans_gram3_test, trans_gram3_test]).argmax(-1)\n",
    "\n",
    "print('Weighted scores')\n",
    "print('F1 score for original text:', f1_score(true_values, preds, average='weighted'))\n",
    "print('F1 score for transformed text with transformed model:', f1_score(true_values, trans_preds, average='weighted'))\n",
    "print('F1 score for transformed text with orig model:', f1_score(true_values, orig_trans_preds, average='weighted'))\n",
    "print()\n",
    "print('Macro averaged scores')\n",
    "print('F1 score for original text:', f1_score(true_values, preds, average='macro'))\n",
    "print('F1 score for transformed text with transformed model:', f1_score(true_values, trans_preds, average='macro'))\n",
    "print('F1 score for transformed text with orig model:', f1_score(true_values, orig_trans_preds, average='macro'))\n",
    "\n",
    "with open('attacker_tests.txt', 'w') as f:\n",
    "    print('Weighted scores', file=f)\n",
    "    print('F1 score for original text:', f1_score(true_values, preds, average='weighted'), file=f)\n",
    "    print('F1 score for transformed text with transformed model:', f1_score(true_values, trans_preds, average='weighted'), file=f)\n",
    "    print('F1 score for transformed text with orig model:', f1_score(true_values, orig_trans_preds, average='weighted'), file=f)\n",
    "    print('', file=f)\n",
    "    print('Macro averaged scores', file=f)\n",
    "    print('F1 score for original text:', f1_score(true_values, preds, average='macro'), file=f)\n",
    "    print('F1 score for transformed text with transformed model:', f1_score(true_values, trans_preds, average='macro'), file=f)\n",
    "    print('F1 score for transformed text with orig model:', f1_score(true_values, orig_trans_preds, average='macro'), file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT sentiment\n",
    "\n",
    "BERT –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö –∏ –Ω–∞ –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞ –∑–∞–¥–∞—á—É Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>911658</th>\n",
       "      <td>4</td>\n",
       "      <td>1752020247</td>\n",
       "      <td>Sat May 09 20:51:17 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Irv25</td>\n",
       "      <td>@SophiaF3F3 I LOVE IT!!!!!!!!!!!!!!!!!!!!!! I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694431</th>\n",
       "      <td>0</td>\n",
       "      <td>2252987666</td>\n",
       "      <td>Sat Jun 20 07:22:37 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Sushilief</td>\n",
       "      <td>Cheer up girls..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530205</th>\n",
       "      <td>4</td>\n",
       "      <td>2177739254</td>\n",
       "      <td>Mon Jun 15 06:37:20 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>janeson59</td>\n",
       "      <td>@JohnLusher @davidspruell @stewartb2b @Kimberl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115526</th>\n",
       "      <td>4</td>\n",
       "      <td>1972971274</td>\n",
       "      <td>Sat May 30 10:13:54 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>elkhorninn</td>\n",
       "      <td>FEMA-folks in McDowell Co. WV: The Elkhorn Inn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795117</th>\n",
       "      <td>0</td>\n",
       "      <td>2327241409</td>\n",
       "      <td>Thu Jun 25 08:05:52 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>brucegskinner</td>\n",
       "      <td>Baltacha out in staight sets, shame</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target          id                          date      flag  \\\n",
       "911658        4  1752020247  Sat May 09 20:51:17 PDT 2009  NO_QUERY   \n",
       "694431        0  2252987666  Sat Jun 20 07:22:37 PDT 2009  NO_QUERY   \n",
       "1530205       4  2177739254  Mon Jun 15 06:37:20 PDT 2009  NO_QUERY   \n",
       "1115526       4  1972971274  Sat May 30 10:13:54 PDT 2009  NO_QUERY   \n",
       "795117        0  2327241409  Thu Jun 25 08:05:52 PDT 2009  NO_QUERY   \n",
       "\n",
       "                  user                                               text  \n",
       "911658           Irv25  @SophiaF3F3 I LOVE IT!!!!!!!!!!!!!!!!!!!!!! I ...  \n",
       "694431       Sushilief                                  Cheer up girls..   \n",
       "1530205      janeson59  @JohnLusher @davidspruell @stewartb2b @Kimberl...  \n",
       "1115526     elkhorninn  FEMA-folks in McDowell Co. WV: The Elkhorn Inn...  \n",
       "795117   brucegskinner               Baltacha out in staight sets, shame   "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ —Ç–≤–∏—Ç—Ç–µ—Ä–∞ —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π –¥–ª—è –∑–∞–¥–∞—á–∏ Sentiment Analysis\n",
    "cols = ['target', 'id', 'date', 'flag', 'user', 'text']\n",
    "sentiment_posts_df = pd.read_csv('/mnt/ess_storage/DN_1/storage/home/vpanov/training.1600000.processed.noemoticon.csv', encoding='latin', names=cols)\n",
    "sentiment_posts_df = sentiment_posts_df.sample(n=10000)\n",
    "sentiment_posts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = sentiment_posts_df.target.nunique()\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb = LabelEncoder()\n",
    "\n",
    "sentiment_posts_df.target = lb.fit_transform(sentiment_posts_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_posts_df['text'] = sentiment_posts_df['text'].apply(apply_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_posts_df['anonymized_text'] = predict_batch(model, sentiment_posts_df['text'].tolist(), seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentiment, test_sentiment = train_test_split(sentiment_posts_df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentiment.to_csv('train_sentiment.csv')\n",
    "test_sentiment.to_csv('test_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentiment = pd.read_csv('train_sentiment.csv')\n",
    "test_sentiment = pd.read_csv('test_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_vecs(docs, use_synsets=USE_SYNSETS, vocabulary=None):\n",
    "    tfidf = TfidfVectorizer(vocabulary=vocabulary, norm='l1')\n",
    "    if use_synsets:\n",
    "        tfidf.fit(docs_with_synonyms)\n",
    "    else:\n",
    "        tfidf.fit(docs)\n",
    "    doc_vecs = tfidf.transform(docs)\n",
    "    words = tfidf.get_feature_names()\n",
    "    return doc_vecs, words, tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymize(doc, doc_vec):\n",
    "    p = np.array(doc_vec.todense().tolist()[0])\n",
    "    words_count = len(doc.split())\n",
    "    words_ = np.random.choice(words, words_count, p=p)\n",
    "    for i in range(words_count):\n",
    "        word_idx = tfidf.vocabulary_[words_[i]]\n",
    "        words_[i] = np.random.choice(words, 1, p=word_replace_probs[word_idx])[0]\n",
    "    return ' '.join(words_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41378ce0e3440289fe98d01d4e55f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18189 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_doc_vecs, words, tfidf = get_doc_vecs(train_sentiment['text'].tolist() + test_sentiment['text'].tolist())\n",
    "\n",
    "word_vecs = [ft.wv[word] for word in words]\n",
    "word_similarities = cosine_similarity(word_vecs, word_vecs)\n",
    "\n",
    "word_replace_probs = []\n",
    "\n",
    "for word in tqdm(words):\n",
    "    word_replace_probs.append(exponential(word, words, score))\n",
    "\n",
    "word_replace_probs = np.array(word_replace_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_anon_syntf = []\n",
    "test_text_anon_syntf = []\n",
    "\n",
    "for idx, doc in enumerate(train_sentiment['text']):\n",
    "    train_text_anon_syntf.append(anonymize(doc, sent_doc_vecs[idx]))\n",
    "    \n",
    "for idx, doc in enumerate(test_sentiment['text']):\n",
    "    test_text_anon_syntf.append(anonymize(doc, sent_doc_vecs[idx + len(train_sentiment)]))\n",
    "\n",
    "train_sentiment['text_anon_syntf'] = train_text_anon_syntf\n",
    "test_sentiment['text_anon_syntf'] = test_text_anon_syntf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "\n",
    "num_labels = train_sentiment.target.nunique()\n",
    "\n",
    "sentiment_tokenizer = AutoTokenizer.from_pretrained(sentiment_model_name)\n",
    "\n",
    "def sentiment_model_init(model_name=sentiment_model_name, num_labels=num_labels):\n",
    "    return AutoModelForSequenceClassification.from_pretrained(sentiment_model_name, num_labels=num_labels, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, targets, tokenizer):\n",
    "        self.inputs = tokenizer(texts, return_tensors=\"pt\", max_length=128, padding='max_length', truncation=True)\n",
    "        self.outputs = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.outputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.inputs['input_ids'][idx],\n",
    "            'token_type_ids': self.inputs['token_type_ids'][idx],\n",
    "            'attention_mask': self.inputs['attention_mask'][idx],\n",
    "            'targets': self.outputs[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_BATCH_SIZE = 8\n",
    "\n",
    "class LitSentiment(pl.LightningModule):\n",
    "    def __init__(self, model_init, train, test, learning_rate=1e-4):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # We hardcode dataset specific stuff here.\n",
    "        self.train_dataset = train\n",
    "        self.test_dataset = test\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model_init()\n",
    "\n",
    "    def forward(self, **inputs):\n",
    "        return self.model(**inputs)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = {a: b for a, b in batch.items() if a != 'targets'}\n",
    "        y = batch['targets']\n",
    "        outputs = self(**x)\n",
    "        logits = outputs.logits\n",
    "        loss = self.loss_func(logits, y)\n",
    "        \n",
    "        f1 = f1_score(y.cpu(), logits.cpu().argmax(dim=-1), average='macro')\n",
    "        \n",
    "        self.log(f'train_loss', loss)\n",
    "        self.log(f'avg_train_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log(f'train_f1', f1)\n",
    "        self.log(f'avg_train_f1', f1, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x = {a: b for a, b in batch.items() if a != 'targets'}\n",
    "        y = batch['targets']\n",
    "        outputs = self(**x)\n",
    "        logits = outputs.logits\n",
    "        loss = self.loss_func(logits, y)\n",
    "        \n",
    "        f1 = f1_score(y.cpu(), logits.cpu().argmax(dim=-1), average='macro')\n",
    "        \n",
    "        self.log(f'val_loss', loss)\n",
    "        self.log(f'avg_val_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log(f'val_f1', f1)\n",
    "        self.log(f'avg_val_f1', f1, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x = {a: b for a, b in batch.items() if a != 'targets'}\n",
    "        y = batch['targets']\n",
    "        outputs = self(**x)\n",
    "        logits = outputs.logits\n",
    "        loss = self.loss_func(logits, y)\n",
    "        \n",
    "        f1 = f1_score(y.cpu(), logits.cpu().argmax(dim=-1), average='macro')\n",
    "        \n",
    "        self.log(f'test_loss', loss)\n",
    "        self.log(f'avg_test_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log(f'test_f1', f1)\n",
    "        self.log(f'avg_test_f1', f1, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def on_train_batch_end(self, outputs, batch, batch_idx):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "#         logger.info(f'Batch train loss {metrics}')\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        print(f'Train loss: {metrics[\"avg_train_loss\"]}')\n",
    "        print(f'Train f1: {metrics[\"avg_train_f1\"]}')\n",
    "\n",
    "    def on_validation_batch_end(self, outputs, batch, batch_idx):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "#         logger.info(f'Batch validation loss {metrics}')\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        print(f'Val loss: {metrics[\"avg_val_loss\"]}')\n",
    "        print(f'Val f1: {metrics[\"avg_val_f1\"]}')\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        print(f'Test loss: {metrics[\"avg_test_loss\"]}')\n",
    "        print(f'Test f1: {metrics[\"avg_test_f1\"]}')\n",
    "\n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "\n",
    "#     def prepare_data(self):\n",
    "#         self.data = nn.utils.rnn.pad_sequence(self.data)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            train_size = int(0.9 * len(self.train_dataset))\n",
    "            val_size = len(self.train_dataset) - train_size\n",
    "            self.data_train, self.data_val = random_split(self.train_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.data_test = self.test_dataset\n",
    "\n",
    "        self.loss_func = nn.CrossEntropyLoss() # forgot to add ignore_index for BERT\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.data_train, batch_size=BERT_BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.data_val, batch_size=BERT_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.data_test, batch_size=BERT_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "chechpoint_path_sentiment = \"checkpoints_sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                          | Params\n",
      "------------------------------------------------------------\n",
      "0 | model     | BertForSequenceClassification | 167 M \n",
      "1 | loss_func | CrossEntropyLoss              | 0     \n",
      "------------------------------------------------------------\n",
      "167 M     Trainable params\n",
      "0         Non-trainable params\n",
      "167 M     Total params\n",
      "669.432   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09c584ea256420eb86db0df98541aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc885267446447db78fd9a858b270e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.47206124663352966\n",
      "Val f1: 0.7558749892083226\n",
      "Train loss: 0.5064026713371277\n",
      "Train f1: 0.7259999369629\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce3b0574b8747a181204023cb916ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.46705251932144165\n",
      "Val f1: 0.7595482048815384\n",
      "Train loss: 0.3792409598827362\n",
      "Train f1: 0.8122553715146329\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3cf95c72a046f298b86a1ab1cbac6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.4660312533378601\n",
      "Val f1: 0.7728488795155464\n",
      "Train loss: 0.26204779744148254\n",
      "Train f1: 0.8758703792777893\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a406582597a3482bb0c1d7362d158c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6459970474243164\n",
      "Val f1: 0.7261336688003357\n",
      "Train loss: 0.16500037908554077\n",
      "Train f1: 0.9289036121628746\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f7b71acdd14b46814aa6f72acd1e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6794469356536865\n",
      "Val f1: 0.7644578137911473\n",
      "Train loss: 0.11057490855455399\n",
      "Train f1: 0.9533260429556746\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SentimentDataset(train_sentiment.text.tolist(), train_sentiment.target.tolist(), sentiment_tokenizer)\n",
    "test_dataset = SentimentDataset(test_sentiment.text.tolist(), test_sentiment.target.tolist(), sentiment_tokenizer)\n",
    "sentiment_pl = LitSentiment(sentiment_model_init, train_dataset, test_dataset, 2e-5)\n",
    "sentiment_pl.train()\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=chechpoint_path_sentiment, save_top_k=2, monitor=\"val_loss\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=5,\n",
    "    num_nodes=1,\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "trainer.fit(sentiment_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/jovyan/notebooks/checkpoints_sentiment/epoch=2-step=3039-v1.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /home/jovyan/notebooks/checkpoints_sentiment/epoch=2-step=3039-v1.ckpt\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ebaf932cd548cbbe06d08a1df8caa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "       Test metric             DataLoader 0\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "       avg_val_f1           0.7545355533355537\n",
      "      avg_val_loss          0.5052968859672546\n",
      "         val_f1             0.7545355533355537\n",
      "        val_loss            0.5052968859672546\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "[{'val_loss': 0.5052968859672546, 'avg_val_loss': 0.5052968859672546, 'val_f1': 0.7545355533355537, 'avg_val_f1': 0.7545355533355537}]\n"
     ]
    }
   ],
   "source": [
    "sentiment_pl.stage = 'test'\n",
    "sentiment_pl.eval()\n",
    "\n",
    "results = trainer.test(sentiment_pl, ckpt_path='best')\n",
    "with open('sentiment_original.txt', 'w') as f:\n",
    "    print(results, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /home/jovyan/notebooks/anonymization/checkpoints_sentiment exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                          | Params\n",
      "------------------------------------------------------------\n",
      "0 | model     | BertForSequenceClassification | 167 M \n",
      "1 | loss_func | CrossEntropyLoss              | 0     \n",
      "------------------------------------------------------------\n",
      "167 M     Trainable params\n",
      "0         Non-trainable params\n",
      "167 M     Total params\n",
      "669.432   Total estimated model params size (MB)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d2b1570f7048d18e87c1d78135da95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.691686749458313\n",
      "Val f1: 0.4269143695810364\n",
      "Train loss: 0.6957077383995056\n",
      "Train f1: 0.421914968433482\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6860303282737732\n",
      "Val f1: 0.5142277968944637\n",
      "Train loss: 0.6830658316612244\n",
      "Train f1: 0.4917938686827525\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.7321146726608276\n",
      "Val f1: 0.48573367373367393\n",
      "Train loss: 0.6371310949325562\n",
      "Train f1: 0.6062868160645921\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.7786092162132263\n",
      "Val f1: 0.4855131535131538\n",
      "Train loss: 0.5189948678016663\n",
      "Train f1: 0.7224052545534025\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 1.164617896080017\n",
      "Val f1: 0.4818428978428982\n",
      "Train loss: 0.3378312587738037\n",
      "Train f1: 0.8382470588396533\n"
     ]
    }
   ],
   "source": [
    "anon_train_dataset = SentimentDataset(train_sentiment.text_anon_syntf.tolist(), train_sentiment.target.tolist(), sentiment_tokenizer)\n",
    "anon_test_dataset = SentimentDataset(test_sentiment.text_anon_syntf.tolist(), test_sentiment.target.tolist(), sentiment_tokenizer)\n",
    "sentiment_pl = LitSentiment(sentiment_model_init, anon_train_dataset, anon_test_dataset, 2e-5)\n",
    "sentiment_pl.train()\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=chechpoint_path_sentiment, save_top_k=2, monitor=\"val_loss\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=5,\n",
    "    num_nodes=1,\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "trainer.fit(sentiment_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/jovyan/notebooks/anonymization/checkpoints_sentiment/epoch=1-step=2026.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/jovyan/notebooks/anonymization/checkpoints_sentiment/epoch=1-step=2026.ckpt\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944914c77850410da63ce8441072985e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6773563623428345\n",
      "Test f1: 0.5492606060606066\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "       Test metric             DataLoader 0\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "       avg_test_f1          0.5492606060606066\n",
      "      avg_test_loss         0.6773563623428345\n",
      "         test_f1            0.5492606060606066\n",
      "        test_loss           0.6773563623428345\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
     ]
    }
   ],
   "source": [
    "sentiment_pl.stage = 'test'\n",
    "sentiment_pl.eval()\n",
    "\n",
    "results = trainer.test(sentiment_pl, ckpt_path='best')\n",
    "with open('sentiment_anonymized.txt', 'w') as f:\n",
    "    print(results, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
