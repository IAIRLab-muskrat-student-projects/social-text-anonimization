{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–∂–µ—Ç –ø–æ–ª—É—á–∏—Ç—å—Å—è –Ω–∞–π—Ç–∏ –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è —É–º–µ–µ—Ç –ª—É—á—à–µ –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –∞–≤—Ç–æ—Ä–∞ —Ç–µ–∫—Å—Ç–∞ (0.26 —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ) | Done\n",
    "\n",
    "–•–µ—à—Ç–µ–≥–∏:\n",
    "–ë–µ—Ä–µ–º –±–µ—Ä—Ç, –≤—ã—á–∏—Å–ª—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Å–µ—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —É—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ —Ö–µ—à—Ç–µ–≥–∞–º. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞—Ö–æ–¥–∏–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞. –ó–∞–º–µ–Ω—É –∏—â–µ–º –∏–∑ –±–ª–∏–∂–∞–π—à–∏—Ö –ø–æ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–º—É —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é, –Ω–æ —Ç–∞–∫–∂–µ –Ω–µ –±–ª–∏–∑–∫–∏—Ö –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é –ª–µ–≤–µ–Ω—à—Ç–∞–π–Ω–∞.\n",
    "\n",
    "–ü–æ—Å—á–∏—Ç–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –±–µ—Ä—Ç–∞ –Ω–∞ –∑–∞–¥–∞—á–∞—Ö MLM –∏ NSP –¥–ª—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –∏ –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö.\n",
    "–ü–æ—Å—á–∏—Ç–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –∑–∞–¥–∞—á–µ –æ—Ü–µ–Ω–∫–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏. –î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –∏–Ω—Å—Ç—ã –º–æ–∂–µ—Ç –ú–∏—à–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å, –µ—Å—Ç—å –≤ –∏–Ω–µ—Ç–µ —Ç–∞–∫–∂–µ –ø–æ —Ç–≤–∏—Ç—Ç–µ—Ä—É.\n",
    "\n",
    "–ö–∞–∫ –æ—Å—Ç–∞–≤–∏—Ç—å —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –¥—Ä—É–≥–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π? –ó–∞–º–µ–Ω–∏—Ç—å –∏—Ö –≤ —Ç–µ–∫—Å—Ç–µ –Ω–∞ <MASK> –Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ—Ç–æ–º –≤—Å—Ç–∞–≤–∏—Ç—å –Ω–∞ –º–µ—Å—Ç–æ —Ç–æ–∫–µ–Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4ff850fa8815>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfasttext\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatapath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "eng_stopwords = stopwords.words('english')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import fasttext as ft, Word2Vec\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "import fasttext\n",
    "\n",
    "from cleantext import clean\n",
    "\n",
    "from transformers import (\n",
    "    AutoModel, \n",
    "    AutoModelForMaskedLM,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from transformers import pipeline\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Embedding\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import re\n",
    "from itertools import chain, islice\n",
    "import logging\n",
    "import os\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "from utils import apply_clean, get_text_and_hashtags\n",
    "\n",
    "CORES = 10\n",
    "\n",
    "SEED = 42\n",
    "TRAIN_DOC_COUNT = 10000\n",
    "TEST_DOC_COUNT = 1000\n",
    "AUTHOR_COUNT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small.n.01 ['small']\n",
      "small.n.02 ['small']\n",
      "small.a.01 ['small', 'little']\n",
      "minor.s.10 ['minor', 'modest', 'small', 'small-scale', 'pocket-size', 'pocket-sized']\n",
      "little.s.03 ['little', 'small']\n"
     ]
    }
   ],
   "source": [
    "synonyms = wordnet.synsets('small')\n",
    "for ss in islice(synonyms, 5):\n",
    "    print(ss.name(), ss.lemma_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortcode</th>\n",
       "      <th>caption</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>authorid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BtE14s-AcIT</td>\n",
       "      <td>Right or Left?\\n\\nBuffalo Chicken slice on the...</td>\n",
       "      <td>1548458208</td>\n",
       "      <td>4640452414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BtEYaa1FozM</td>\n",
       "      <td>Friday‚Äôs at the office just got a little sweet...</td>\n",
       "      <td>1548443178</td>\n",
       "      <td>8486247913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BtDq0V4FKOZ</td>\n",
       "      <td>The early bird gets the best sunrise pics.</td>\n",
       "      <td>1548418851</td>\n",
       "      <td>185562852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BtEwnkfFzCg</td>\n",
       "      <td>Poor Cyndy!  This superstar massage therapist ...</td>\n",
       "      <td>1548455447</td>\n",
       "      <td>247991751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BtEwsGCAcmq</td>\n",
       "      <td>he hit the booty like a drum, yumyum.üòÄ why he ...</td>\n",
       "      <td>1548455484</td>\n",
       "      <td>8102841338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     shortcode                                            caption   timestamp  \\\n",
       "0  BtE14s-AcIT  Right or Left?\\n\\nBuffalo Chicken slice on the...  1548458208   \n",
       "1  BtEYaa1FozM  Friday‚Äôs at the office just got a little sweet...  1548443178   \n",
       "2  BtDq0V4FKOZ         The early bird gets the best sunrise pics.  1548418851   \n",
       "3  BtEwnkfFzCg  Poor Cyndy!  This superstar massage therapist ...  1548455447   \n",
       "4  BtEwsGCAcmq  he hit the booty like a drum, yumyum.üòÄ why he ...  1548455484   \n",
       "\n",
       "     authorid  \n",
       "0  4640452414  \n",
       "1  8486247913  \n",
       "2   185562852  \n",
       "3   247991751  \n",
       "4  8102841338  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['shortcode', 'caption', 'authorid', 'timestamp']\n",
    "\n",
    "nyc_posts_df = pd.read_csv('/mnt/ess_storage/DN_1/storage/home/vpanov/instagram_posts/data/nyc_posts_2019.csv', usecols=cols, nrows=10000000)\n",
    "nyc_posts_df = nyc_posts_df.dropna(axis=0)\n",
    "nyc_posts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2422245"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nyc_posts_df['authorid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2422245"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nyc_posts_df['authorid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288898810     405\n",
       "581325206     404\n",
       "31033532      404\n",
       "6612357200    404\n",
       "2206015241    403\n",
       "             ... \n",
       "1303589730    374\n",
       "3711248845    374\n",
       "7370266134    374\n",
       "1418705634    373\n",
       "1291658614    373\n",
       "Name: authorid, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset = 500\n",
    "nyc_posts_df['authorid'].value_counts()[offset:offset+AUTHOR_COUNT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortcode</th>\n",
       "      <th>caption</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>authorid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4947526</th>\n",
       "      <td>BxtFxE0FYag</td>\n",
       "      <td>TODAY\\nMay 20th\\n@fortythirdstreetcafe will be...</td>\n",
       "      <td>1558398646</td>\n",
       "      <td>450551504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384135</th>\n",
       "      <td>BwmpRlZgfXV</td>\n",
       "      <td>Today is beautiful and so are you.</td>\n",
       "      <td>1556034898</td>\n",
       "      <td>1594705691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9020735</th>\n",
       "      <td>B0Dy8axlAI1</td>\n",
       "      <td>It‚Äôs definitely a good feeling when you see yo...</td>\n",
       "      <td>1563455497</td>\n",
       "      <td>1506891433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726136</th>\n",
       "      <td>BsGM4d2FP6W</td>\n",
       "      <td>Bike Club Shop Ride, Croton Aqueduct Trail, Ja...</td>\n",
       "      <td>1546356336</td>\n",
       "      <td>36407423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6367470</th>\n",
       "      <td>B3a6YFwHss1</td>\n",
       "      <td>World War 2 casualty #gravesite #ww2 #soldier ...</td>\n",
       "      <td>1570673597</td>\n",
       "      <td>1567349564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           shortcode                                            caption  \\\n",
       "4947526  BxtFxE0FYag  TODAY\\nMay 20th\\n@fortythirdstreetcafe will be...   \n",
       "4384135  BwmpRlZgfXV                 Today is beautiful and so are you.   \n",
       "9020735  B0Dy8axlAI1  It‚Äôs definitely a good feeling when you see yo...   \n",
       "5726136  BsGM4d2FP6W  Bike Club Shop Ride, Croton Aqueduct Trail, Ja...   \n",
       "6367470  B3a6YFwHss1  World War 2 casualty #gravesite #ww2 #soldier ...   \n",
       "\n",
       "          timestamp    authorid  \n",
       "4947526  1558398646   450551504  \n",
       "4384135  1556034898  1594705691  \n",
       "9020735  1563455497  1506891433  \n",
       "5726136  1546356336    36407423  \n",
       "6367470  1570673597  1567349564  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_productive_authors = nyc_posts_df['authorid'].value_counts()[offset:offset+AUTHOR_COUNT].index.values\n",
    "nyc_posts_authors_df = nyc_posts_df[nyc_posts_df.authorid.isin(most_productive_authors)].sample(frac=1.0, random_state=SEED)\n",
    "nyc_posts_authors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)\n",
    "\n",
    "def apply_clean(doc):\n",
    "    doc = clean(doc,\n",
    "                fix_unicode=True,               # fix various unicode errors\n",
    "                to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "                lower=True,                     # lowercase text\n",
    "                no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them\n",
    "                no_urls=True,                  # replace all URLs with a special token\n",
    "                no_emails=True,                # replace all email addresses with a special token\n",
    "                no_phone_numbers=False,         # replace all phone numbers with a special token\n",
    "                no_numbers=False,               # replace all numbers with a special token\n",
    "                no_digits=False,                # replace all digits with a special token\n",
    "                no_currency_symbols=False,      # replace all currency symbols with a special token\n",
    "                no_punct=False,                 # remove punctuations\n",
    "                replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
    "                replace_with_url=\"<URL>\",\n",
    "                replace_with_email=\"<EMAIL>\",\n",
    "                lang=\"en\"                       # set to 'de' for German special handling\n",
    "               )\n",
    "    doc = remove_emojis(doc)\n",
    "    return doc\n",
    "\n",
    "nyc_posts_authors_df.caption = nyc_posts_authors_df.caption.apply(apply_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortcode</th>\n",
       "      <th>caption</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>authorid</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4947526</th>\n",
       "      <td>BxtFxE0FYag</td>\n",
       "      <td>today may 20th @fortythirdstreetcafe will be o...</td>\n",
       "      <td>1558398646</td>\n",
       "      <td>450551504</td>\n",
       "      <td>today may 20th @fortythirdstreetcafe will be o...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384135</th>\n",
       "      <td>BwmpRlZgfXV</td>\n",
       "      <td>today is beautiful and so are you.</td>\n",
       "      <td>1556034898</td>\n",
       "      <td>1594705691</td>\n",
       "      <td>today is beautiful and so are you.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9020735</th>\n",
       "      <td>B0Dy8axlAI1</td>\n",
       "      <td>it's definitely a good feeling when you see yo...</td>\n",
       "      <td>1563455497</td>\n",
       "      <td>1506891433</td>\n",
       "      <td>it's definitely a good feeling when you see yo...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726136</th>\n",
       "      <td>BsGM4d2FP6W</td>\n",
       "      <td>bike club shop ride, croton aqueduct trail, ja...</td>\n",
       "      <td>1546356336</td>\n",
       "      <td>36407423</td>\n",
       "      <td>bike club shop ride, croton aqueduct trail, ja...</td>\n",
       "      <td>#bike #bikes #bikelife #shopride #shoplife #my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6367470</th>\n",
       "      <td>B3a6YFwHss1</td>\n",
       "      <td>world war 2 casualty #gravesite #ww2 #soldier ...</td>\n",
       "      <td>1570673597</td>\n",
       "      <td>1567349564</td>\n",
       "      <td>world war 2 casualty</td>\n",
       "      <td>#gravesite #ww2 #soldier #rip #queens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           shortcode                                            caption  \\\n",
       "4947526  BxtFxE0FYag  today may 20th @fortythirdstreetcafe will be o...   \n",
       "4384135  BwmpRlZgfXV                 today is beautiful and so are you.   \n",
       "9020735  B0Dy8axlAI1  it's definitely a good feeling when you see yo...   \n",
       "5726136  BsGM4d2FP6W  bike club shop ride, croton aqueduct trail, ja...   \n",
       "6367470  B3a6YFwHss1  world war 2 casualty #gravesite #ww2 #soldier ...   \n",
       "\n",
       "          timestamp    authorid  \\\n",
       "4947526  1558398646   450551504   \n",
       "4384135  1556034898  1594705691   \n",
       "9020735  1563455497  1506891433   \n",
       "5726136  1546356336    36407423   \n",
       "6367470  1570673597  1567349564   \n",
       "\n",
       "                                                      text  \\\n",
       "4947526  today may 20th @fortythirdstreetcafe will be o...   \n",
       "4384135                 today is beautiful and so are you.   \n",
       "9020735  it's definitely a good feeling when you see yo...   \n",
       "5726136  bike club shop ride, croton aqueduct trail, ja...   \n",
       "6367470                               world war 2 casualty   \n",
       "\n",
       "                                                  hashtags  \n",
       "4947526                                                     \n",
       "4384135                                                     \n",
       "9020735                                                     \n",
       "5726136  #bike #bikes #bikelife #shopride #shoplife #my...  \n",
       "6367470              #gravesite #ww2 #soldier #rip #queens  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_text_and_hashtags(row):\n",
    "    text = row['caption']\n",
    "    if len(text) == 0:\n",
    "        return ''\n",
    "    return re.sub('#\\w+', '', text).strip(), ' '.join(re.findall('#\\w+', text))\n",
    "\n",
    "nyc_posts_authors_df[['text', 'hashtags']] = nyc_posts_authors_df.apply(get_text_and_hashtags, axis=1, result_type='expand')\n",
    "nyc_posts_authors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38795"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nyc_posts_authors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25969"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nyc_posts_authors_df[nyc_posts_authors_df.text.str.len() > 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nyc_posts_authors_df[nyc_posts_authors_df.text.str.len() > 50].authorid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10579934087    403\n",
       "288898810      400\n",
       "182549672      399\n",
       "1706798002     398\n",
       "2112186305     392\n",
       "10198719       392\n",
       "1795862337     392\n",
       "2040926754     391\n",
       "477908643      386\n",
       "270846038      386\n",
       "643127146      385\n",
       "2421664219     383\n",
       "1317549717     382\n",
       "299818632      382\n",
       "228791166      381\n",
       "480519937      380\n",
       "7291939241     379\n",
       "340711336      378\n",
       "582872531      377\n",
       "2906490331     375\n",
       "4978535758     375\n",
       "1303589730     373\n",
       "1814837251     373\n",
       "1411792405     373\n",
       "1291658614     373\n",
       "10192579486    372\n",
       "9059101974     372\n",
       "1418705634     371\n",
       "655934981      370\n",
       "4529154010     369\n",
       "31033532       368\n",
       "450551504      366\n",
       "3165744688     365\n",
       "6612357200     364\n",
       "7624638307     361\n",
       "581325206      358\n",
       "257267175      356\n",
       "3282508444     351\n",
       "39037837       349\n",
       "21452784       346\n",
       "1514849890     342\n",
       "213882856      340\n",
       "3050309989     330\n",
       "1125451713     329\n",
       "4473522466     327\n",
       "488134907      316\n",
       "32219305       314\n",
       "1920983937     312\n",
       "217402170      310\n",
       "4334476665     305\n",
       "Name: authorid, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_posts_authors_df[nyc_posts_authors_df.text.str.len() > 50].authorid.value_counts()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_authors = 50\n",
    "least_long = 50\n",
    "\n",
    "long_posts = nyc_posts_authors_df[nyc_posts_authors_df.text.str.len() > least_long]\n",
    "authors_posts_count = long_posts.authorid.value_counts()\n",
    "authors = authors_posts_count[:max_authors].index.tolist()\n",
    "min_posts = authors_posts_count.values[max_authors - 1]\n",
    "median_posts = int(authors_posts_count.median())\n",
    "\n",
    "train_posts = []\n",
    "test_posts = []\n",
    "\n",
    "for i in authors:\n",
    "    author_i_posts = nyc_posts_authors_df[(nyc_posts_authors_df.text.str.len() > least_long) & (nyc_posts_authors_df.authorid == i)]\n",
    "    l = len(author_i_posts)\n",
    "    train_posts.append(author_i_posts[:l - 20])\n",
    "    test_posts.append(author_i_posts[l - 20:])\n",
    "\n",
    "train_posts = pd.concat(train_posts).sample(frac=1.0, random_state=SEED)\n",
    "test_posts = pd.concat(test_posts).sample(frac=1.0, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "lang_ft = fasttext.load_model('/mnt/ess_storage/DN_1/storage/home/vpanov/lang/lid.176.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_func(text):\n",
    "    return lang_ft.predict(apply_clean(text), k=1)[0][0][9:]\n",
    "\n",
    "nyc_posts_df_march['lang'] = nyc_posts_df_march.caption.apply(lang_func)\n",
    "\n",
    "from collections import Counter\n",
    "c = Counter(nyc_posts_df_march.lang.tolist())\n",
    "# c.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('en', 629351),\n",
       " ('es', 21942),\n",
       " ('pt', 5341),\n",
       " ('fr', 4182),\n",
       " ('it', 3624),\n",
       " ('de', 3087),\n",
       " ('nl', 1451),\n",
       " ('ja', 1239),\n",
       " ('zh', 1134),\n",
       " ('sv', 1059)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11270"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(num for lang, num in c.items() if num < 1059)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_func(text):\n",
    "    return lang_ft.predict(text, k=1)[0][0][9:]\n",
    "\n",
    "train_posts['lang'] = train_posts.caption.apply(lang_func)\n",
    "test_posts['lang'] = test_posts.caption.apply(lang_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('en', 17900), ('pt', 237), ('es', 127), ('de', 5), ('it', 1), ('hu', 1)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c = Counter(train_posts.lang.tolist()) + Counter(test_posts.lang.tolist())\n",
    "c.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_posts, others = train_test_split(nyc_posts_df[nyc_posts_df.text.str.len() > 100], train_size=TRAIN_DOC_COUNT, random_state=SEED)\n",
    "# test_posts = others[others.authorid.isin(train_posts.authorid.unique())].sample(n=TEST_DOC_COUNT, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17271"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortcode</th>\n",
       "      <th>caption</th>\n",
       "      <th>authorid</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7062952</th>\n",
       "      <td>B2zJvl_F3Ho</td>\n",
       "      <td>we are definitely sailing tonight at 5pm!! cal...</td>\n",
       "      <td>2040926754</td>\n",
       "      <td>we are definitely sailing tonight at 5pm!! cal...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8245150</th>\n",
       "      <td>Bse6L35FoPx</td>\n",
       "      <td>to dance , to eat, to drink , to flirt and at ...</td>\n",
       "      <td>581325206</td>\n",
       "      <td>to dance , to eat, to drink , to flirt and at ...</td>\n",
       "      <td>#brooklyn #ny #restaurant #brooklyn #wedding #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138598</th>\n",
       "      <td>BtQt1YJBuCF</td>\n",
       "      <td>another reminder about cold weather safety fro...</td>\n",
       "      <td>1125451713</td>\n",
       "      <td>another reminder about cold weather safety fro...</td>\n",
       "      <td>#winter #coldweather #bundleup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5252918</th>\n",
       "      <td>B4VsLN0D2a6</td>\n",
       "      <td>our cosmopolitan feels fridaylicious join us f...</td>\n",
       "      <td>4334476665</td>\n",
       "      <td>our cosmopolitan feels fridaylicious join us f...</td>\n",
       "      <td>#happyhour #seawalkrestaurant #inwood #uptown ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490783</th>\n",
       "      <td>B4i4-yrFYFc</td>\n",
       "      <td>every saturday @spyce_astoria. rsvp now for cr...</td>\n",
       "      <td>31033532</td>\n",
       "      <td>every saturday @spyce_astoria. rsvp now for cr...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           shortcode                                            caption  \\\n",
       "7062952  B2zJvl_F3Ho  we are definitely sailing tonight at 5pm!! cal...   \n",
       "8245150  Bse6L35FoPx  to dance , to eat, to drink , to flirt and at ...   \n",
       "3138598  BtQt1YJBuCF  another reminder about cold weather safety fro...   \n",
       "5252918  B4VsLN0D2a6  our cosmopolitan feels fridaylicious join us f...   \n",
       "6490783  B4i4-yrFYFc  every saturday @spyce_astoria. rsvp now for cr...   \n",
       "\n",
       "           authorid                                               text  \\\n",
       "7062952  2040926754  we are definitely sailing tonight at 5pm!! cal...   \n",
       "8245150   581325206  to dance , to eat, to drink , to flirt and at ...   \n",
       "3138598  1125451713  another reminder about cold weather safety fro...   \n",
       "5252918  4334476665  our cosmopolitan feels fridaylicious join us f...   \n",
       "6490783    31033532  every saturday @spyce_astoria. rsvp now for cr...   \n",
       "\n",
       "                                                  hashtags  \n",
       "7062952                                                     \n",
       "8245150  #brooklyn #ny #restaurant #brooklyn #wedding #...  \n",
       "3138598                     #winter #coldweather #bundleup  \n",
       "5252918  #happyhour #seawalkrestaurant #inwood #uptown ...  \n",
       "6490783                                                     "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortcode</th>\n",
       "      <th>caption</th>\n",
       "      <th>authorid</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9904347</th>\n",
       "      <td>Bx7ciYrHfIo</td>\n",
       "      <td>just a reminder that we are closed today and t...</td>\n",
       "      <td>9059101974</td>\n",
       "      <td>just a reminder that we are closed today and t...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8251367</th>\n",
       "      <td>BsgSx_GlNJJ</td>\n",
       "      <td>miss twin peaksis next saturday night at @joes...</td>\n",
       "      <td>257267175</td>\n",
       "      <td>miss twin peaksis next saturday night at @joes...</td>\n",
       "      <td>#twinpeaks #misstwinpeaks2019 #davidlynch #joe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047692</th>\n",
       "      <td>ByUWouqnbuw</td>\n",
       "      <td>attention  this thursday june 6th #privilegedt...</td>\n",
       "      <td>3282508444</td>\n",
       "      <td>attention  this thursday june 6th ‚Äº presents  ...</td>\n",
       "      <td>#privilegedthursday #theprinceofny #power105 #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420468</th>\n",
       "      <td>BusFIZGnY68</td>\n",
       "      <td>congratulations to this week's trivia winners-...</td>\n",
       "      <td>6612357200</td>\n",
       "      <td>congratulations to this week's trivia winners-...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7769533</th>\n",
       "      <td>BsIXTrGlAAN</td>\n",
       "      <td>since inception, amici by baci's mission has b...</td>\n",
       "      <td>4978535758</td>\n",
       "      <td>since inception, amici by baci's mission has b...</td>\n",
       "      <td>#aw19 #winter19 #boutiquefashion #agelessbeaut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           shortcode                                            caption  \\\n",
       "9904347  Bx7ciYrHfIo  just a reminder that we are closed today and t...   \n",
       "8251367  BsgSx_GlNJJ  miss twin peaksis next saturday night at @joes...   \n",
       "1047692  ByUWouqnbuw  attention  this thursday june 6th #privilegedt...   \n",
       "3420468  BusFIZGnY68  congratulations to this week's trivia winners-...   \n",
       "7769533  BsIXTrGlAAN  since inception, amici by baci's mission has b...   \n",
       "\n",
       "           authorid                                               text  \\\n",
       "9904347  9059101974  just a reminder that we are closed today and t...   \n",
       "8251367   257267175  miss twin peaksis next saturday night at @joes...   \n",
       "1047692  3282508444  attention  this thursday june 6th ‚Äº presents  ...   \n",
       "3420468  6612357200  congratulations to this week's trivia winners-...   \n",
       "7769533  4978535758  since inception, amici by baci's mission has b...   \n",
       "\n",
       "                                                  hashtags  \n",
       "9904347                                                     \n",
       "8251367  #twinpeaks #misstwinpeaks2019 #davidlynch #joe...  \n",
       "1047692  #privilegedthursday #theprinceofny #power105 #...  \n",
       "3420468                                                     \n",
       "7769533  #aw19 #winter19 #boutiquefashion #agelessbeaut...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_authors = 50\n",
    "least_long = 50\n",
    "\n",
    "long_posts = nyc_posts_authors_df[nyc_posts_authors_df.hashtags.str.len() > least_long]\n",
    "authors_posts_count = long_posts.authorid.value_counts()\n",
    "authors = authors_posts_count[:max_authors].index.tolist()\n",
    "min_posts = authors_posts_count.values[max_authors - 1]\n",
    "median_posts = int(authors_posts_count.median())\n",
    "\n",
    "train_hashtags = []\n",
    "test_hashtags = []\n",
    "\n",
    "for i in authors:\n",
    "    author_i_posts = nyc_posts_authors_df[(nyc_posts_authors_df.hashtags.str.len() > least_long) & (nyc_posts_authors_df.authorid == i)]\n",
    "    l = len(author_i_posts)\n",
    "    train_hashtags.append(author_i_posts[:l - 20])\n",
    "    test_hashtags.append(author_i_posts[l - 20:])\n",
    "\n",
    "train_hashtags = pd.concat(train_hashtags).sample(frac=1.0, random_state=SEED)\n",
    "test_hashtags = pd.concat(test_hashtags).sample(frac=1.0, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortcode</th>\n",
       "      <th>caption</th>\n",
       "      <th>authorid</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7861361</th>\n",
       "      <td>BwIYsy-nFdp</td>\n",
       "      <td>bobo! #donovansdogs #wewalkweplay #hoboken #do...</td>\n",
       "      <td>536329622</td>\n",
       "      <td>bobo!          @chuckitfetchgames</td>\n",
       "      <td>#donovansdogs #wewalkweplay #hoboken #dogsofho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129404</th>\n",
       "      <td>B1oVUX9ldOT</td>\n",
       "      <td>hi, i'm posey!  my mom abbigail works in the d...</td>\n",
       "      <td>228791166</td>\n",
       "      <td>hi, i'm posey!  my mom abbigail works in the d...</td>\n",
       "      <td>#nationaldogday #museumdog #lookmakesniff #dog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553101</th>\n",
       "      <td>B47peP8n8GD</td>\n",
       "      <td>new chocolates from @vosgeshautchocolat! guaji...</td>\n",
       "      <td>1291658614</td>\n",
       "      <td>new chocolates from @vosgeshautchocolat! guaji...</td>\n",
       "      <td>#beer #craftbeer #milkandhops #cheese #gourmet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9709754</th>\n",
       "      <td>B5n4Q6FH94A</td>\n",
       "      <td>dryer all brands from $ 299 at $ 499. come by ...</td>\n",
       "      <td>8408116943</td>\n",
       "      <td>dryer all brands from $ 299 at $ 499. come by ...</td>\n",
       "      <td>#refrigerator #freezer #white #pride #month #a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8301893</th>\n",
       "      <td>B3AMCxtjShh</td>\n",
       "      <td>#brunch with us! 2 courses meal + mimosas, san...</td>\n",
       "      <td>4334476665</td>\n",
       "      <td>with us! 2 courses meal + mimosas, sangria or ...</td>\n",
       "      <td>#brunch #seawalkrestaurant #inwood #uptown #wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6516762</th>\n",
       "      <td>B1OeNo4Hzfw</td>\n",
       "      <td>friday's specials! we have some great burger s...</td>\n",
       "      <td>9059101974</td>\n",
       "      <td>friday's specials! we have some great burger s...</td>\n",
       "      <td>#food #seeyouagain #breakfast #loveofgrub #are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997768</th>\n",
       "      <td>B181afRh56H</td>\n",
       "      <td>this view tho #lashes #volumelashes #volumelas...</td>\n",
       "      <td>1719293203</td>\n",
       "      <td>this view tho</td>\n",
       "      <td>#lashes #volumelashes #volumelashextensions #l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4371593</th>\n",
       "      <td>Bwnd1uAgIvD</td>\n",
       "      <td>if you're tired of staying stuck  and ready to...</td>\n",
       "      <td>7624638307</td>\n",
       "      <td>if you're tired of staying stuck  and ready to...</td>\n",
       "      <td>#herbalife #transformationtuesday #transformat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6689247</th>\n",
       "      <td>ByfOAuLFK28</td>\n",
       "      <td>this afternoon starting @ o12pm make ur way &amp;...</td>\n",
       "      <td>10579934087</td>\n",
       "      <td>this afternoon starting @ o12pm make ur way &amp; ...</td>\n",
       "      <td>#astoria #longislandcity #queens #ny #cme #lrb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5025871</th>\n",
       "      <td>BwM2ORtFot5</td>\n",
       "      <td>saturday morning work out shoulders#thebodykin...</td>\n",
       "      <td>207831235</td>\n",
       "      <td>saturday morning work out shoulders</td>\n",
       "      <td>#thebodykingstudio #shoulderworkout #reardelts...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16441 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           shortcode                                            caption  \\\n",
       "7861361  BwIYsy-nFdp  bobo! #donovansdogs #wewalkweplay #hoboken #do...   \n",
       "1129404  B1oVUX9ldOT  hi, i'm posey!  my mom abbigail works in the d...   \n",
       "2553101  B47peP8n8GD  new chocolates from @vosgeshautchocolat! guaji...   \n",
       "9709754  B5n4Q6FH94A  dryer all brands from $ 299 at $ 499. come by ...   \n",
       "8301893  B3AMCxtjShh  #brunch with us! 2 courses meal + mimosas, san...   \n",
       "...              ...                                                ...   \n",
       "6516762  B1OeNo4Hzfw  friday's specials! we have some great burger s...   \n",
       "1997768  B181afRh56H  this view tho #lashes #volumelashes #volumelas...   \n",
       "4371593  Bwnd1uAgIvD  if you're tired of staying stuck  and ready to...   \n",
       "6689247  ByfOAuLFK28   this afternoon starting @ o12pm make ur way &...   \n",
       "5025871  BwM2ORtFot5  saturday morning work out shoulders#thebodykin...   \n",
       "\n",
       "            authorid                                               text  \\\n",
       "7861361    536329622                  bobo!          @chuckitfetchgames   \n",
       "1129404    228791166  hi, i'm posey!  my mom abbigail works in the d...   \n",
       "2553101   1291658614  new chocolates from @vosgeshautchocolat! guaji...   \n",
       "9709754   8408116943  dryer all brands from $ 299 at $ 499. come by ...   \n",
       "8301893   4334476665  with us! 2 courses meal + mimosas, sangria or ...   \n",
       "...              ...                                                ...   \n",
       "6516762   9059101974  friday's specials! we have some great burger s...   \n",
       "1997768   1719293203                                      this view tho   \n",
       "4371593   7624638307  if you're tired of staying stuck  and ready to...   \n",
       "6689247  10579934087  this afternoon starting @ o12pm make ur way & ...   \n",
       "5025871    207831235                saturday morning work out shoulders   \n",
       "\n",
       "                                                  hashtags  \n",
       "7861361  #donovansdogs #wewalkweplay #hoboken #dogsofho...  \n",
       "1129404  #nationaldogday #museumdog #lookmakesniff #dog...  \n",
       "2553101  #beer #craftbeer #milkandhops #cheese #gourmet...  \n",
       "9709754  #refrigerator #freezer #white #pride #month #a...  \n",
       "8301893  #brunch #seawalkrestaurant #inwood #uptown #wa...  \n",
       "...                                                    ...  \n",
       "6516762  #food #seeyouagain #breakfast #loveofgrub #are...  \n",
       "1997768  #lashes #volumelashes #volumelashextensions #l...  \n",
       "4371593  #herbalife #transformationtuesday #transformat...  \n",
       "6689247  #astoria #longislandcity #queens #ny #cme #lrb...  \n",
       "5025871  #thebodykingstudio #shoulderworkout #reardelts...  \n",
       "\n",
       "[16441 rows x 5 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2e79ce50ef4b2a8b578adec946e5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1a042e3a3b4823945d3377211a6301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/829 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9307b076e6064b2ba884ef67640ddbd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189a0465f6a64b71b6dfe6a54933c228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654959017bf94ff3a25fbb006859b765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f5f32c98b047729b6fa1aad0c6755b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/413M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poor Cyndy!  This superstar massage therapist had to endure an hour of Amy's special playlist with The Sky treatment to break a 4 day cuckoo migraine.  Wow, this treatment works!  But, Cyndy will never ever want to listen to Pearl Jam, DMB or REM again. #sorrynotsorry #nomoremigraine #cyndyisthebest\n",
      "\n",
      "[{'entity': 'B-PER', 'score': 0.99826306, 'index': 2, 'word': 'Cy', 'start': 5, 'end': 7}, {'entity': 'B-PER', 'score': 0.9971724, 'index': 16, 'word': 'Amy', 'start': 71, 'end': 74}, {'entity': 'I-ORG', 'score': 0.59139955, 'index': 24, 'word': 'Sky', 'start': 103, 'end': 106}, {'entity': 'B-PER', 'score': 0.9979698, 'index': 46, 'word': 'Cy', 'start': 185, 'end': 187}, {'entity': 'B-PER', 'score': 0.6932147, 'index': 55, 'word': 'Pearl', 'start': 225, 'end': 230}, {'entity': 'I-PER', 'score': 0.6572199, 'index': 56, 'word': 'Jam', 'start': 231, 'end': 234}, {'entity': 'B-MISC', 'score': 0.92161834, 'index': 58, 'word': 'D', 'start': 236, 'end': 237}]\n"
     ]
    }
   ],
   "source": [
    "example = nyc_posts_df['caption'][3]\n",
    "\n",
    "ner_results = nlp(example)\n",
    "print(example)\n",
    "print()\n",
    "print(ner_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text anonymization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SynTF method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SYNSETS = False\n",
    "TEXT_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3621\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3622\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-09737ae7c995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moriginal_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnyc_posts_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnyc_posts_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3505\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3506\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3622\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3623\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3624\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3625\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "original_docs = nyc_posts_df.loc[nyc_posts_df['text'].str.len() > 100, 'text'][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'@\\w+', ' ', text.lower())\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    words = text.split()\n",
    "    words = filter(lambda x: x not in eng_stopwords, words)\n",
    "    return ' '.join(lemmatizer.lemmatize(x) for x in words)\n",
    "\n",
    "def get_synonyms(uniq_words):\n",
    "    all_synonyms = set()\n",
    "    for word in uniq_words:\n",
    "        synonyms = wordnet.synsets(word)\n",
    "        all_synonyms.update(chain.from_iterable([word.lemma_names() for word in synonyms]))\n",
    "    return all_synonyms\n",
    "\n",
    "docs = original_docs.apply(preprocess).tolist()\n",
    "if USE_SYNSETS:\n",
    "    uniq_words = set(chain.from_iterable([doc.split() for doc in docs]))\n",
    "    synonyms = ' '.join(get_synonyms(uniq_words))\n",
    "    docs_with_synonyms = [*docs, synonyms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "if USE_SYNSETS:\n",
    "    tfidf.fit(docs_with_synonyms)\n",
    "else:\n",
    "    tfidf.fit(docs)\n",
    "doc_vecs = tfidf.transform(docs)\n",
    "doc_vecs = normalize(doc_vecs, norm='l1')\n",
    "words = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7458"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = fasttext.load_facebook_model(datapath('/mnt/ess_storage/DN_1/storage/home/vpanov/cc.en.300.bin.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7458, 7458)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vecs = [ft.wv[word] for word in words]\n",
    "word_similarities = cosine_similarity(word_vecs, word_vecs)\n",
    "word_similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kgram_overlap(word1, word2, k):\n",
    "    a = set([word1[i:i+k] for i in range(0, len(word1) - k + 1)])\n",
    "    b = set([word2[i:i+k] for i in range(0, len(word2) - k + 1)])\n",
    "    inter = len(a.intersection(b))\n",
    "    return inter / (len(a) + len(b) - inter)\n",
    "\n",
    "def score(word1, word2):\n",
    "    idx1, idx2 = tfidf.vocabulary_[word1], tfidf.vocabulary_[word2]\n",
    "    return word_similarities[idx1, idx2] - 0.3 * kgram_overlap(word1, word2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://programming-dp.com/notebooks/ch9.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unforgettable ['unedited']\n"
     ]
    }
   ],
   "source": [
    "def exponential_gen(x, R, u, sensitivity=1, epsilon=25.4):\n",
    "    # Calculate the score for each element of R\n",
    "    scores = [u(x, r) for r in R]\n",
    "    \n",
    "    # Calculate the probability for each element, based on its score\n",
    "    probabilities = [np.exp(epsilon * score / (2 * sensitivity)) for score in scores]\n",
    "    \n",
    "    # Normalize the probabilties so they sum to 1\n",
    "    probabilities = probabilities / np.linalg.norm(probabilities, ord=1)\n",
    "\n",
    "    # Choose an element from R based on the probabilities\n",
    "    return np.random.choice(R, 1, p=probabilities)\n",
    "\n",
    "num = 7000\n",
    "print(words[num], exponential_gen(words[num], words, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3342ecb536a0454d9452dbfbf1e3cd3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=7458.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7458, 7458)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exponential(x, R, u, sensitivity=1, epsilon=25.4):\n",
    "    # Calculate the score for each element of R\n",
    "    scores = [u(x, r) for r in R]\n",
    "    \n",
    "    # Calculate the probability for each element, based on its score\n",
    "    probabilities = [np.exp(epsilon * score / (2 * sensitivity)) for score in scores]\n",
    "    \n",
    "    # Normalize the probabilties so they sum to 1\n",
    "    probabilities = probabilities / np.linalg.norm(probabilities, ord=1)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "word_replace_probs = []\n",
    "\n",
    "for word in tqdm(words):\n",
    "    word_replace_probs.append(exponential(word, words, score))\n",
    "\n",
    "word_replace_probs = np.array(word_replace_probs)\n",
    "word_replace_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--ORIGINAL--\n",
      "Right or Left?\n",
      "\n",
      "Buffalo Chicken slice on the right and Chicken, Bacon(beef), Ranch on the left from @saucny, all new halal pizza spot in New Hyde Park.\n",
      "--PREPROCESSED--\n",
      "right left buffalo chicken slice right chicken bacon beef ranch left new halal pizza spot new hyde park\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "freshwater bend fish horn lyndhurst cabbage placed rice priestley proof goat rippon bacon inside pork nearby spot though\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "Poor Cyndy!  This superstar massage therapist had to endure an hour of Amy's special playlist with The Sky treatment to break a 4 day cuckoo migraine.  Wow, this treatment works!  But, Cyndy will never ever want to listen to Pearl Jam, DMB or REM again.\n",
      "--PREPROCESSED--\n",
      "poor cyndy superstar massage therapist endure hour amy special playlist sky treatment break 4 day cuckoo migraine wow treatment work cyndy never ever want listen pearl jam dmb rem\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "spray elizabeth falling karen occasion atlanta visited soft revamped heidi superstar else crush tech scott blue elizabeth nice folklore kitt edwin programing tmn defiantly waking rosie drummer twelve product\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "he hit the booty like a drum, yumyum.üòÄ why he wanna stutter and he know he wanna butter my buns and have all of my sons. got them young and old like yang hyun suk and bang yong guk and my baby knows how to cook, red suit,  korean look.  startin all them trends in the mercedes benz playin that kpop, that jrock, i'm playin with that cüêàüêìk he likes a chick that plays wu tang that's how we bang, loves to talk slang knows how to freestyle knows how to get buckwild. he's a little bit of bruce lee doin karate, he a hottie he pulls out the shottie and we keep it sexual, also intellectual they askin what the dragon  do! üêâüî•üî•üî•                   üçéüçè          üòò‚õ≤üòúüí±üì≥üåÉüíöüí´\n",
      "--PREPROCESSED--\n",
      "hit booty like drum yumyum wanna stutter know wanna butter bun son got young old like yang hyun suk bang yong guk baby know cook red suit korean look startin trend mercedes benz playin kpop jrock playin c k like chick play wu tang bang love talk slang know freestyle know get buckwild little bit bruce lee doin karate hottie pull shottie keep sexual also intellectual askin dragon\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "jen strangely booty dj bruce pulling ndido guk intellectual infant whine garlic alright ssi hackensack slang let nicole heavy blvd heat samantha stutter look giant husband jummah ure bagel everywhere bjj echt enrichment second mater charming hell trans rts adversity push uch sobre new chunky true zou pointed verlo streammiter rhd conozcas sportin girl nenhum farm ah medical seriously tof little firsties sky naomi suk cheryl bit key\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "First cocktail of the day ‚Äî Three Hearts ‚Äî featuring Kansas distilled spirit. And our bartender just finished writing her first play.\n",
      "--PREPROCESSED--\n",
      "first cocktail day three heart featuring kansa distilled spirit bartender finished writing first play\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "twice fourth summer timing kansa finishing allowing second seven includes snack clase unfinished named\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "Just a week away we are welcoming all the youth from ages 14-18 !!! Let us start this year with God !\n",
      "--PREPROCESSED--\n",
      "week away welcoming youth age 14 18 let u start year god\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "34 23 welcoming god joyous hating pursuing adult month 30 true announcing\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for idx, doc in enumerate(docs[:5]):\n",
    "    print('--ORIGINAL--')\n",
    "    print(original_docs[original_docs.index[idx]])\n",
    "    print('--PREPROCESSED--')\n",
    "    print(doc)\n",
    "    print('--GENERATED SEQUENCE (WITHOUT WORD ORDER)--')\n",
    "    words_count = len(doc.split())\n",
    "    words_ = np.random.choice(words, words_count, p=doc_vecs[idx].todense().tolist()[0])\n",
    "    for i in range(words_count):\n",
    "        word_idx = tfidf.vocabulary_[words_[i]]\n",
    "        words_[i] = np.random.choice(words, 1, p=word_replace_probs[word_idx])[0]\n",
    "    print(' '.join(words_))\n",
    "    print('-'*150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ER-AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = 'distilbert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bert = AutoModel.from_pretrained(model_name, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 146, 1176, 18348, 119, 1262, 22888, 119, 102] [CLS] I like pigs. And apples. [SEP]\n",
      "[101, 178, 1176, 18348, 119, 1105, 22888, 119, 102] [CLS] i like pigs. and apples. [SEP]\n",
      "[101, 178, 1176, 18348, 119, 1105, 22888, 119, 102] [CLS] i like pigs. and apples. [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode('I like pigs. And apples.'), tokenizer.decode(tokenizer.encode('I like pigs. And apples.')))\n",
    "print(tokenizer.encode('i like pigs. and apples.'), tokenizer.decode(tokenizer.encode('i like pigs. and apples.')))\n",
    "print(tokenizer.encode('i like pigs . and apples .'), tokenizer.decode(tokenizer.encode('i like pigs . and apples .')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(doc):\n",
    "    doc = tokenizer.decode(tokenizer.encode(doc, max_length=128, padding='max_length', truncation=True))\n",
    "#     doc = tokenizer.decode(tokenizer.encode(doc))\n",
    "    doc = re.sub(r'([\\.,\\'‚Äô\\\"\\-!\\?\\(\\)])', r' \\1 ', doc)\n",
    "    doc = re.sub('\\s', ' ', doc)\n",
    "    return doc.split()\n",
    "\n",
    "unique_tokens = set(chain.from_iterable([*train_posts.text.apply(get_words).tolist(),\n",
    "                                       *test_posts.text.apply(get_words).tolist()]))\n",
    "\n",
    "token2idx = {token: idx for idx, token in enumerate(unique_tokens)}\n",
    "idx2token = {idx: token for idx, token in enumerate(unique_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_TOKEN_ID = token2idx['[CLS]']\n",
    "EOS_TOKEN_ID = token2idx['[SEP]']\n",
    "PAD_TOKEN_ID = token2idx['[PAD]']\n",
    "\n",
    "VOCAB_SIZE = len(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26571"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_idx(sent: str, word: str):\n",
    "    return sent.split(\" \").index(word)\n",
    "\n",
    "def get_hidden_states(encoded, token_ids_words, model, layers):\n",
    "    \"\"\"Push input IDs through model. Stack and sum `layers` (last four by default).\n",
    "        Select only those subword token outputs that belong to our word of interest\n",
    "        and average them.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded)\n",
    " \n",
    "    # Get all hidden states\n",
    "    states = output.hidden_states\n",
    "    # Stack and sum all requested layers\n",
    "    output = torch.stack([states[i] for i in layers]).sum(0).squeeze()\n",
    "    \n",
    "    res = []\n",
    "    labels_count = []\n",
    "    \n",
    "    for idx, (outp, label) in enumerate(zip(output, token_ids_words)):\n",
    "        if label is None or token_ids_words[idx - 1] is None or token_ids_words[idx - 1] != token_ids_words[idx]:\n",
    "            res.append(outp)\n",
    "            labels_count.append(1)\n",
    "        else: \n",
    "            res[-1] += outp\n",
    "            labels_count[-1] += 1\n",
    "    \n",
    "    res = torch.vstack(res)\n",
    "    res = res / torch.tensor(labels_count).float().unsqueeze(1)\n",
    " \n",
    "    return res\n",
    "\n",
    "\n",
    "def get_word_vectors(sent, tokenizer, model, layers):\n",
    "    \"\"\"Get a word vector by first tokenizing the input sentence, getting all token idxs\n",
    "        that make up the word of interest, and then `get_hidden_states`.\"\"\"\n",
    "    encoded = tokenizer.encode_plus(sent, return_tensors=\"pt\", max_length=128, padding='max_length', truncation=True)\n",
    "    return get_hidden_states(encoded, encoded.word_ids(), model, layers)\n",
    "\n",
    "\n",
    "def exmpl(layers=None):\n",
    "    # Use last four layers by default\n",
    "    layers = [-4, -3, -2, -1] if layers is None else layers\n",
    "\n",
    "    sent = train_posts.text[train_posts.index[23]]\n",
    "\n",
    "    word_embedding = get_word_vectors(sent, tokenizer, bert, layers)\n",
    "\n",
    "    return word_embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([119, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exmpl().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "['[CLS]', 'outpour', 'is', 'here', 'all', 'the', 'vlogs', 'led', 'us', 'to', 'this', '!', 'you', 'don', \"'\", 't', 'want', 'to', 'miss', 'what', 'we', 'have', 'prepared', 'for', 'you', '.', 'come', 'expecting', '!', 'doors', 'open', 'at', '6', ':', '30pm', ',', 'come', 'early', 'and', 'get', 'our', 'new', 'merch', 'at', 'the', 'pop', 'up', 'shop', '!', 'special', 'guests', ':', '@', 'havilahcunnington', '@', 'annagoldenmusic', '@', 'waynefrancis', '@', 'degroves', 'wednesday', '/', '/', '7pm', 'thursday', '/', '/', '7pm', 'friday', '/', '/', '7pm', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (97) must match the existing size (98) at non-singleton dimension 0.  Target sizes: [97, 768].  Tensor sizes: [98, 1]\n",
      "688\n",
      "['[CLS]', 'help', 'barc', 'out', '!', '!', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', 'for', 'next', '15', 'days', 'only', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (117) must match the existing size (118) at non-singleton dimension 0.  Target sizes: [117, 768].  Tensor sizes: [118, 1]\n",
      "1054\n",
      "['[CLS]', 'come', 'check', 'out', 'my', 'day', 'time', 'bar', 'star', '@', 'andrellamaringa', 'as', 'she', 'create', 'her', 'signature', 'cocktails', '@', 'chefdomcreates', '@', 'larouge', '_', 'restaurant', '_', 'lounge', 'we', 'don', \"'\", 't', 'own', 'the', 'rights', 'to', 'this', 'song', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (119) must match the existing size (120) at non-singleton dimension 0.  Target sizes: [119, 768].  Tensor sizes: [120, 1]\n",
      "1294\n",
      "['[CLS]', '1', 'more', 'days', 'till', 'the', 'biggest', 'birthday', 'celebration', '@', 'empireloungenj', '@', 'chefdomcreates', '@', 'unclevinrock', '@', 'larouge', '_', 'restaurant', '_', 'lounge', '@', 'sa', '_', 'kye', '_', 'dom', '@', 'djsupadice', '@', 'mrdjovaflow', '@', 'judexmrgoodlife', 'chef', 'dom', \"'\", 's', 'birthday', 'celebration', '!', '!', '!', 'bottle', 'service', ',', 'hookah', ',', 'food', 'will', 'be', 'catered', 'by', 'no', 'other', 'but', 'me', 'lol', ',', 'vip', 'section', 'available', '.', '.', '.', '.', '.', '.', 'stay', 'tune', 'for', 'more', 'details', '\"', 'i', 'don', \"'\", 't', 'own', 'the', 'copyright', 'to', 'this', 'song', '\"', 'empire', 'lounge', 'vip', 'section', 'still', 'available', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (95) must match the existing size (96) at non-singleton dimension 0.  Target sizes: [95, 768].  Tensor sizes: [96, 1]\n",
      "1757\n",
      "['[CLS]', 'new', 'collection', 'alert', '.', '.', 'an', 'exclusive', 'sneak', 'peek', 'from', 'amici', 'by', 'baci', 'we', 'have', 'just', 'received', '!', 'this', 'is', 'one', 'collection', 'you', 'don', \"'\", 't', 'want', 'to', 'miss', '!', '.', '.', '.', 'you', 'can', 'contact', 'amici', 'through', 'baci', 'via', 'the', 'link', 'in', 'our', 'bio', 'for', 'more', 'information', 'about', 'the', 'line', '.', '.', 'hudson', 'mercantile', ',', 'february', '24', '-', '26', '2019', ',', 'studio', 'atelier', 'nyc', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (111) must match the existing size (112) at non-singleton dimension 0.  Target sizes: [111, 768].  Tensor sizes: [112, 1]\n",
      "2078\n",
      "['[CLS]', 'missing', 'dog', ':', 'lily', ',', 'still', 'with', 'leash', 'and', 'harness', ',', 'last', 'seen', 'on', 'prospect', 'park', 'west', 'and', '5th', 'street', '.', 'don', \"'\", 't', 'chase', 'if', 'seen', '!', '!', '!', 'call', 'lindsey', 'at', '917', '-', '515', '-', '4355', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (121) must match the existing size (122) at non-singleton dimension 0.  Target sizes: [121, 768].  Tensor sizes: [122, 1]\n",
      "2087\n",
      "['[CLS]', 'enough', 'with', 'the', 'hamburger', 'and', 'hotdogs', '.', '.', '.', '.', 'come', 'eat', 'some', 'real', 'food', 'and', 'drinks', 'at', 'larouge', 'lounge', 'and', 'restaurant', '972', 'broad', 'street', 'newark', 'nj', '@', 'chefdomcreates', '@', 'larouge', '_', 'restaurant', '_', 'lounge', 'kitchen', 'open', '6', '-', '12am', 'today', 'i', 'don', \"'\", 't', 'own', 'the', 'right', 'to', 'the', 'songs', 'playing', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (113) must match the existing size (114) at non-singleton dimension 0.  Target sizes: [113, 768].  Tensor sizes: [114, 1]\n",
      "2663\n",
      "['[CLS]', 'enough', 'with', 'the', 'hamburger', 'and', 'hotdogs', '.', '.', '.', '.', 'come', 'eat', 'some', 'real', 'food', 'and', 'drinks', 'at', 'larouge', 'lounge', 'and', 'restaurant', '972', 'broad', 'street', 'newark', 'nj', '@', 'chefdomcreates', '@', 'larouge', '_', 'restaurant', '_', 'lounge', 'kitchen', 'open', '6', '-', '12am', 'today', 'i', 'don', \"'\", 't', 'own', 'the', 'right', 'to', 'the', 'songs', 'playing', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (113) must match the existing size (114) at non-singleton dimension 0.  Target sizes: [113, 768].  Tensor sizes: [114, 1]\n",
      "2706\n",
      "['[CLS]', 'copper', 'has', 'had', 'a', 'very', 'exhausting', 'day', 'meeting', 'his', 'new', 'family', ',', 'friends', ',', 'home', ',', 'and', 'hang', 'out', 'spots', '!', 'please', 'don', \"'\", 't', 'wake', 'him', 'from', 'his', 'nap', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (127) must match the existing size (128) at non-singleton dimension 0.  Target sizes: [127, 768].  Tensor sizes: [128, 1]\n",
      "2944\n",
      "['[CLS]', 'caries', 'are', 'true', 'cavities', 'in', 'animals', '.', 'they', 'are', 'caused', 'by', 'consumption', 'of', 'carbohydrates', 'such', 'as', 'peas', ',', 'carrots', ',', 'green', 'beans', ',', 'and', 'sweet', 'potatoes', '.', 'unlike', 'people', ',', 'we', 'don', \"'\", 't', 'fill', 'cavities', ',', 'the', 'treatment', 'would', 'be', 'extraction', 'of', 'the', 'tooth', '.', 'brushing', 'can', 'help', 'remove', 'food', 'particles', 'stuck', 'in', 'teeth', 'that', 'may', 'contribute', 'to', 'cavities', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (115) must match the existing size (116) at non-singleton dimension 0.  Target sizes: [115, 768].  Tensor sizes: [116, 1]\n",
      "3130\n",
      "['[CLS]', 'show', 'your', 'support', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', 'for', 'next', '25', 'days', 'only', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (118) must match the existing size (119) at non-singleton dimension 0.  Target sizes: [118, 768].  Tensor sizes: [119, 1]\n",
      "3184\n",
      "['[CLS]', 'heatwave', 'in', 'effect', 'the', 'next', 'couple', 'days', '.', 'keep', 'your', 'pets', 'safe', '.', 'don', \"'\", 't', 'pour', 'water', 'on', 'them', 'outside', 'in', 'the', 'heat', ',', 'you', 'are', 'cooking', 'their', 'skin', '.', 'stay', 'indoors', '!', '!', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (126) must match the existing size (127) at non-singleton dimension 0.  Target sizes: [126, 768].  Tensor sizes: [127, 1]\n",
      "3506\n",
      "['[CLS]', 'help', 'barc', 'out', '!', '!', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', '9', 'days', 'only', 'left', 'on', 'this', 'fundraiser', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (116) must match the existing size (117) at non-singleton dimension 0.  Target sizes: [116, 768].  Tensor sizes: [117, 1]\n",
      "3545\n",
      "['[CLS]', 'spots', 'are', 'going', 'fast', 'for', 'our', 'next', 'on', 'march', '16', '!', '!', '!', 'be', 'sure', 'to', 'call', 'our', 'store', 'to', 'pre', '-', 'register', '.', 'we', 'will', 'be', 'donating', 'the', 'proceeds', 'we', 'get', 'from', 'the', 'venue', 'fee', 'to', 'the', '@', 'americancancersociety', ',', 'so', 'please', 'spread', 'the', 'word', '.', 'all', 'donations', 'are', 'welcome', '.', 'you', 'don', \"'\", 't', 'have', 'to', 'be', 'a', 'participate', 'to', 'donate', '.', 'we', 'are', 'also', 'accepting', 'sign', '-', 'ups', 'for', 'our', 'doubles', 'tournament', 'on', 'march', '23rd', '!', 'you', 'must', 'pre', '-', 'register', 'both', 'yourself', 'and', 'your', 'partner', 'when', 'you', 'call', '.', 'thank', 'you', '!', 'for', 'more', 'info', 'on', 'our', 'policies', 'and', 'rulesets', ',', 'please', 'visit', 'sidescrollersnj', '.', 'com', '/', 'tournaments', '[SEP]', '[PAD]']\n",
      "The expanded size of the tensor (114) must match the existing size (115) at non-singleton dimension 0.  Target sizes: [114, 768].  Tensor sizes: [115, 1]\n",
      "3626\n",
      "['[CLS]', '\"', 'microchips', 'greatly', 'increase', 'the', 'chances', 'that', 'pets', 'will', 'be', 'reuinted', 'with', 'their', 'families', 'if', 'they', 'are', 'lost', 'or', 'stolen', ',', 'but', 'a', 'microchip', 'only', 'works', 'if', 'its', 'registration', 'information', 'is', 'accurate', '.', '\"', 'when', 'we', 'place', 'a', 'microchip', '@', 'abingdonsquarevet', 'we', 'register', 'the', 'chip', 'for', 'you', 'but', 'you', 'need', 'to', 'keep', 'the', 'info', 'up', 'to', 'date', '!', 'if', 'your', 'pet', 'already', 'has', 'a', 'chip', ',', 'we', 'can', 'scan', 'it', 'and', 'provide', 'you', 'the', 'number', '.', '<', 'url', '>', 'can', 'be', 'helpful', 'if', 'you', 'know', 'the', 'microchip', 'number', 'but', 'don', \"'\", 't', 'know', 'what', 'company', 'to', 'register', 'your', 'pet', \"'\", 's', 'microchip', '!', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (109) must match the existing size (110) at non-singleton dimension 0.  Target sizes: [109, 768].  Tensor sizes: [110, 1]\n",
      "3640\n",
      "['[CLS]', '5', 'days', 'remaining', '!', '!', 'help', 'barc', 'out', ',', 'only', '6', 'days', 'left', '!', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', '5', 'days', 'only', 'left', 'on', 'this', 'fundraiser', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (116) must match the existing size (117) at non-singleton dimension 0.  Target sizes: [116, 768].  Tensor sizes: [117, 1]\n",
      "3642\n",
      "['[CLS]', 'all', 'of', 'our', 'services', 'are', 'by', 'appointment', 'only', '.', 'we', 'don', \"'\", 't', 'take', 'any', 'walk', '-', 'ins', '.', 'we', 'want', 'to', 'ensure', 'that', 'no', 'one', 'is', 'waiting', 'and', 'that', 'everyone', 'may', 'have', 'a', 'wonderful', 'experience', 'with', 'us', 'at', 'gorgeous', 'spa', '.', 'send', 'us', 'a', 'direct', 'message', 'or', 'call', 'us', 'at', '(', '347', ')', '460', '-', '6006', '.', 'we', 'look', 'forward', 'to', 'hearing', 'from', 'you', 'gorgeous', '!', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (126) must match the existing size (127) at non-singleton dimension 0.  Target sizes: [126, 768].  Tensor sizes: [127, 1]\n",
      "3762\n",
      "['[CLS]', 'we', 'don', \"'\", 't', 'cross', 'our', 'arms', 'to', 'rest', ',', 'only', 'just', 'to', 'show', 'our', 'wonders', 'of', 'design', 'fingerless', 'gloves', 'de', 'main', '145', 'front', 'st', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (126) must match the existing size (127) at non-singleton dimension 0.  Target sizes: [126, 768].  Tensor sizes: [127, 1]\n",
      "4122\n",
      "['[CLS]', 'join', 'us', 'friday', ',', 'june', '21st', 'at', '8', ':', '15pm', 'for', 'our', 'kickoff', 'to', 'summer', 'black', 'light', 'class', '!', 'this', '90', 'minute', 'class', 'with', 'feature', '2', 'surprise', 'trainers', '!', 'if', 'you', 'would', 'like', 'an', 'official', 'cko', 'black', 'light', 'shirt', ',', 'preorder', 'yours', 'at', 'the', 'front', 'desk', 'for', '$', '15', 'by', 'sunday', ',', 'june', '9th', '!', '!', 'wear', 'neon', 'or', 'white', 'shirts', 'if', 'you', 'don', \"'\", 't', 'purchase', 'a', 'cko', 'shirt', '.', 'reserve', 'your', 'bag', 'at', 'the', 'front', 'desk', 'or', 'dm', 'to', 'reserve', 'your', 'spot', '!', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (116) must match the existing size (117) at non-singleton dimension 0.  Target sizes: [116, 768].  Tensor sizes: [117, 1]\n",
      "4181\n",
      "['[CLS]', 'robell', 'is', 'everyday', '-', 'luxury', 'for', 'women', 'who', 'don', \"'\", 't', 'want', 'to', 'compromise', 'when', 'it', 'comes', 'to', 'look', 'or', 'comfort', '.', '.', 'if', 'you', 'buy', 'a', 'pair', 'of', 'robell', 'trousers', ',', 'you', 'are', 'guaranteed', 'a', 'high', 'quality', '-', 'at', 'reasonable', 'prices', '.', '.', 'robell', 'knows', 'that', 'each', 'woman', 'is', 'different', '.', 'therefore', ',', 'you', 'will', 'find', 'the', 'trousers', 'and', 'jeans', 'in', 'different', 'styles', 'in', 'a', 'number', 'of', 'colours', 'and', 'fashionable', 'prints', '-', 'whether', 'you', 'prefer', 'a', 'classical', 'or', 'a', 'more', 'stylish', 'look', '.', '.', '.', 'you', 'can', 'contact', 'robell', 'through', 'godske', 'group', 'via', '.', '.', 'hudson', 'mercantile', ',', 'february', '24', '-', '26', '2019', ',', 'studio', 'atelier', 'nyc', '.', '[SEP]']\n",
      "The expanded size of the tensor (110) must match the existing size (111) at non-singleton dimension 0.  Target sizes: [110, 768].  Tensor sizes: [111, 1]\n",
      "4354\n",
      "['[CLS]', '1', 'more', 'days', 'till', 'the', 'biggest', 'birthday', 'celebration', '@', 'empireloungenj', '@', 'chefdomcreates', '@', 'unclevinrock', '@', 'larouge', '_', 'restaurant', '_', 'lounge', '@', 'sa', '_', 'kye', '_', 'dom', '@', 'djsupadice', '@', 'mrdjovaflow', '@', 'judexmrgoodlife', 'chef', 'dom', \"'\", 's', 'birthday', 'celebration', '!', '!', '!', 'bottle', 'service', ',', 'hookah', ',', 'food', 'will', 'be', 'catered', 'by', 'no', 'other', 'but', 'me', 'lol', ',', 'vip', 'section', 'available', '.', '.', '.', '.', '.', '.', 'stay', 'tune', 'for', 'more', 'details', '\"', 'i', 'don', \"'\", 't', 'own', 'the', 'copyright', 'to', 'this', 'song', '\"', 'empire', 'lounge', 'vip', 'section', 'still', 'available', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (95) must match the existing size (96) at non-singleton dimension 0.  Target sizes: [95, 768].  Tensor sizes: [96, 1]\n",
      "4423\n",
      "['[CLS]', 'did', 'you', 'make', 'our', 'last', 'black', 'light', 'class', '?', 'if', 'not', '.', '.', '.', 'join', 'us', 'friday', ',', 'june', '21st', 'at', '8', ':', '15pm', 'for', 'our', 'kickoff', 'to', 'summer', 'black', 'light', 'class', '!', 'if', 'you', 'would', 'like', 'an', 'official', 'cko', 'black', 'light', 'shirt', ',', 'preorder', 'yours', 'at', 'the', 'front', 'desk', 'for', '$', '15', 'by', 'sunday', ',', 'june', '9th', '!', '!', '!', 'wear', 'neon', 'or', 'white', 'shirts', 'if', 'you', 'don', \"'\", 't', 'purchase', 'a', 'cko', 'shirt', '.', 'reserve', 'your', 'spot', 'at', 'the', 'front', 'desk', 'or', 'by', 'dm', '!', 'don', \"'\", 't', 'forget', 'after', 'party', 'at', 'cj', \"'\", 's', 'at', '10pm', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (114) must match the existing size (115) at non-singleton dimension 0.  Target sizes: [114, 768].  Tensor sizes: [115, 1]\n",
      "4590\n",
      "['[CLS]', 'lost', 'dog', 'named', 'murphy', ',', 'slipped', 'out', 'of', 'her', 'harness', 'around', 'gates', 'and', 'marcy', 'avenue', ',', 'brooklyn', '.', 'don', \"'\", 't', 'chase', '!', 'offer', 'treats', '!', 'any', 'sightings', 'or', 'information', ',', 'call', '301', '-', '956', '-', '6937', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (119) must match the existing size (120) at non-singleton dimension 0.  Target sizes: [119, 768].  Tensor sizes: [120, 1]\n",
      "4661\n",
      "['[CLS]', '\"', 'don', \"'\", 'thing', 'from', 'selfish', 'ambition', 'or', 'conceit', ',', 'but', 'in', 'humility', 'count', 'others', 'more', 'significant', 'than', 'yourselves', '.', '\"', '-', 'philippians', '2', ':', '3', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (120) must match the existing size (121) at non-singleton dimension 0.  Target sizes: [120, 768].  Tensor sizes: [121, 1]\n",
      "5221\n",
      "['[CLS]', 'friends', ',', 'please', 'don', \"'\", 't', 'forget', 'to', 'reserve', 'your', 'table', 'for', 'fathers', 'day', 'for', 'this', 'sunday', '!', 'we', 'still', 'have', 'some', 'tables', 'available', ',', 'but', 'please', 'rush', '!', 'happy', 'fathers', 'day', 'guys', '!', '347', '-', '673', '-', '5411', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (124) must match the existing size (125) at non-singleton dimension 0.  Target sizes: [124, 768].  Tensor sizes: [125, 1]\n",
      "6001\n",
      "['[CLS]', 'barc', 'shelter', 'just', 'updated', 'our', 'wishlist', 'on', 'amazon', ',', 'and', 'we', 'are', 'out', 'of', 'stock', 'on', 'these', 'items', '.', 'if', 'you', 'would', 'like', 'to', 'donate', ',', 'go', 'to', '@', 'barcshelter', 'and', 'on', 'our', 'profile', 'you', 'will', 'see', 'our', 'amazon', 'wishlist', '.', 'if', 'you', 'don', \"'\", 't', 'want', 'to', 'purchase', 'through', 'amazon', ',', 'you', 'can', 'also', 'get', 'it', 'through', 'costco', '/', 'target', 'or', 'buy', 'it', 'locally', 'and', 'drop', 'it', 'off', '.', 'every', 'little', 'thing', 'helps', '.', 'thank', 'you', 'for', 'your', 'kind', 'heart', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (115) must match the existing size (116) at non-singleton dimension 0.  Target sizes: [115, 768].  Tensor sizes: [116, 1]\n",
      "6910\n",
      "['[CLS]', 'every', 'week', 'we', 'get', 'submissions', 'from', 'people', 'from', 'around', 'the', 'world', 'for', 'a', 'segment', 'of', 'our', 'open', 'mic', 'called', '\"', 'read', 'my', 'lines', '.', '\"', 'this', 'allows', 'artists', 'to', 'submit', 'their', 'work', 'whenever', 'they', 'cannot', 'attend', 'our', 'events', 'or', 'if', 'they', 'don', \"'\", 't', 'live', 'in', 'our', 'country', 'or', 'state', 'or', 'if', 'they', 'have', 'stage', 'fright', 'but', 'still', 'want', 'their', 'voice', 'heard', ',', 'and', 'a', 'volunteer', 'will', 'be', 'recorded', 'reading', 'their', 'work', '.', '.', 'we', 'would', 'like', 'to', 'give', 'a', 'big', 'shoutout', 'to', '@', 'shay', '_', 'marie', '_', 'g', 'for', 'an', 'awesome', 'job', 'reading', '@', 'kingcesar1583', 'erotic', 'short', 'story', '.', 'special', 'thank', 'you', 'to', '@', 'kingcesar1583', 'for', 'submitting', 'his', 'work', '[SEP]']\n",
      "The expanded size of the tensor (111) must match the existing size (112) at non-singleton dimension 0.  Target sizes: [111, 768].  Tensor sizes: [112, 1]\n",
      "7412\n",
      "['[CLS]', 'did', 'you', 'make', 'our', 'last', 'black', 'light', 'class', '?', 'if', 'not', '.', '.', '.', 'join', 'us', 'friday', ',', 'june', '21st', 'at', '8', ':', '15pm', 'for', 'our', 'kickoff', 'to', 'summer', 'black', 'light', 'class', '!', 'if', 'you', 'would', 'like', 'an', 'official', 'cko', 'black', 'light', 'shirt', ',', 'preorder', 'yours', 'at', 'the', 'front', 'desk', 'for', '$', '15', 'by', 'sunday', ',', 'june', '9th', '!', '!', '!', 'wear', 'neon', 'or', 'white', 'shirts', 'if', 'you', 'don', \"'\", 't', 'purchase', 'a', 'cko', 'shirt', '.', 'reserve', 'your', 'spot', 'at', 'the', 'front', 'desk', 'or', 'by', 'dm', '!', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (116) must match the existing size (117) at non-singleton dimension 0.  Target sizes: [116, 768].  Tensor sizes: [117, 1]\n",
      "7800\n",
      "['[CLS]', '~', 'where', 'can', 'you', 'relax', 'and', 'fully', 'be', 'yourself', '~', '.', '~', 'where', 'can', 'you', 'go', 'and', 'feel', 'loved', 'and', 'safe', '?', '~', '.', '~', 'where', 'is', 'the', 'place', 'you', 'can', 'go', 'and', 'heal', 'from', 'the', 'areas', 'in', 'which', 'you', 'don', \"'\", 't', 'feel', 'supported', '?', '~', '.', 'it', 'can', 'be', 'hard', 'to', 'find', 'a', 'place', 'like', 'that', 'and', 'when', 'you', 'do', '.', '.', '.', 'hold', 'onto', 'it', '.', '.', 'join', 'us', 'tonight', 'for', 'a', 'healing', 'soundbath', 'with', 'shunny', '@', 'sounddreamsnyc', '.', 'last', 'sound', 'bath', 'of', 'the', 'decade', 'learning', 'how', 'to', 'manifest', 'our', 'realities', 'and', 'find', 'happiness', 'within', 'ourselves', 'amongst', 'a', 'wild', 'continuously', 'moving', 'and', 'chaotic', 'world', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (120) must match the existing size (121) at non-singleton dimension 0.  Target sizes: [120, 768].  Tensor sizes: [121, 1]\n",
      "8582\n",
      "['[CLS]', 'barc', 'shelter', 'is', 'almost', 'out', 'of', 'these', 'cleaning', 'items', '.', 'if', 'you', 'would', 'like', 'to', 'donate', ',', 'go', 'to', '@', 'barcshelter', 'and', 'on', 'our', 'profile', 'you', 'will', 'see', 'our', 'amazon', 'wishlist', '.', 'if', 'you', 'don', \"'\", 't', 'want', 'to', 'purchase', 'through', 'amazon', ',', 'you', 'can', 'also', 'get', 'it', 'through', 'costco', ',', 'or', 'buy', 'it', 'locally', 'and', 'drop', 'it', 'off', '.', 'every', 'little', 'thing', 'helps', '.', 'thank', 'you', 'for', 'your', 'kind', 'heart', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (118) must match the existing size (119) at non-singleton dimension 0.  Target sizes: [118, 768].  Tensor sizes: [119, 1]\n",
      "8758\n",
      "['[CLS]', 'how', 'did', 'we', 'not', 'respect', 'this', '.', '.', '.', 'we', 'complain', 'about', 'but', 'we', 'don', \"'\", 't', 'keep', 'shit', 'up', '?', '?', '!', '!', 'let', \"'\", 's', 'talk', 'about', 'it', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (128) must match the existing size (129) at non-singleton dimension 0.  Target sizes: [128, 768].  Tensor sizes: [129, 1]\n",
      "8800\n",
      "['[CLS]', 'snow', 'is', 'in', 'the', 'forecast', ',', 'but', 'please', 'don', \"'\", 't', 'confuse', 'cute', 'zorro', 'with', 'a', 'snowflake', '.', '@', 'zorro', '_', 'maltese', '_', 'puppy', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (119) must match the existing size (120) at non-singleton dimension 0.  Target sizes: [119, 768].  Tensor sizes: [120, 1]\n",
      "8932\n",
      "['[CLS]', 'help', 'barc', 'out', '!', '!', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', 'for', 'next', '16', 'days', 'only', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (117) must match the existing size (118) at non-singleton dimension 0.  Target sizes: [117, 768].  Tensor sizes: [118, 1]\n",
      "9199\n",
      "['[CLS]', 'tomorrow', 'is', 'saturday', 'at', '!', 'our', 'event', 'will', 'begin', 'at', '5pm', '.', 'register', 'over', 'at', 'smash', '.', 'gg', '(', 'link', 'in', 'bio', ')', '.', 'walk', '-', 'ins', 'are', 'welcome', '.', 'if', 'you', 'don', \"'\", 't', 'have', 'a', 'smash', '.', 'gg', 'account', ',', 'you', 'can', 'make', 'one', 'for', 'free', 'at', 'time', 'of', 'sign', '-', 'up', '.', 'you', 'can', 'find', 'our', 'rules', 'on', 'our', 'smash', '.', 'gg', 'page', 'as', 'well', 'as', 'our', 'website', 'sidescrollersnj', '.', 'com', '/', 'tournaments', 'please', 'note', ':', 'our', 'shop', 'will', 'have', 'a', 'delayed', 'opening', 'at', '2pm', '.', 'the', 'will', 'be', 'closed', 'off', 'to', 'non', '-', 'participants', 'during', 'the', 'tournament', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (116) must match the existing size (117) at non-singleton dimension 0.  Target sizes: [116, 768].  Tensor sizes: [117, 1]\n",
      "9313\n",
      "['[CLS]', 'the', 'best', 'part', 'by', 'living', 'by', 'this', 'view', '&', 'comin', 'home', 'straight', 'after', 'work', 'is', 'that', 'its', 'peaceful', ',', 'a', 'blessing', '&', 'a', 'spot', 'to', 'clear', 'ur', 'mind', '&', 'think', 'about', 'alot', 'of', 'things', 'and', 'relex', 'when', 'u', 'alone', 'but', 'the', 'hardest', 'part', 'about', 'it', 'is', 'when', 'u', 'take', 'the', 'time', 'to', 'think', 'about', 'someone', 'you', 'really', 'miss', '&', 'love', 'but', 'cant', 'don', \"'\", 'thing', 'about', 'it', 'to', 'show', 'them', 'or', 'prove', 'to', 'them', 'what', 'you', 'mean', 'to', 'then', '&', 'l', '@', 'djeasynyc', '@', 'djeasycalderon', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (112) must match the existing size (113) at non-singleton dimension 0.  Target sizes: [112, 768].  Tensor sizes: [113, 1]\n",
      "10910\n",
      "['[CLS]', 'it', \"'\", 's', 'too', 'this', 'week', ',', 'protect', 'your', 'pets', '!', 'also', 'don', \"'\", 't', 'pour', 'water', 'on', 'your', 'pets', 'outside', 'in', 'this', 'heat', ',', 'you', 'will', 'be', 'cooking', 'them', ',', 'walk', 'in', 'the', 'shade', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (128) must match the existing size (129) at non-singleton dimension 0.  Target sizes: [128, 768].  Tensor sizes: [129, 1]\n",
      "10925\n",
      "['[CLS]', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (118) must match the existing size (119) at non-singleton dimension 0.  Target sizes: [118, 768].  Tensor sizes: [119, 1]\n",
      "11052\n",
      "['[CLS]', 'when', 'you', \"'\", 're', 'trapped', 'in', 'the', 'black', 'lodge', ',', 'how', 'long', 'does', 'it', 'take', 'for', 'you', 'to', 'realized', 'you', \"'\", 're', 'stuck', 'in', 'there', '?', '25', 'years', '?', 'it', \"'\", 's', 'hard', 'to', 'say', 'how', 'or', 'why', ',', 'but', 'my', 'burlesque', 'accounts', 'don', \"'\", 't', 'get', 'seen', 'much', 'these', 'days', '.', 'please', 'give', 'us', 'a', 'like', 'and', 'maybe', 'a', 'comment', '?', 'pretty', 'please', '?', 'help', 'me', 'get', 'released', '!', '@', 'thepinkroomburlesque', 'call', 'for', 'help', '!', 'we', \"'\", 're', 'trapped', 'in', 'the', 'black', 'lodge', 'and', 'we', 'cant', 'get', 'out', '!', '@', 'thepinkroomburlesque', 'appears', 'to', 'be', 'under', 'the', 'effects', 'of', 'shadowbanning', '!', 'the', 'instagram', 'algorithms', 'are', 'harder', 'to', '[SEP]']\n",
      "The expanded size of the tensor (108) must match the existing size (109) at non-singleton dimension 0.  Target sizes: [108, 768].  Tensor sizes: [109, 1]\n",
      "11168\n",
      "['[CLS]', 'barc', 'shelter', 'is', 'almost', 'out', 'of', 'these', 'items', '.', 'if', 'you', 'would', 'like', 'to', 'donate', ',', 'go', 'to', '@', 'barcshelter', 'and', 'on', 'our', 'profile', 'you', 'will', 'see', 'our', 'amazon', 'wishlist', '.', 'if', 'you', 'don', \"'\", 't', 'want', 'to', 'purchase', 'through', 'amazon', ',', 'you', 'can', 'also', 'get', 'it', 'through', 'costco', ',', 'or', 'buy', 'it', 'locally', 'and', 'drop', 'it', 'off', '.', 'every', 'little', 'thing', 'helps', '.', 'thank', 'you', 'for', 'your', 'kind', 'heart', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (118) must match the existing size (119) at non-singleton dimension 0.  Target sizes: [118, 768].  Tensor sizes: [119, 1]\n",
      "11291\n",
      "['[CLS]', 'friends', ',', 'please', 'don', \"'\", 't', 'forget', 'to', 'reserve', 'your', 'table', 'for', 'fathers', 'day', 'for', 'this', 'sunday', '!', 'we', 'still', 'have', 'some', 'tables', 'available', ',', 'but', 'please', 'rush', '!', 'happy', 'fathers', 'day', 'guys', '!', '347', '-', '673', '-', '5411', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (124) must match the existing size (125) at non-singleton dimension 0.  Target sizes: [124, 768].  Tensor sizes: [125, 1]\n",
      "11456\n",
      "['[CLS]', 'help', 'barc', 'out', '!', '!', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', 'for', 'next', '20', 'days', 'only', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (117) must match the existing size (118) at non-singleton dimension 0.  Target sizes: [117, 768].  Tensor sizes: [118, 1]\n",
      "13096\n",
      "['[CLS]', 'help', 'barc', 'out', ',', 'only', '6', 'days', 'left', '!', '!', 'barc', 'shelter', 'is', 'doing', 'fundraising', 'via', 'bonfire', ',', '6', 'days', 'only', 'left', 'on', 'this', 'fundraiser', ',', 'with', 'these', 'shirts', 'for', '$', '19', '.', '99', '-', 'comes', 'in', '7', 'sizes', 'xs', '-', '3xl', ',', '5', 'colors', '(', 'white', 'not', 'shown', ')', '-', 'shirts', 'are', 'online', 'only', ',', 'we', 'don', \"'\", 't', 'have', 'them', 'at', 'the', 'shelter', '.', 'go', 'to', 'our', 'profile', '@', 'barcshelter', 'and', 'click', 'the', 'link', 'or', 'go', 'to', '<', 'url', '>', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (116) must match the existing size (117) at non-singleton dimension 0.  Target sizes: [116, 768].  Tensor sizes: [117, 1]\n",
      "13811\n",
      "['[CLS]', 'barc', 'shelter', 'is', 'running', 'out', 'of', 'litter', 'in', 'our', 'cat', 'loft', '.', 'if', 'you', 'would', 'like', 'to', 'donate', ',', 'go', 'to', '@', 'barcshelter', 'and', 'on', 'our', 'profile', 'you', 'will', 'see', 'our', 'amazon', 'wishlist', '.', 'if', 'you', 'don', \"'\", 't', 'want', 'to', 'purchase', 'through', 'amazon', ',', 'you', 'can', 'also', 'get', 'it', 'through', 'costco', ',', 'or', 'buy', 'it', 'locally', 'and', 'drop', 'it', 'off', '.', 'every', 'little', 'thing', 'helps', '.', 'thank', 'you', 'for', 'your', 'kind', 'heart', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (118) must match the existing size (119) at non-singleton dimension 0.  Target sizes: [118, 768].  Tensor sizes: [119, 1]\n",
      "14493\n",
      "['[CLS]', 'all', 'of', 'our', 'services', 'are', 'by', 'appointment', 'only', '.', 'we', 'don', \"'\", 't', 'take', 'any', 'walk', '-', 'ins', '.', 'we', 'want', 'to', 'ensure', 'that', 'no', 'one', 'is', 'waiting', 'and', 'that', 'everyone', 'may', 'have', 'a', 'wonderful', 'experience', 'with', 'us', 'at', 'gorgeous', 'spa', '.', 'send', 'us', 'a', 'direct', 'message', 'or', 'call', 'us', 'at', '(', '347', ')', '460', '-', '6006', '.', 'we', 'look', 'forward', 'to', 'hearing', 'from', 'you', 'gorgeous', '!', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (126) must match the existing size (127) at non-singleton dimension 0.  Target sizes: [126, 768].  Tensor sizes: [127, 1]\n",
      "14945\n",
      "['[CLS]', 'friends', ',', 'please', 'don', \"'\", 't', 'forget', 'to', 'reserve', 'your', 'table', 'for', 'fathers', 'day', 'this', 'sunday', '!', 'we', 'still', 'have', 'some', 'tables', 'available', ',', 'but', 'the', 'holiday', 'is', 'literally', 'tomorrow', '!', 'and', 'happy', 'fathers', 'day', '718', '-', '513', '-', '6004', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (124) must match the existing size (125) at non-singleton dimension 0.  Target sizes: [124, 768].  Tensor sizes: [125, 1]\n",
      "15596\n",
      "['[CLS]', 'barc', 'shelter', 'is', 'almost', 'out', 'of', 'these', 'items', '.', 'if', 'you', 'would', 'like', 'to', 'donate', ',', 'go', 'to', '@', 'barcshelter', 'and', 'on', 'our', 'profile', 'you', 'will', 'see', 'our', 'amazon', 'wishlist', '.', 'if', 'you', 'don', \"'\", 't', 'want', 'to', 'purchase', 'through', 'amazon', ',', 'you', 'can', 'also', 'get', 'it', 'through', 'costco', ',', 'or', 'buy', 'it', 'locally', 'and', 'drop', 'it', 'off', '.', 'every', 'little', 'thing', 'helps', '.', 'thank', 'you', 'for', 'your', 'kind', 'heart', '!', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (118) must match the existing size (119) at non-singleton dimension 0.  Target sizes: [118, 768].  Tensor sizes: [119, 1]\n",
      "15778\n",
      "['[CLS]', 'friends', ',', 'please', 'don', \"'\", 't', 'forget', 'to', 'reserve', 'your', 'table', 'for', 'fathers', 'day', 'for', 'this', 'sunday', '!', 'we', 'still', 'have', 'some', 'tables', 'available', ',', 'but', 'please', 'rush', '!', 'happy', 'fathers', 'day', 'guys', '!', '347', '-', '673', '-', '5411', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (124) must match the existing size (125) at non-singleton dimension 0.  Target sizes: [124, 768].  Tensor sizes: [125, 1]\n",
      "16167\n",
      "['[CLS]', 'friends', ',', 'please', 'don', \"'\", 't', 'forget', 'to', 'reserve', 'your', 'table', 'for', 'fathers', 'day', 'this', 'sunday', '!', 'we', 'still', 'have', 'some', 'tables', 'available', ',', 'but', 'the', 'holiday', 'is', 'literally', 'tomorrow', '!', 'and', 'happy', 'fathers', 'day', '718', '-', '513', '-', '6004', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (124) must match the existing size (125) at non-singleton dimension 0.  Target sizes: [124, 768].  Tensor sizes: [125, 1]\n",
      "16201\n",
      "['[CLS]', 'is', 'it', 'still', 'moonday', '?', 'how', 'luck', 'am', 'i', 'that', 'i', 'get', 'to', 'don', \"'\", 't', 'one', 'butt', 'two', 'shows', 'with', '@', 'mspussnboots', 'this', 'week', '?', 'catch', 'me', 'on', 'tuesday', 'at', '@', 'naughtynoirshow', \"'\", 's', '5th', 'anniversary', 'at', '@', 'thedelancey', 'thursday', 'at', '@', 'stachenovak', \"'\", 's', 'midnight', 'fingers', 'at', '@', 'slipperroomnyc', 'for', 'a', 'lynchian', 'night', 'that', \"'\", 's', 'gonna', 'have', 'you', 'up', 'in', 'flames', 'then', 'stay', 'turned', 'for', '@', 'thepinkroomburlesque', 'to', 'release', 'tickets', 'real', 'soon', 'for', 'our', 'oct', '19th', 'costume', 'party', 'at', '@', 'bedlamnyc', '!', '!', '!', 'scroll', 'to', 'see', '[SEP]']\n",
      "The expanded size of the tensor (91) must match the existing size (92) at non-singleton dimension 0.  Target sizes: [91, 768].  Tensor sizes: [92, 1]\n",
      "16724\n",
      "['[CLS]', 'don', \"'\", 't', 'let', 'the', 'cold', 'stop', 'you', 'from', 'what', 'you', 'love', '!', '.', 'class', 'with', '@', 'daya', '_', 'mama', 'tomorrow', 'at', '8am', '.', 'if', 'you', 'miss', ',', 'it', \"'\", 's', 'ok', '!', 'we', 'have', 'classes', 'all', 'day', '!', 'come', 'by', 'for', 'some', 'yoga', 'and', 'tea', 'and', 'smiles', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "The expanded size of the tensor (125) must match the existing size (126) at non-singleton dimension 0.  Target sizes: [125, 768].  Tensor sizes: [126, 1]\n"
     ]
    }
   ],
   "source": [
    "def get_word_vectors(sent, tokenizer, model, layers):\n",
    "    \"\"\"Get a word vector by first tokenizing the input sentence, getting all token idxs\n",
    "        that make up the word of interest, and then `get_hidden_states`.\"\"\"\n",
    "    \n",
    "    encoded = tokenizer.encode_plus(sent, return_tensors=\"pt\", max_length=128, padding='max_length', truncation=True)\n",
    "    \n",
    "    input_ids = list(map(lambda x: token2idx[x], get_words(sent)))\n",
    "    input_ids = torch.tensor(input_ids).unsqueeze(0)\n",
    "    return get_hidden_states(encoded, encoded.word_ids(), model, layers).cpu(), input_ids\n",
    "\n",
    "def get_embedding(doc, model=bert):\n",
    "    \"Get embedding for each word\"\n",
    "    layers = [-4, -3, -2, -1]\n",
    "    return get_word_vectors(doc, tokenizer, model, layers)\n",
    "\n",
    "embeddings = []\n",
    "input_ids = []\n",
    "\n",
    "token_embeddings = torch.zeros((VOCAB_SIZE, 768))\n",
    "token_count = torch.zeros((VOCAB_SIZE,))\n",
    "\n",
    "for idx, doc in enumerate(train_posts.text):\n",
    "    try:\n",
    "        embedding, ids = get_embedding(doc)\n",
    "        embeddings.append(embedding)\n",
    "        input_ids.append(ids)\n",
    "        token_embeddings.scatter_add_(0, ids[0].unsqueeze(1).expand(embedding.shape), embedding)\n",
    "        token_count.scatter_add_(0, ids[0], torch.ones_like(ids[0]).float())\n",
    "    except Exception as e:\n",
    "        print(idx)\n",
    "        print(get_words(doc))\n",
    "        print(e)\n",
    "\n",
    "token_embeddings = torch.nan_to_num(torch.div(token_embeddings, token_count.unsqueeze(1).expand(token_embeddings.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26571, 768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_similarities = cosine_similarity(token_embeddings, token_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85      , 0.7274614 , 0.6562746 , ..., 0.81573904, 0.8017423 ,\n",
       "        0.82521707],\n",
       "       [0.7274614 , 0.85      , 0.5251325 , ..., 0.70555705, 0.66722405,\n",
       "        0.7024103 ],\n",
       "       [0.6562746 , 0.5251325 , 0.85      , ..., 0.6272595 , 0.62632334,\n",
       "        0.6571109 ],\n",
       "       ...,\n",
       "       [0.81573904, 0.70555705, 0.6272595 , ..., 0.85      , 0.85      ,\n",
       "        0.85      ],\n",
       "       [0.8017423 , 0.66722405, 0.62632334, ..., 0.85      , 0.85      ,\n",
       "        0.85      ],\n",
       "       [0.82521707, 0.7024103 , 0.6571109 , ..., 0.85      , 0.85      ,\n",
       "        0.85      ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_similarities.clip(max=0.85, out=token_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26571, 26571)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NYDataset(Dataset):\n",
    "    def __init__(self, embeddings, input_ids):\n",
    "        self.embeddings = embeddings\n",
    "        self.input_ids = list(map(lambda x: x.squeeze(), input_ids))\n",
    "        \n",
    "        self.embeddings = nn.utils.rnn.pad_sequence(self.embeddings, batch_first=True, padding_value=0)\n",
    "        self.input_ids = nn.utils.rnn.pad_sequence(self.input_ids, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return embeddings[idx], input_ids[idx].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 26571])\n"
     ]
    }
   ],
   "source": [
    "gen = torch.randn(128, 64, VOCAB_SIZE)\n",
    "print(gen[:, 0, :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1037657.1250)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = F.log_softmax(torch.randn(128, 64, VOCAB_SIZE), -1)\n",
    "orig = torch.randint(0, VOCAB_SIZE, (64, 128))\n",
    "\n",
    "gen_doc = gen[:, 0, :]\n",
    "orig_doc = orig[0, :]\n",
    "\n",
    "def doc_embed_loss(gen_doc, orig_doc, k=5):\n",
    "    topk_values, topk_indices = torch.topk(gen_doc, k, dim=-1)\n",
    "    rand_indices = torch.randint(0, VOCAB_SIZE, (gen_doc.shape[0], k))\n",
    "    doc_loss = 0\n",
    "    for i in range(gen_doc.shape[0]):\n",
    "        rand_values = torch.index_select(gen_doc, -1, rand_indices[i])\n",
    "        doc_loss += (topk_values * token_similarities[orig_doc[i].item(), topk_indices[i]]).sum()\n",
    "        doc_loss += (rand_values * token_similarities[orig_doc[i].item(), rand_indices[i]]).sum()\n",
    "    \n",
    "    return -doc_loss\n",
    "\n",
    "doc_embed_loss(gen_doc, orig_doc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22579"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_doc[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.6972)\n",
      "tensor(65637484.)\n",
      "tensor(32817366.)\n"
     ]
    }
   ],
   "source": [
    "gen = torch.randn(64, 128, VOCAB_SIZE)\n",
    "orig = torch.randint(0, VOCAB_SIZE, (64, 1, 128))\n",
    "\n",
    "# LOSS FUNCTIONS\n",
    "\n",
    "def recon_loss(inp, targ):\n",
    "    \"Loss of first stage\"\n",
    "    return F.cross_entropy(inp.view(-1, VOCAB_SIZE), targ.reshape(-1)) # forgot set ignore_index as PAD_TOKEN_ID\n",
    "\n",
    "def doc_embed_loss(gen_doc, orig_doc, k=5):\n",
    "    topk_values, topk_indices = torch.topk(gen_doc, k, dim=-1)\n",
    "    rand_indices = torch.randint(0, VOCAB_SIZE, (gen_doc.shape[0], k))\n",
    "    doc_loss = 0\n",
    "    \n",
    "    for i in range(gen_doc.shape[0]):\n",
    "        rand_values = torch.index_select(gen_doc, -1, rand_indices[i])\n",
    "        doc_loss += (topk_values * token_similarities[orig_doc[i].item(), topk_indices[i]]).sum()\n",
    "        doc_loss += (rand_values * token_similarities[orig_doc[i].item(), rand_indices[i]]).sum()\n",
    "\n",
    "    return doc_loss\n",
    "\n",
    "def embed_loss(inp, targ, k=5):\n",
    "    loss = 0\n",
    "    inp = F.log_softmax(inp, dim=-1)\n",
    "    for i in range(inp.shape[0]):\n",
    "        loss += doc_embed_loss(inp[i], targ[i][0], k=k)\n",
    "    return -loss\n",
    "\n",
    "def total_loss(inp, targ, alpha=1, beta=0.5, k=5):\n",
    "    \"Loss of second stage\"\n",
    "    return alpha * recon_loss(inp, targ) + beta * embed_loss(inp, targ, k)\n",
    "\n",
    "print(recon_loss(gen, orig))\n",
    "print(embed_loss(gen, orig))\n",
    "print(total_loss(gen, orig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch-lightning.readthedocs.io/en/latest/notebooks/lightning_examples/datamodules.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(samples):\n",
    "    x = [sample[0] for sample in samples]\n",
    "    y = [sample[1].squeeze() for sample in samples]\n",
    "    \n",
    "    x = nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=0.0)\n",
    "    y = nn.utils.rnn.pad_sequence(y, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "    \n",
    "    if x.shape[1] < y.shape[1]:\n",
    "        y = y[:, :x.shape[1]]\n",
    "    \n",
    "#     print(x.shape, y.shape)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "class LitERAE(pl.LightningModule):\n",
    "    def __init__(self, data, hidden_size=512, num_layers=2, learning_rate=1e-3):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # We hardcode dataset specific stuff here.\n",
    "        self.data = data\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Build model\n",
    "        self.gru_1 = nn.GRU(768, hidden_size, num_layers, bidirectional=True, batch_first=True)\n",
    "        self.linear_1 = nn.Linear(hidden_size * 2, 768)\n",
    "        self.gru_2 = nn.GRU(768, hidden_size, num_layers, bidirectional=True, batch_first=True)\n",
    "        self.linear_2 = nn.Linear(hidden_size * 2, VOCAB_SIZE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, hidden = self.gru_1(x)\n",
    "        x = self.linear_1(x)\n",
    "        x, _ = self.gru_2(x, hidden)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_func(logits, y)\n",
    "        \n",
    "        self.log(f'train_loss', loss)\n",
    "        self.log(f'avg_train_loss', loss, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_func(logits, y)\n",
    "        \n",
    "        self.log(f'val_loss', loss)\n",
    "        self.log(f'avg_val_loss', loss, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        lr_scheduler = {\"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, verbose=True), \"monitor\": \"avg_val_loss\"}\n",
    "        return {'optimizer': optimizer, 'lr_shceduler': lr_scheduler}\n",
    "\n",
    "    def on_train_batch_end(self, outputs, batch, batch_idx, dataloader_idx):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "#         logger.info(f'Batch train loss {metrics}')\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        print(f'Train loss: {metrics[\"avg_train_loss\"]}')\n",
    "\n",
    "    def on_validation_batch_end(self, outputs, batch, batch_idx, dataloader_idx):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "#         logger.info(f'Batch validation loss {metrics}')\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        print(f'Val loss: {metrics[\"avg_val_loss\"]}')\n",
    "\n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "\n",
    "#     def prepare_data(self):\n",
    "#         self.data = nn.utils.rnn.pad_sequence(self.data)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            train_size = int(0.9 * len(self.data))\n",
    "            val_size = len(self.data) - train_size\n",
    "            self.data_train, self.data_val = random_split(self.data, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "            self.loss_func = recon_loss\n",
    "        \n",
    "        if stage == 'fit_2':\n",
    "            train_size = int(0.9 * self.data.shape[1])\n",
    "            val_size = self.data.shape[1] - train_size\n",
    "            self.data_train, self.data_val = random_split(self.data, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "            self.loss_func = total_loss\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "#         if stage == \"test\" or stage is None:\n",
    "#             self.data_test\n",
    "#             self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.data_train, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.data_val, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "#     def test_dataloader(self):\n",
    "#         return DataLoader(self.mnist_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chechpoint_path = \"checkpoints_eng_distilbert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:326: LightningDeprecationWarning: Base `LightningModule.on_train_batch_end` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py:380: RuntimeWarning: Found unsupported keys in the optimizer configuration: {'lr_shceduler'}\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name     | Type   | Params\n",
      "------------------------------------\n",
      "0 | gru_1    | GRU    | 8.7 M \n",
      "1 | linear_1 | Linear | 787 K \n",
      "2 | gru_2    | GRU    | 8.7 M \n",
      "3 | linear_2 | Linear | 27.2 M\n",
      "------------------------------------\n",
      "45.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "45.3 M    Total params\n",
      "181.394   Total estimated model params size (MB)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b80f1de9384f699a8ef4f6aa4c82bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b3d26bfaa04a86a3d13741663ef4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 1.9502904415130615\n",
      "Train loss: 2.6417641639709473\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94a0b9e96c34870a1eade3d34adb674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 1.177188754081726\n",
      "Train loss: 1.4339770078659058\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04ba4effb424cef86e35a21ed28f686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.8991775512695312\n",
      "Train loss: 0.9246569275856018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c7dbcc212f4fb0a667566197cbb5d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6994844079017639\n",
      "Train loss: 0.6217681765556335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db4c393792940b8976c6927ecfe4db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5918701887130737\n",
      "Train loss: 0.4160321056842804\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ca905de22f476eb9aa868a0d14e4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5327003598213196\n",
      "Train loss: 0.2820001542568207\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5166d3afdb34252818875511d018c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5668911337852478\n",
      "Train loss: 0.21441902220249176\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0691071148c1408aad7166ea1a8e3313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.461037814617157\n",
      "Train loss: 0.15748204290866852\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30de4f793bd54997adfc16ad7b2d1562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.43227794766426086\n",
      "Train loss: 0.10459686815738678\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98f80b7da3240d3ae5c48cb1a5789e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.4098885953426361\n",
      "Train loss: 0.07377519458532333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c828f5b7554522aac92ade450f4b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.3920246660709381\n",
      "Train loss: 0.051990289241075516\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58873c78875c47f0aebe67708fc09bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.3803144693374634\n",
      "Train loss: 0.035847779363393784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e3f3e9bbf24161bcc6411947fb0441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.37181714177131653\n",
      "Train loss: 0.025869004428386688\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff37b2ddb3e4549998af21f146fe1d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.36293455958366394\n",
      "Train loss: 0.019378552213311195\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ee979e45b64f0092a33d0e88dc84eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.36055082082748413\n",
      "Train loss: 0.015040900558233261\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0473f45cc349d9941e2bee2a7cac28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.35821521282196045\n",
      "Train loss: 0.012281929142773151\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8897eb4c1db4e41a3175cfd64565729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.3572542071342468\n",
      "Train loss: 0.010950349271297455\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a791149d9cd4203bdff461a8c960de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.3641934096813202\n",
      "Train loss: 0.01320961955934763\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34994716df9d464ebe083348240e46b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.36115366220474243\n",
      "Train loss: 0.016599932685494423\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9884cc1380eb4b718356ef50b8ee9cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.35689786076545715\n",
      "Train loss: 0.014915265142917633\n"
     ]
    }
   ],
   "source": [
    "data = NYDataset(embeddings, input_ids)\n",
    "model = LitERAE(data)\n",
    "model.train()\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=chechpoint_path, save_top_k=2, monitor=\"val_loss\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=20,\n",
    "    progress_bar_refresh_rate=20,\n",
    "    gpus=1,\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/notebooks/checkpoints_eng_distilbert/epoch=19-step=4860.ckpt'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitERAE.load_from_checkpoint(checkpoint_path=checkpoint_callback.best_model_path, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type   | Params\n",
      "------------------------------------\n",
      "0 | gru_1    | GRU    | 8.7 M \n",
      "1 | linear_1 | Linear | 787 K \n",
      "2 | gru_2    | GRU    | 8.7 M \n",
      "3 | linear_2 | Linear | 27.2 M\n",
      "------------------------------------\n",
      "45.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "45.3 M    Total params\n",
      "181.394   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdde56b6046046faad17690671646595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed1355e9d154564927c6750d1356a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.32509157061576843\n",
      "Train loss: 0.015901822596788406\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ccacb0ecc4494585402fa6ab1b60a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.34149202704429626\n",
      "Train loss: 0.01277176570147276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca11a6f998c49acb077db10591df4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.33103469014167786\n",
      "Train loss: 0.01462724432349205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62179b4534f24e3bb19371dea01eb620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.331027090549469\n",
      "Train loss: 0.013831734657287598\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c92ceeaa3014cf3ac55c50415ed2bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.32355788350105286\n",
      "Train loss: 0.009537290781736374\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0607972174e64702896b7572795c95dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.32059308886528015\n",
      "Train loss: 0.007281139027327299\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f1e8c3d71a478d878bc1810d9cb703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.3264179229736328\n",
      "Train loss: 0.006722027901560068\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af9711f0a4f4035a93d3fc7eced6039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.3272750675678253\n",
      "Train loss: 0.007264561019837856\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbcfe01556224df29dc03291950e7a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.3247795104980469\n",
      "Train loss: 0.007408006116747856\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389b60fc9274457eaaa201932ef9ab9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.3317500650882721\n",
      "Train loss: 0.009097867645323277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f9b474cab24cffa11ae61698180c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.3249076306819916\n",
      "Train loss: 0.008706294000148773\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798c153962a1403189b5ead06df87590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.32049262523651123\n",
      "Train loss: 0.007119002286344767\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a33a60fed67476393d414b19e7339d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.32144972681999207\n",
      "Train loss: 0.006045342888683081\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c342de5100984bf889d09d4c9b53bed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.3178316652774811\n",
      "Train loss: 0.005349114071577787\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa6a1d96cae4e60abf4af965c888a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.3252803683280945\n",
      "Train loss: 0.005313844420015812\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80f6fc33f9c417dad5ff6723b07cb7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.3280400037765503\n",
      "Train loss: 0.0063263229094445705\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a941b5a6d54a44afbfa5d1514c6af85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.32875826954841614\n",
      "Train loss: 0.00682975584641099\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2c4f082ad84aa7b08ca9f582359504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.32497328519821167\n",
      "Train loss: 0.00619220407679677\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de0302e870046bda963bc4d56329eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.3270348906517029\n",
      "Train loss: 0.00642442237585783\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0562fd920d4d059a3076f80526ef96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.3231877088546753\n",
      "Train loss: 0.005789212882518768\n"
     ]
    }
   ],
   "source": [
    "model.stage = 'fit_2'\n",
    "model.train()\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=chechpoint_path, save_top_k=2, monitor=\"val_loss\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=20,\n",
    "    progress_bar_refresh_rate=20,\n",
    "    gpus=1,\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitERAE.load_from_checkpoint(checkpoint_path=checkpoint_callback.best_model_path, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'epoch=0-step=243.ckpt'    'epoch=13-step=3402.ckpt'  'epoch=2-step=729.ckpt'\n",
      "'epoch=1-step=486.ckpt'    'epoch=16-step=4131.ckpt'\n",
      "'epoch=11-step=2916.ckpt'  'epoch=19-step=4860.ckpt'\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints_eng_distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = NYDataset(embeddings, input_ids)\n",
    "model = LitERAE.load_from_checkpoint(checkpoint_path='checkpoints_eng_distilbert/epoch=13-step=3402.ckpt', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_mechanism(pho, epsilon, delta):\n",
    "    pho = np.array(pho)\n",
    "    temp = np.exp(epsilon / (2 * delta) * pho)\n",
    "    return temp / np.sum(temp)\n",
    "\n",
    "\n",
    "def predict(model, sent, seed=None):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    inp = get_embedding(sent)[0].unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        logits = model(inp)[0]\n",
    "    \n",
    "    predicted_probs = torch.softmax(logits, dim=-1)\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    def build_two_sets(probs, k=5):\n",
    "        # return lexical set and semantic set\n",
    "        probs = np.array(probs)\n",
    "        l_set = rng.choice(probs.shape[0], k, p=probs, replace=True)\n",
    "        l_set_probs = probs[l_set]\n",
    "\n",
    "        marks = np.ones(probs.shape[0], dtype=bool)\n",
    "        marks[l_set] = False\n",
    "\n",
    "        whole_idxs = np.arange(probs.shape[0])\n",
    "        s_set = whole_idxs[marks]\n",
    "        s_set_probs = probs[marks]\n",
    "\n",
    "        return l_set, s_set, l_set_probs, s_set_probs\n",
    "\n",
    "    def choose_set(l_set, s_set, l_set_probs, s_set_probs, eps=80):\n",
    "        probs = [0, 0]\n",
    "        probs[0] = np.sum(l_set_probs) / (np.sum(l_set_probs) + np.sum(s_set_probs))\n",
    "        probs[1] = 1 - probs[0]\n",
    "        probs = exponential_mechanism(probs, eps, 1)\n",
    "        po = [(l_set, l_set_probs), (s_set, s_set_probs)]\n",
    "        indxs = [0, 1]\n",
    "        indx = int(rng.choice(indxs, 1, p=probs))\n",
    "        return po[indx]\n",
    "\n",
    "    for probs in predicted_probs:\n",
    "        # build set\n",
    "        l_set, s_set, l_set_probs, s_set_probs = build_two_sets(probs, k=5)\n",
    "\n",
    "        # choose set\n",
    "        c_set, c_set_probs = choose_set(l_set, s_set, l_set_probs, s_set_probs)\n",
    "\n",
    "        # choose token\n",
    "        token_eps = 0.1\n",
    "        c_set_probs = exponential_mechanism(c_set_probs, token_eps, 1)\n",
    "        token_idx = int(rng.choice(c_set, 1, p=c_set_probs))\n",
    "\n",
    "        if token_idx == EOS_TOKEN_ID:\n",
    "            break\n",
    "        res.append(token_idx)\n",
    "#     o_pred = ' '.join([self.params['idx2word'][idx] for idx in res])\n",
    "#     o_pred = tokenizer.decode(res, skip_special_tokens=True)\n",
    "    o_pred = ' '.join(idx2token[idx] for idx in res[1:])\n",
    "    return o_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Original>:\n",
      "miss twin peaksis next saturday night at @joespub ! will you be there? @schafferthedarklord @revlegsmalone @bunnybuxom @booboodarlin @seedyedie @holly_honeypot @francineld @minxarcana @loganlaveau @ameliabareparts @varlavelour photos & design by @francinefoto     : joespub.com\n",
      "--------------------------------->\n",
      "<Transformed>:\n",
      "miss mythic cans next saturday night at @ joespub ! will you be there ? @ cassandrarosebeetle @ vonkaromanov @ larougenewark @ sao @ descomedy @ murray _ wolf @ francineld @ minxarcana @ evokes @ pastor @ etna pictures & design by @ bramble : frankenthaler . com\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "text = test_posts.text[test_posts.index[1]]\n",
    "print('<Original>:')\n",
    "print(text)\n",
    "print('--------------------------------->')\n",
    "print('<Transformed>:')\n",
    "print(predict(model, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Original>:\n",
      "ladies and gentlemen! we are almost fully booked for 2020 new year party but still have some availabilities, but literally couple of tables....literally  718-513-6004\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "ladies and gentlemen ! we are almost fully booked for 2020 new year party but still have some availabilities , but literally couple of tables . . . . literally 718 - 513 - 6004\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "a new perspective on an old favorite... that's what the new year can gift to you! good food and great  at @sistersbklyn (900 fulton). : @stefanieeesays\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "a new consistent on an old favorite . . . that ' s what the new year can gift to you ! good food and great at @ brumch ( % fulton ) . : @ deliciasdeminasrestaurant\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "today was a blessing i got to see my family and my  sister\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "today was a that i got to see my family and my pet\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "taboga  saturday 05/25 /19 apptetizer + main course + dessert [ + 2 hrs unlimited mimosa / sangria / punch ] only for $35.00 music by: ecraze stay_liifted pesao anthony rey free free hookah from 1pm-5pm . .. rsvp: 917-330-9248 tex .. taboga by oleaga restaurant . billiard . barbershop 421 w 202nd st, new york, ny 10034 .. ..\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "taboga saturday 05 / 25 / 19 apptetizer + main course + dessert [ + 2 hrs unlimited mimosa / sangria / punch ] only for $ 35 . 00 music by : ecraze stay _ liifted pesao anthony rey free free hookah from 1pm - 5pm . . . rsvp : 917 - 330 - 9248 tex . . taboga by oleaga restaurant . billiard . barbershop 421 w 202nd st , new york , ny 10034 . . . .\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "it's officially summer  'call out mondays' @fortythirdstreetcafe with @djyoungfresh is the place to be!! open bar menu selection. (8pm-9pm)  free admission & $2 crabs. now that's a party! 1425 springfield ave. irvington, nj @bass_entertainment  & @scott2289 turn up the heat on a monday\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "it ' s officially summer ' call out mondays ' @ fortythirdstreetcafe with @ djyoungfresh is the place to be ! ! open bar menu selection . ( 8pm - 9pm ) free admission & $ 2 crabs . now that ' s a party ! 1425 springfield ave . irvington , nj @ bass _ entertainment & @ scott2289 turn up the heat on a monday\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "this saturday party with us at the dopest comedy show on the northern tip of manhattan. when? 23 feb 2019. seats @ 9:30p, first come! where? @theparkviewcafe the park view, 219 dyckman st, nyc. 2 items min. no cover! seats go fast; rsvp now w/ link in profile , or here: <url>   special guest host: @leevalentin nataly aukar @natyourcolor kevin berrey @berrey tayler yarish @tayleryarish drexton clemons @thisguydrex erik helewa @erik_helewa brittanie sheree @brittisfunny   !! !!!\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "this saturday party with us at the dopest comedy show on the northern tip of manhattan . when ? 23 feb 2019 . seats @ 9 : 30p , first come ! where ? @ theparkviewcafe the park view , 219 dyckman st , nyc . 2 items min . no cover ! seats go fast ; rsvp now w / link in profile , or here : < url > special guest host : @ tayleryarish drexton presented @ tayleryarish kevin berrey @ berrey tayleryarish drexton @ featured\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "are you around nyc next weekend?  the vibrant and inspiring time of bushwick open studios is happening in synch with the fall equinox  daya will be participating and we have so many wonderful offerings coming your way! ! ! . . . fri 9/20 7p: 108 sun salutations to celebrate the fall equinox with ania lesniak @daya_mama 7-10p: art viewing . . sat 9/21 8a: cacao ceremony with erika laila @truthseekerdivinationnyc 2-5:30p: psychic fair ( tarot reading, natal chart reading, astrology reading, cupping & much more ) 6:30p: interactive performance with ania & mariya dimov @mariyadimov 7:45p: pierce boaz comedy 8-9p: interactive experience with michael doonan @michaeldoonan . . sun 9/22 block party in collaboration with house of yes 12-1p: kirtan with ania & carmina 1-2p: performative yoga with nikki ortiz @nikki_ortiz 2-3p: meditation for manifestation with diana & patrick @emily_cremona 3-4p: daya dance with ania 4-5p: sound bath with andrea baquero @soundandvibe . . art viewing 2-5p tarantella dance 7-10pm with alessendrana belloni @belloni.alessandra   . . photo by : @houseofyesnyc\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "are you around nyc next weekend ? the cada and exploring time of thenyffopens open creatures is happening in compassion with the fall pride daya will be planning and we have so many huge creatures coming your way ! ! ! . . . fri 9 / 20 29 : 108 sun vinyasa to celebrate the fall lovers with ania lesniak @ daya _ mama 7 - 10pm : art viewing . . sat 9 / 21 1a : cacao text with daya figurative @ tanta 2 - 5 : 31 : encanta\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "this sweetheart performs at this casita every friday at 11. join @leeburgos, her band and our familia, we guarantee you a fabulous night.\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "this gorgeous happens at this casita every friday at 11 . join @ jerome , her company and our okinawa , we craft you a happy night .\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "chef david and our talented team here at the caldwell bakery will help you design the perfect cake for any occasion, from weddings to birthdays and everything in between\n",
      "------------------------>\n",
      "<Transformed>:\n",
      "chef david and our talented team here at the caldwell bakery will help you design the perfect cake for any occasion , from weddings to birthdays and everything in between\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "<Original>:\n",
      "...even on a rainy day  check out our boutique for the latest & greatest!\n",
      "------------------------>\n",
      "<Transformed>:\n",
      ". . . even on a rainy day check out our jacket for the fall & community !\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "test_texts = test_posts.text\n",
    "for i in range(100, 110):\n",
    "    text = test_texts[test_posts.index[i]]\n",
    "    print('<Original>:')\n",
    "    print(text)\n",
    "    print('------------------------>')\n",
    "    print('<Transformed>:')\n",
    "    print(predict(model, text))\n",
    "    print('\\n------------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtags anonymization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SynTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nyc_posts_authors_df.loc[nyc_posts_authors_df['hashtags'].str.len() > 50, 'hashtags'][:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#bike #bikes #bikelife #shopride #shoplife #myfavoritebikeshop #bikeclub #bikenyc #bikeny #croton #crotonaqueduct #gravelgrinder #gravel #gravelride #offroad'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18078"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "s = set(chain.from_iterable(docs.str.split()))\n",
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_model = CountVectorizer(ngram_range=(1,1))\n",
    "X = count_model.fit_transform(docs)\n",
    "Xc = (X.T * X)\n",
    "Xc.setdiag(0)\n",
    "Xc = Xc.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5119884,\n",
       " matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 5, 5],\n",
       "         [0, 0, 0, ..., 5, 0, 5],\n",
       "         [0, 0, 0, ..., 5, 5, 0]]))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc.sum(), Xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13364, 13364)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.4684e-05, 7.4684e-05, 7.4684e-05,  ..., 7.4684e-05, 7.4684e-05,\n",
       "         7.4684e-05],\n",
       "        [7.4582e-05, 7.4582e-05, 7.4582e-05,  ..., 7.4582e-05, 7.4582e-05,\n",
       "         7.4582e-05],\n",
       "        [7.3181e-05, 7.3181e-05, 7.3181e-05,  ..., 7.3181e-05, 7.3181e-05,\n",
       "         7.3181e-05],\n",
       "        ...,\n",
       "        [3.0429e-07, 3.0429e-07, 3.0429e-07,  ..., 3.0429e-07, 4.5161e-05,\n",
       "         4.5161e-05],\n",
       "        [3.0429e-07, 3.0429e-07, 3.0429e-07,  ..., 4.5161e-05, 3.0429e-07,\n",
       "         4.5161e-05],\n",
       "        [3.0429e-07, 3.0429e-07, 3.0429e-07,  ..., 4.5161e-05, 4.5161e-05,\n",
       "         3.0429e-07]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc = torch.softmax(torch.from_numpy(Xc).float(), dim=-1)\n",
    "Xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0000), tensor(7.4684e-05))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc[0].sum(), Xc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "tfidf.fit(docs)\n",
    "doc_vecs = tfidf.transform(docs)\n",
    "doc_vecs = normalize(doc_vecs, norm='l1')\n",
    "words = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18063"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1405975, 5131770)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft = fasttext.load_facebook_model(datapath('/mnt/ess_storage/DN_1/storage/home/vpanov/cc.en.300.bin.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc[count_model.vocabulary_['newyork']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13364, 13364)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vecs = [Xc[count_model.vocabulary_[word]].tolist()[0] for word in words]\n",
    "word_similarities = cosine_similarity(word_vecs, word_vecs)\n",
    "word_similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kgram_overlap(word1, word2, k):\n",
    "    a = set([word1[i:i+k] for i in range(0, len(word1) - k + 1)])\n",
    "    b = set([word2[i:i+k] for i in range(0, len(word2) - k + 1)])\n",
    "    inter = len(a.intersection(b))\n",
    "    return inter / (len(a) + len(b) - inter)\n",
    "\n",
    "def score(word1, word2):\n",
    "    idx1, idx2 = tfidf.vocabulary_[word1], tfidf.vocabulary_[word2]\n",
    "    return word_similarities[idx1, idx2] - 0.3 * kgram_overlap(word1, word2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likes4like ['turkiye']\n"
     ]
    }
   ],
   "source": [
    "def exponential_gen(x, R, u, sensitivity=1, epsilon=25.4):\n",
    "    # Calculate the score for each element of R\n",
    "    scores = [u(x, r) for r in R]\n",
    "    \n",
    "    # Calculate the probability for each element, based on its score\n",
    "    probabilities = [np.exp(epsilon * score / (2 * sensitivity)) for score in scores]\n",
    "    \n",
    "    # Normalize the probabilties so they sum to 1\n",
    "    probabilities = probabilities / np.linalg.norm(probabilities, ord=1)\n",
    "\n",
    "    # Choose an element from R based on the probabilities\n",
    "    return np.random.choice(R, 1, p=probabilities)\n",
    "\n",
    "num = 7000\n",
    "print(words[num], exponential_gen(words[num], words, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13364, 13364)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exponential(x, R, u, sensitivity=1, epsilon=25.4):\n",
    "    # Calculate the score for each element of R\n",
    "    scores = [u(x, r) for r in R]\n",
    "    \n",
    "    # Calculate the probability for each element, based on its score\n",
    "    probabilities = [np.exp(epsilon * score / (2 * sensitivity)) for score in scores]\n",
    "    \n",
    "    # Normalize the probabilties so they sum to 1\n",
    "    probabilities = probabilities / np.linalg.norm(probabilities, ord=1)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "word_replace_probs = []\n",
    "\n",
    "for idx, word in enumerate(words):\n",
    "    if idx % 1000 == 0:\n",
    "        print(idx)\n",
    "    word_replace_probs.append(exponential(word, words, score))\n",
    "\n",
    "word_replace_probs = np.array(word_replace_probs)\n",
    "word_replace_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--ORIGINAL--\n",
      "#EATDRINKPARTY #miercolesplayero #bronx #BottleSpecials #bestiakitchenbx #LaBestiaDelBronx #HappyHour #PartyPeople #FoodPorn #salsa #playero #retro #4thofjulyparty #preindependenceday #preindependencedayparty\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "gaynightlife nbafinals2019 bachata miercolesplayero eatdrinkparty nbafinals2019 santiago 4thofjulyparty caucau 4thofjulyparty lentejitas nycdrinks ericktorres latino 4thofjulyparty\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "#914 #newrochelle #newrochelleny #ionacollege #westchester #westchesterny #westchestereats #westchesternyeats #westchestercountyny #westchestercounty #westchesterfood #westchesterfoodie #tuckahoeny #tuckahoe #eastchester #eastchesterny #larchmont #larchmontny #larchmontvillage #pelhamny #yonkers #yonkersny #bronxville #bronxvilleny #burgersandbeer #bestwings\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "westchestereats burgersandfries jameson yonkersny jameson latenightfood larchmontny larchmont yonkers yonkers panini phillycheesesteak tuckahoe titosvodka pelhammanor larchmontny bestwingsever jamesonwhiskey bestwings yonkers newrochelle burgersandfries salad westchesternyeats jamesonwhiskey yonkers\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "#effigies #forevergrounded #record #punk #1984 #theeffigies #records #vinyl #newyorkcity #recordsforsale #carrollgardens #redhook #chicago #punkrock #vinylporn #recordshop #hardcorepunk #vinyligclub #rock #almostreadyrecords #vinylforsale #webuyvinyl #buyselltrade #nyc #brooklyn #vinylrecord #enigma #lp\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "carlitosway stooges thebeatles almostready citoferminorchestra 33rpm 1970 effigies 1996 reissue thedictatorsnyc records mysaxophoneforchristmas modusoperandi doom thecity sealed almostchristmas miccitysons redhook redvinyl enigma effigies alifewithoutobstacles jamesbrown recordporn countryteasers ska\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "#10yearchallenge #tgif #1 #happyhour #78loungenj #drinks #food #birthday #turnup #party #goodlife #nightlife #dj #like4like #goodtime #friends #family #followme #instaselfie #swag #follow #newjersey #friday #flashbackfriday\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "followme 78lifestyle amazonbooks tournament 78loungenj theheavyhitterdjs sipandpaint friends niceandsmooth family friends lawenforcement goodtime ncaa favorite followme goodlife nightlife 78lounge stpattysday theheavyhitterdjs budin dj djcoolv\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "#birthdayparties #halloween #halloweenparty2019 #thecomplexnyc #birthday #bubbleball #bubbleballsoccer #halloweenpartylic #halloweenpartyastoria #bubbleballny #adults #bounce #astoria #lic #astoriaqueens #queens #birthdayparties #newyork #astoriaqueensny #astoriaqueens #queens #fun #kids #funkids #family #astoriasportscomplex #costumeparty #prizes #halloweenpartynyc #kidshalloweenparty #kidshalloweenparty2019 #halloweenpartyny #nychalloweenparty\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "birthdayparties funkids babysharkchallenge nerfgun halloweenpartynyc swag knockerballnyc halloweenpartynyc kids lic kidshalloweenparty2018 hocuspocustrivia animalshow magicshownyc costumeparty costumeparty funkids swimlessons funkids bubbleballsoccer bubbleballsoccer bubbleballsoccer halloweenpartyny astoriaqueensny bubbleballsoccer halloweenpartyny november bubblesoccer bubbleballsoccer indoors astoriaqueensny bubbleballnyc kidshalloweenparty2018\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for idx, doc in enumerate(docs[:5]):\n",
    "    print('--ORIGINAL--')\n",
    "    print(doc)\n",
    "    print('--GENERATED SEQUENCE (WITHOUT WORD ORDER)--')\n",
    "    words_count = len(doc.split())\n",
    "    words_ = np.random.choice(words, words_count, p=doc_vecs[idx].todense().tolist()[0])\n",
    "    for i in range(words_count):\n",
    "        word_idx = tfidf.vocabulary_[words_[i]]\n",
    "        words_[i] = np.random.choice(words, 1, p=word_replace_probs[word_idx])[0]\n",
    "    print(' '.join(words_))\n",
    "    print('-'*150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtags magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nyc_posts_authors_df.loc[nyc_posts_authors_df['hashtags'].str.len() > 50, 'hashtags'][:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3536335, 10212810)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags = docs.str.split().tolist()\n",
    "\n",
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=5,\n",
    "                     vector_size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=10)\n",
    "w2v_model.build_vocab(hashtags, progress_per=1000)\n",
    "w2v_model.train(hashtags, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#tagforlikes', 0.747814416885376),\n",
       " ('#wedding', 0.7455034255981445),\n",
       " ('#like', 0.7374163866043091),\n",
       " ('#barmitzvah', 0.7349600791931152),\n",
       " ('#aniversary', 0.7308018803596497),\n",
       " ('#selfie', 0.7256142497062683),\n",
       " ('#foody', 0.7172373533248901),\n",
       " ('#picoftheday', 0.7157788276672363),\n",
       " ('#restaurants', 0.7054566740989685),\n",
       " ('#happy', 0.7051026225090027)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('#newyork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#birthday', 0.9645171165466309),\n",
       " ('#aniversary', 0.9628538489341736),\n",
       " ('#restaurants', 0.9571098685264587),\n",
       " ('#barmitzvah', 0.954374372959137),\n",
       " ('#tagforlikes', 0.932794451713562),\n",
       " ('#sushi', 0.9251395463943481),\n",
       " ('#foody', 0.921452522277832),\n",
       " ('#like', 0.9046717882156372),\n",
       " ('#selfie', 0.885693371295929),\n",
       " ('#appetizer', 0.8824301958084106)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('#wedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/\n",
    "\n",
    "def levenshteinDistanceDP(token1, token2):\n",
    "    distances = numpy.zeros((len(token1) + 1, len(token2) + 1))\n",
    "\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "#     printDistances(distances, len(token1), len(token2))\n",
    "    return distances[len(token1)][len(token2)]\n",
    "\n",
    "def kgram_overlap(word1, word2, k):\n",
    "    a = set([word1[i:i+k] for i in range(0, len(word1) - k + 1)])\n",
    "    b = set([word2[i:i+k] for i in range(0, len(word2) - k + 1)])\n",
    "    inter = len(a.intersection(b))\n",
    "    return inter / (len(a) + len(b) - inter + 1)\n",
    "\n",
    "def score(word1, word2):\n",
    "    return w2v_model.wv.similarity(word1, word2) - 0.5 * kgram_overlap(word1, word2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#newyork ['#happy']\n"
     ]
    }
   ],
   "source": [
    "# def get_replace(word, k=5, seed=None):\n",
    "#     repls = [(repl, score(word, repl)) for repl, _ in w2v_model.wv.most_similar(word, topn=k)]\n",
    "#     repls.sort(key=lambda x: x[1], reverse=True)\n",
    "#     rng = np.random.default_rng(seed)\n",
    "#     return rng.choice(repls, p=[score for _, score in repls])[0]\n",
    "\n",
    "# get_replace('#newyork')\n",
    "\n",
    "words = list(w2v_model.wv.key_to_index.keys())\n",
    "\n",
    "def exponential_gen(x, R, u, sensitivity=1, epsilon=25.4, seed=None):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    # Calculate the score for each element of R\n",
    "    scores = [u(x, r) for r in R]\n",
    "    \n",
    "    # Calculate the probability for each element, based on its score\n",
    "    probabilities = [np.exp(epsilon * score / (2 * sensitivity)) for score in scores]\n",
    "    \n",
    "    # Normalize the probabilties so they sum to 1\n",
    "    probabilities = probabilities / np.linalg.norm(probabilities, ord=1)\n",
    "\n",
    "    # Choose an element from R based on the probabilities\n",
    "    return rng.choice(R, 1, p=probabilities)\n",
    "\n",
    "word = '#newyork'\n",
    "print(word, exponential_gen(word, words, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2242, 2242)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exponential(x, R, u, sensitivity=1, epsilon=25.4, seed=None):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # Calculate the score for each element of R\n",
    "    scores = [u(x, r) for r in R]\n",
    "    \n",
    "    # Calculate the probability for each element, based on its score\n",
    "    probabilities = [np.exp(epsilon * score / (2 * sensitivity)) for score in scores]\n",
    "    \n",
    "    # Normalize the probabilties so they sum to 1\n",
    "    probabilities = probabilities / np.linalg.norm(probabilities, ord=1)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "word_replace_probs = []\n",
    "\n",
    "for idx, word in enumerate(words):\n",
    "    if idx % 1000 == 0:\n",
    "        print(idx)\n",
    "    word_replace_probs.append(exponential(word, words, score))\n",
    "\n",
    "word_replace_probs = np.array(word_replace_probs)\n",
    "word_replace_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--ORIGINAL--\n",
      "#bike #bikes #bikelife #shopride #shoplife #myfavoritebikeshop #bikeclub #bikenyc #bikeny #croton #crotonaqueduct #gravelgrinder #gravel #gravelride #offroad\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "#bike #cycling #movesale #shopride #shoplife #myfavoritebikeshop #bikeclub #bikenyc #bikeny #croton #crotonaqueduct #gravelgrinder #gravel #gravelride #offroad\n",
      "----------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "#76ers #raptors #blazers #nuggets #labatt #genesse #molson #nba #nbaplayoffs #nba2019 #basketball #hoops #nbafirstround #beerandhoops #brooklynsportsbar\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "#76ers #warriors #blazers #nuggets #labatt #genesse #molson #nbaleaguepass #nbaplayoffs #nba2019 #basketball #hoops #nbafirstround #nba2019 #brooklynsportsbar\n",
      "----------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "#comicartsbrooklyn #prattinstitute #gianthand #art #fun\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "#comicartsbrooklyn #prattinstitute #gianthand #art #ff\n",
      "----------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "#spendinglabordaylaboring #creativelylaboring #lovemyjob #howmisskatiespendsholidays\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "#spendinglabordaylaboring #creativelylaboring #lovemyjob #howmisskatiespendsholidays\n",
      "----------------------------------------------------------------------------------------------------\n",
      "--ORIGINAL--\n",
      "#rolex #custom #diamonds #nj #store #ship #unmated #value #textme\n",
      "--GENERATED SEQUENCE (WITHOUT WORD ORDER)--\n",
      "#rolex #quality #unmatched #nj #refrigeradora #rolex #unmated #unmatched #diamonds\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "\n",
    "for idx, doc in enumerate(docs[:5]):\n",
    "    print('--ORIGINAL--')\n",
    "    print(doc)\n",
    "    print('--GENERATED SEQUENCE (WITHOUT WORD ORDER)--')\n",
    "    words_ = doc.split()\n",
    "    for i in range(len(words_)):\n",
    "        if rng.random() < 0.5 and words_[i] in w2v_model.wv:\n",
    "            word_idx = w2v_model.wv.key_to_index[words_[i]]\n",
    "            words_[i] = rng.choice(words, 1, p=word_replace_probs[word_idx])[0]\n",
    "    print(' '.join(words_))\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/gkhayes/author_attribution CNN AA model\n",
    "\n",
    "https://github.com/yunitata/continuous-n-gram-AA code for CNN AA experiments reproduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = tokenizer.batch_decode(tokenizer(train_posts.text.tolist(), return_tensors=\"pt\", max_length=128, padding='max_length', truncation=True).input_ids, skip_special_tokens=True)\n",
    "text_test = tokenizer.batch_decode(tokenizer(test_posts.text.tolist(), return_tensors=\"pt\", max_length=128, padding='max_length', truncation=True).input_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_n_grams(excerpt_list, n, vocab_size, seq_size):\n",
    "    \"\"\"Create a list of n-gram sequences\n",
    "    \n",
    "    Args:\n",
    "    excerpt_list: list of strings. List of normalized text excerpts.\n",
    "    n: int. Length of n-grams.\n",
    "    vocab_size: int. Size of n-gram vocab (used in one-hot encoding)\n",
    "    seq_size: int. Size of n-gram sequences\n",
    "    \n",
    "    Returns:\n",
    "    n_gram_array: array. Numpy array of one-hot encoded n-grams.\n",
    "    \"\"\"\n",
    "    n_gram_list = []\n",
    "\n",
    "    for excerpt in excerpt_list:\n",
    "        # Remove spaces\n",
    "        excerpt = excerpt.replace(\" \", \"\")\n",
    "\n",
    "        # Extract n-grams\n",
    "        n_grams = [excerpt[i:i + n] for i in range(len(excerpt) - n + 1)]\n",
    "\n",
    "        # Convert to a single string with spaces between n-grams\n",
    "        new_string = \" \".join(n_grams)\n",
    "\n",
    "        # One hot encode\n",
    "        hot = one_hot(new_string, round(vocab_size*1.3))\n",
    "\n",
    "        # Pad hot if necessary\n",
    "        hot_len = len(hot)\n",
    "        if hot_len >= seq_size:\n",
    "            hot = hot[0:seq_size]\n",
    "        else:\n",
    "            diff = seq_size - hot_len\n",
    "            extra = [0]*diff\n",
    "            hot = hot + extra\n",
    "\n",
    "        n_gram_list.append(hot)\n",
    "    \n",
    "    n_gram_array = np.array(n_gram_list)\n",
    "    \n",
    "    return n_gram_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_size(excerpt_list, n, seq_size):\n",
    "    \"\"\"Calculate size of n-gram vocab\n",
    "    \n",
    "    Args:\n",
    "    excerpt_list: list of strings. List of normalized text excerpts.\n",
    "    n: int. Length of n-grams.\n",
    "    seq_size: int. Size of n-gram sequences\n",
    "    \n",
    "    Returns:\n",
    "    vocab_size: int. Size of n-gram vocab.\n",
    "    \"\"\"\n",
    "    n_gram_list = []\n",
    "\n",
    "    for excerpt in excerpt_list:\n",
    "        # Remove spaces\n",
    "        excerpt = excerpt.replace(\" \", \"\")\n",
    "\n",
    "        # Extract n-grams           \n",
    "        n_grams = [excerpt[i:i + n] for i in range(len(excerpt) - n + 1)]\n",
    "\n",
    "        # Create list of n-grams\n",
    "        gram_len = len(n_grams)\n",
    "        if gram_len >= seq_size:\n",
    "            n_grams = n_grams[0:seq_size]\n",
    "        else:\n",
    "            diff = seq_size - gram_len\n",
    "            extra = [0]*diff\n",
    "            n_grams = n_grams + extra\n",
    "        \n",
    "        n_gram_list.append(n_grams)\n",
    "    \n",
    "    # Flatten n-gram list\n",
    "    n_gram_list = list(np.array(n_gram_list).flat)\n",
    "    \n",
    "    # Calculate vocab size\n",
    "    n_gram_cnt = Counter(n_gram_list)\n",
    "    vocab_size = len(n_gram_cnt)\n",
    "    \n",
    "    return vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size for n = 109 is: 32207\n"
     ]
    }
   ],
   "source": [
    "vocab_size = get_vocab_size(text_train, 3, 128)\n",
    "print('Vocab size for n =', i, 'is:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17271, 128)\n",
      "(1000, 128)\n"
     ]
    }
   ],
   "source": [
    "# Create n-gram lists\n",
    "gram3_train = create_n_grams(text_train, 3, vocab_size, 128)\n",
    "gram3_test = create_n_grams(text_test, 3, vocab_size, 128)\n",
    "\n",
    "print(np.shape(gram3_train))\n",
    "print(np.shape(gram3_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum encoding value for 3-grams is:  41868\n"
     ]
    }
   ],
   "source": [
    "max_3gram = np.max(gram3_train)\n",
    "\n",
    "print('Maximum encoding value for 3-grams is: ', max_3gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture in keras\n",
    "# Code reference: https://github.com/gkhayes/author_attribution\n",
    "def define_model(input_len, output_size, vocab_size, embedding_dim, verbose = True,\n",
    "                drop_out_pct = 0.25, conv_filters = 500, activation_fn = 'relu', pool_size = 2, learning = 0.0001):\n",
    "    \"\"\"Define n-gram CNN\n",
    "    \n",
    "    Args:\n",
    "    input_len: int. Length of input sequences.\n",
    "    output_size: int. Number of output classes.\n",
    "    vocab_size: int. Maximum value of n-gram encoding.\n",
    "    embedding_dim: int. Size of embedding layer.\n",
    "    verbose: bool. Whether or not to print model summary.\n",
    "    drop_out_pct: float. Drop-out rate.\n",
    "    conv_filters: int. Number of filters in the conv layer.\n",
    "    activation_fn: string. Activation function to use in the convolutional layer.\n",
    "    pool_size: int. Pool size for the max pooling layer.\n",
    "    learning: float. Learning rate for the model optimizer.\n",
    "    \n",
    "    Returns:\n",
    "    model: keras model object. \n",
    "    \"\"\"\n",
    "    # Channel 1\n",
    "    inputs1 = Input(shape = (input_len,))\n",
    "    embedding1 = Embedding(vocab_size, embedding_dim)(inputs1)\n",
    "    drop1 = Dropout(drop_out_pct)(embedding1)\n",
    "    conv1 = Conv1D(filters = conv_filters, kernel_size = 3, activation = activation_fn)(drop1)\n",
    "    pool1 = MaxPooling1D(pool_size = pool_size)(conv1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    \n",
    "    # Channel 2\n",
    "    inputs2 = Input(shape = (input_len,))\n",
    "    embedding2 = Embedding(vocab_size, embedding_dim)(inputs2)\n",
    "    drop2 = Dropout(drop_out_pct)(embedding2)\n",
    "    conv2 = Conv1D(filters = conv_filters, kernel_size = 4, activation = activation_fn)(drop2)\n",
    "    pool2 = MaxPooling1D(pool_size = pool_size)(conv2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "\n",
    "    # Channel 3\n",
    "    inputs3 = Input(shape = (input_len,))\n",
    "    embedding3= Embedding(vocab_size, embedding_dim)(inputs3)\n",
    "    drop3 = Dropout(drop_out_pct)(embedding3)\n",
    "    conv3 = Conv1D(filters = conv_filters, kernel_size = 5, activation = activation_fn)(drop3)\n",
    "    pool3 = MaxPooling1D(pool_size = pool_size)(conv3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    \n",
    "    # Merge channels\n",
    "    merged = Concatenate()([flat1, flat2, flat3])\n",
    "    \n",
    "    # Create output layer\n",
    "    output = Dense(output_size, activation = 'softmax')(merged)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = [inputs1, inputs2, inputs3], outputs = output)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer = Adam(lr = learning), metrics=['accuracy'])\n",
    "    \n",
    "    if verbose:\n",
    "        print(model.summary())\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = preprocessing.LabelEncoder()\n",
    "\n",
    "author_train = lb.fit_transform(train_posts.authorid.values)\n",
    "author_train_hot = pd.get_dummies(author_train).values\n",
    "author_test = lb.transform(test_posts.authorid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 128, 600)     25121400    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 128, 600)     25121400    ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 128, 600)     25121400    ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128, 600)     0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128, 600)     0           ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 128, 600)     0           ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 126, 500)     900500      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 125, 500)     1200500     ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 124, 500)     1500500     ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 63, 500)      0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 62, 500)     0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 62, 500)     0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 31500)        0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 31000)        0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 31000)        0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 93500)        0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 50)           4675050     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 83,640,750\n",
      "Trainable params: 83,640,750\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create the 3-gram model\n",
    "gram3_model = define_model(128, len(train_posts.authorid.unique()), max_3gram + 1, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "432/432 [==============================] - 43s 83ms/step - loss: 3.4190 - accuracy: 0.2015 - val_loss: 2.9380 - val_accuracy: 0.3832\n",
      "Epoch 2/15\n",
      "432/432 [==============================] - 36s 82ms/step - loss: 2.1586 - accuracy: 0.5333 - val_loss: 1.7953 - val_accuracy: 0.6026\n",
      "Epoch 3/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 1.0757 - accuracy: 0.7845 - val_loss: 1.2411 - val_accuracy: 0.6987\n",
      "Epoch 4/15\n",
      "432/432 [==============================] - 36s 84ms/step - loss: 0.4927 - accuracy: 0.9206 - val_loss: 1.0009 - val_accuracy: 0.7392\n",
      "Epoch 5/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.2100 - accuracy: 0.9779 - val_loss: 0.9050 - val_accuracy: 0.7664\n",
      "Epoch 6/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0882 - accuracy: 0.9958 - val_loss: 0.8539 - val_accuracy: 0.7757\n",
      "Epoch 7/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0407 - accuracy: 0.9992 - val_loss: 0.8170 - val_accuracy: 0.7896\n",
      "Epoch 8/15\n",
      "432/432 [==============================] - 35s 82ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.8054 - val_accuracy: 0.7890\n",
      "Epoch 9/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.8022 - val_accuracy: 0.7913\n",
      "Epoch 10/15\n",
      "432/432 [==============================] - 35s 82ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.8033 - val_accuracy: 0.7933\n",
      "Epoch 11/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.8072 - val_accuracy: 0.7933\n",
      "Epoch 12/15\n",
      "432/432 [==============================] - 35s 82ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8124 - val_accuracy: 0.7933\n",
      "Epoch 13/15\n",
      "432/432 [==============================] - 36s 82ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8135 - val_accuracy: 0.7939\n",
      "Epoch 14/15\n",
      "432/432 [==============================] - 36s 82ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8176 - val_accuracy: 0.7948\n",
      "Epoch 15/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8250 - val_accuracy: 0.7957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f068de07130>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram3_model.fit([gram3_train, gram3_train, gram3_train], author_train_hot, epochs=15, batch_size=32, \n",
    "                verbose = 1, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7749999999999999\n",
      "Ave. Precision: 0.785078044860199\n",
      "Ave. Recall: 0.775\n",
      "Ave. F1 Score: 0.7768020735745182\n",
      "Prediction Time: 0.4026064872741699 seconds\n",
      "Confusion Matrix:\n",
      " [[16  0  0 ...  0  0  0]\n",
      " [ 0 15  0 ...  0  0  0]\n",
      " [ 0  0 19 ...  0  0  1]\n",
      " ...\n",
      " [ 0  0  0 ... 15  0  0]\n",
      " [ 0  0  0 ...  0 16  0]\n",
      " [ 0  0  0 ...  0  0 20]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate Model 1 (3-gram CNN)\n",
    "\n",
    "# t0 = time.time()\n",
    "\n",
    "# # Fit model\n",
    "# model1 = define_model(128, len(train_posts.authorid.unique()), max_3gram + 1, 300)\n",
    "# model1.fit([gram3_train, gram3_train, gram3_train], author_train_hot, epochs=10, batch_size=32, \n",
    "#            verbose = 1, validation_split = 0.2)\n",
    "t1 = time.time()\n",
    "\n",
    "# Predict values for test set\n",
    "author_pred1 = gram3_model.predict([gram3_test, gram3_test, gram3_test]).argmax(-1)\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "# Evaluate\n",
    "accuracy = balanced_accuracy_score(author_test, author_pred1)\n",
    "precision, recall, f1, support = score(author_test, author_pred1, average='weighted')\n",
    "confusion = confusion_matrix(author_test, author_pred1)\n",
    "    \n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Ave. Precision:\", precision)\n",
    "print(\"Ave. Recall:\", recall)\n",
    "print(\"Ave. F1 Score:\", f1)\n",
    "# print(\"Training Time:\", (t1 - t0), \"seconds\")\n",
    "print(\"Prediction Time:\", (t2 - t1), \"seconds\")\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "\n",
    "with open('attacker_eng.txt', 'w') as f:\n",
    "    print(\"Accuracy:\", accuracy, file=f)\n",
    "    print(\"Ave. Precision:\", precision, file=f)\n",
    "    print(\"Ave. Recall:\", recall, file=f)\n",
    "    print(\"Ave. F1 Score:\", f1, file=f)\n",
    "    print(\"Confusion Matrix:\\n\", confusion, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_states_batch(encoded, model, layers):\n",
    "    \"\"\"Push input IDs through model. Stack and sum `layers` (last four by default).\n",
    "        Select only those subword token outputs that belong to our word of interest\n",
    "        and average them.\"\"\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        states = model(**encoded).hidden_states\n",
    " \n",
    "    batch_res = []\n",
    "    \n",
    "    for i in range(len(states[0])):\n",
    "        token_ids_words = encoded.word_ids(i)\n",
    "        output = torch.stack([states[layer][i] for layer in layers]).sum(0).squeeze().cpu()\n",
    "\n",
    "        res = []\n",
    "        labels_count = []\n",
    "\n",
    "        for idx, (outp, label) in enumerate(zip(output, token_ids_words)):\n",
    "            if label is None or token_ids_words[idx - 1] is None or token_ids_words[idx - 1] != token_ids_words[idx]:\n",
    "                res.append(outp)\n",
    "                labels_count.append(1)\n",
    "            else: \n",
    "                res[-1] += outp\n",
    "                labels_count[-1] += 1\n",
    "\n",
    "        res = torch.vstack(res)\n",
    "        res = res / torch.tensor(labels_count).float().unsqueeze(1)\n",
    "        \n",
    "        batch_res.append(res)\n",
    "    batch_res = nn.utils.rnn.pad_sequence(batch_res, batch_first=True, padding_value=0.0)\n",
    "    return batch_res\n",
    "\n",
    "def get_word_vectors_batch(sents, tokenizer, model, layers):\n",
    "    \"\"\"Get a word vector by first tokenizing the input sentence, getting all token idxs\n",
    "        that make up the word of interest, and then `get_hidden_states`.\"\"\"\n",
    "    \n",
    "    encoded = tokenizer.batch_encode_plus(sents, return_tensors=\"pt\", max_length=128, padding='max_length', truncation=True)\n",
    "\n",
    "    hidden_states = get_hidden_states_batch(encoded, model, layers)\n",
    "    return hidden_states\n",
    "\n",
    "def get_embedding_batch(docs, model=bert):\n",
    "    \"Get embedding for each word\"\n",
    "    layers = [-4, -3, -2, -1]\n",
    "    return get_word_vectors_batch(docs, tokenizer, model, layers)\n",
    "\n",
    "def predict_batch(model, sents, seed=None, batch_size=32, verbose=False, print_step=20):\n",
    "    model.eval()\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    def build_two_sets(probs, k=5):\n",
    "        # return lexical set and semantic set\n",
    "        probs = np.array(probs)\n",
    "        l_set = rng.choice(probs.shape[0], k, p=probs, replace=True)\n",
    "        l_set_probs = probs[l_set]\n",
    "\n",
    "        marks = np.ones(probs.shape[0], dtype=bool)\n",
    "        marks[l_set] = False\n",
    "\n",
    "        whole_idxs = np.arange(probs.shape[0])\n",
    "        s_set = whole_idxs[marks]\n",
    "        s_set_probs = probs[marks]\n",
    "\n",
    "        return l_set, s_set, l_set_probs, s_set_probs\n",
    "\n",
    "    def choose_set(l_set, s_set, l_set_probs, s_set_probs, eps=80):\n",
    "        probs = [0, 0]\n",
    "        probs[0] = np.sum(l_set_probs) / (np.sum(l_set_probs) + np.sum(s_set_probs))\n",
    "        probs[1] = 1 - probs[0]\n",
    "        probs = exponential_mechanism(probs, eps, 1)\n",
    "        po = [(l_set, l_set_probs), (s_set, s_set_probs)]\n",
    "        indxs = [0, 1]\n",
    "        indx = int(rng.choice(indxs, 1, p=probs))\n",
    "        return po[indx]\n",
    "    \n",
    "    o_pred = []\n",
    "    \n",
    "    for i in range(0, len(sents), batch_size):\n",
    "        batch = sents[i:i+batch_size]\n",
    "        inp = get_embedding_batch(batch)\n",
    "        with torch.no_grad():\n",
    "            logits = model(inp)\n",
    "\n",
    "        predicted_probs = torch.softmax(logits, dim=-1)\n",
    "    \n",
    "        for sent in predicted_probs:\n",
    "            res = []\n",
    "            for probs in sent:\n",
    "                # build set\n",
    "                l_set, s_set, l_set_probs, s_set_probs = build_two_sets(probs, k=5)\n",
    "\n",
    "                # choose set\n",
    "                c_set, c_set_probs = choose_set(l_set, s_set, l_set_probs, s_set_probs)\n",
    "\n",
    "                # choose token\n",
    "                token_eps = 0.1\n",
    "                c_set_probs = exponential_mechanism(c_set_probs, token_eps, 1)\n",
    "                token_idx = int(rng.choice(c_set, 1, p=c_set_probs))\n",
    "\n",
    "                if token_idx == EOS_TOKEN_ID:\n",
    "                    break\n",
    "                res.append(token_idx)\n",
    "        #     o_pred = tokenizer.decode(res, skip_special_tokens=True)\n",
    "            o_pred.append(' '.join(idx2token[idx] for idx in res[1:]))\n",
    "        \n",
    "        if verbose and (i % (print_step * batch_size)) == 0:\n",
    "            print(i)\n",
    "\n",
    "    return o_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "640\n",
      "1280\n",
      "1920\n",
      "2560\n",
      "3200\n",
      "3840\n",
      "4480\n",
      "5120\n",
      "5760\n",
      "6400\n",
      "7040\n",
      "7680\n",
      "8320\n",
      "8960\n",
      "9600\n",
      "10240\n",
      "10880\n",
      "11520\n",
      "12160\n",
      "12800\n",
      "13440\n",
      "14080\n",
      "14720\n",
      "15360\n",
      "16000\n",
      "16640\n"
     ]
    }
   ],
   "source": [
    "train__ = train_posts.text.tolist()\n",
    "model.eval()\n",
    "trans_train = predict_batch(model, train__, seed=42, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_vocab_size = get_vocab_size(trans_train, 3, 128)\n",
    "trans_gram3_train = create_n_grams(trans_train, 3, trans_vocab_size, 128)\n",
    "trans_max_3gram = np.max(trans_gram3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 128, 600)     25383000    ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 128, 600)     25383000    ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 128, 600)     25383000    ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128, 600)     0           ['embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 128, 600)     0           ['embedding_4[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 128, 600)     0           ['embedding_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 126, 500)     900500      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 125, 500)     1200500     ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 124, 500)     1500500     ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 63, 500)     0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 62, 500)     0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 62, 500)     0           ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 31500)        0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 31000)        0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 31000)        0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 93500)        0           ['flatten_3[0][0]',              \n",
      "                                                                  'flatten_4[0][0]',              \n",
      "                                                                  'flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 50)           4675050     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 84,425,550\n",
      "Trainable params: 84,425,550\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "432/432 [==============================] - 36s 84ms/step - loss: 3.4286 - accuracy: 0.2019 - val_loss: 2.9536 - val_accuracy: 0.3957\n",
      "Epoch 2/15\n",
      "432/432 [==============================] - 36s 84ms/step - loss: 2.1869 - accuracy: 0.5323 - val_loss: 1.8205 - val_accuracy: 0.5676\n",
      "Epoch 3/15\n",
      "432/432 [==============================] - 36s 84ms/step - loss: 1.0951 - accuracy: 0.7786 - val_loss: 1.2671 - val_accuracy: 0.6787\n",
      "Epoch 4/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.5114 - accuracy: 0.9154 - val_loss: 1.0020 - val_accuracy: 0.7395\n",
      "Epoch 5/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.2167 - accuracy: 0.9776 - val_loss: 0.9209 - val_accuracy: 0.7534\n",
      "Epoch 6/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0929 - accuracy: 0.9954 - val_loss: 0.8447 - val_accuracy: 0.7795\n",
      "Epoch 7/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0428 - accuracy: 0.9992 - val_loss: 0.8287 - val_accuracy: 0.7812\n",
      "Epoch 8/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0214 - accuracy: 0.9999 - val_loss: 0.8190 - val_accuracy: 0.7858\n",
      "Epoch 9/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.8147 - val_accuracy: 0.7861\n",
      "Epoch 10/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.8153 - val_accuracy: 0.7867\n",
      "Epoch 11/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.8270 - val_accuracy: 0.7855\n",
      "Epoch 12/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8231 - val_accuracy: 0.7873\n",
      "Epoch 13/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8264 - val_accuracy: 0.7896\n",
      "Epoch 14/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8308 - val_accuracy: 0.7904\n",
      "Epoch 15/15\n",
      "432/432 [==============================] - 36s 83ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8441 - val_accuracy: 0.7896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f068d995310>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the 3-gram model\n",
    "trans_gram3_model = define_model(128, len(train_posts.authorid.unique()), trans_max_3gram + 1, 600)\n",
    "trans_gram3_model.fit([trans_gram3_train, trans_gram3_train, trans_gram3_train], author_train_hot, epochs=15, batch_size=32, \n",
    "                verbose = 1, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test_posts.text.tolist()\n",
    "model.eval()\n",
    "trans_test = predict_batch(model, test_texts, seed=42)\n",
    "true_values = author_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted scores\n",
      "F1 score for original text: 0.7768020735745182\n",
      "F1 score for transformed text with transformed model: 0.7492330041099541\n",
      "F1 score for transformed text with orig model: 0.012240394780708912\n",
      "\n",
      "Macro averaged scores\n",
      "F1 score for original text: 0.7768020735745182\n",
      "F1 score for transformed text with transformed model: 0.7492330041099541\n",
      "F1 score for transformed text with orig model: 0.012240394780708914\n"
     ]
    }
   ],
   "source": [
    "preds = gram3_model.predict([gram3_test, gram3_test, gram3_test]).argmax(-1)\n",
    "\n",
    "trans_vocab_size = get_vocab_size(trans_train, 3, 128)\n",
    "trans_gram3_test = create_n_grams(trans_test, 3, trans_vocab_size, 128)\n",
    "trans_preds = trans_gram3_model.predict([trans_gram3_test, trans_gram3_test, trans_gram3_test]).argmax(-1)\n",
    "\n",
    "vocab_size = get_vocab_size(text_train, 3, 128)\n",
    "orig_trans_gram3_test = create_n_grams(trans_test, 3, vocab_size, 128)\n",
    "orig_trans_preds = gram3_model.predict([trans_gram3_test, trans_gram3_test, trans_gram3_test]).argmax(-1)\n",
    "\n",
    "print('Weighted scores')\n",
    "print('F1 score for original text:', f1_score(true_values, preds, average='weighted'))\n",
    "print('F1 score for transformed text with transformed model:', f1_score(true_values, trans_preds, average='weighted'))\n",
    "print('F1 score for transformed text with orig model:', f1_score(true_values, orig_trans_preds, average='weighted'))\n",
    "print()\n",
    "print('Macro averaged scores')\n",
    "print('F1 score for original text:', f1_score(true_values, preds, average='macro'))\n",
    "print('F1 score for transformed text with transformed model:', f1_score(true_values, trans_preds, average='macro'))\n",
    "print('F1 score for transformed text with orig model:', f1_score(true_values, orig_trans_preds, average='macro'))\n",
    "\n",
    "with open('attacker_tests_eng.txt', 'w') as f:\n",
    "    print('Weighted scores', file=f)\n",
    "    print('F1 score for original text:', f1_score(true_values, preds, average='weighted'), file=f)\n",
    "    print('F1 score for transformed text with transformed model:', f1_score(true_values, trans_preds, average='weighted'), file=f)\n",
    "    print('F1 score for transformed text with orig model:', f1_score(true_values, orig_trans_preds, average='weighted'), file=f)\n",
    "    print('', file=f)\n",
    "    print('Macro averaged scores', file=f)\n",
    "    print('F1 score for original text:', f1_score(true_values, preds, average='macro'), file=f)\n",
    "    print('F1 score for transformed text with transformed model:', f1_score(true_values, trans_preds, average='macro'), file=f)\n",
    "    print('F1 score for transformed text with orig model:', f1_score(true_values, orig_trans_preds, average='macro'), file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['target', 'id', 'date', 'flag', 'user', 'text']\n",
    "# sentiment_posts_df = pd.read_csv('/mnt/ess_storage/DN_1/storage/home/vpanov/training.1600000.processed.noemoticon.csv', encoding='latin', names=cols)\n",
    "# sentiment_posts_df = sentiment_posts_df.sample(n=10000)\n",
    "# sentiment_posts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentiment = pd.read_csv('train_sentiment.csv')\n",
    "test_sentiment = pd.read_csv('test_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Fri Apr 17 20:35:29 PDT 2009', 'Wed May 27 07:27:26 PDT 2009')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentiment.date.min(), train_sentiment.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Fri Jun 05 08:37:34 PDT 2009', 'Wed May 13 20:46:34 PDT 2009')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentiment.date.min(), test_sentiment.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_labels = sentiment_posts_df.target.nunique()\n",
    "# num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# lb = LabelEncoder()\n",
    "\n",
    "# sentiment_posts_df.target = lb.fit_transform(sentiment_posts_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_posts_df['text'] = sentiment_posts_df['text'].apply(apply_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentiment['anonymized_text'] = predict_batch(model, train_sentiment['text'].tolist(), seed=42)\n",
    "test_sentiment['anonymized_text'] = predict_batch(model, test_sentiment['text'].tolist(), seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sentiment, test_sentiment = train_test_split(sentiment_posts_df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentiment.to_csv('train_sentiment_2.csv')\n",
    "test_sentiment.to_csv('test_sentiment_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentiment = pd.read_csv('train_sentiment_2.csv')\n",
    "test_sentiment = pd.read_csv('test_sentiment_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "\n",
    "num_labels = train_sentiment.target.nunique()\n",
    "\n",
    "sentiment_tokenizer = AutoTokenizer.from_pretrained(sentiment_model_name)\n",
    "\n",
    "def sentiment_model_init(model_name=sentiment_model_name, num_labels=num_labels):\n",
    "    return AutoModelForSequenceClassification.from_pretrained(sentiment_model_name, num_labels=num_labels, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, targets, tokenizer):\n",
    "        self.inputs = tokenizer(texts, return_tensors=\"pt\", max_length=128, padding='max_length', truncation=True)\n",
    "        self.outputs = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.outputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.inputs['input_ids'][idx],\n",
    "            'token_type_ids': self.inputs['token_type_ids'][idx],\n",
    "            'attention_mask': self.inputs['attention_mask'][idx],\n",
    "            'targets': self.outputs[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_BATCH_SIZE = 8\n",
    "\n",
    "class LitSentiment(pl.LightningModule):\n",
    "    def __init__(self, model_init, train, test, learning_rate=1e-4):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # We hardcode dataset specific stuff here.\n",
    "        self.train_dataset = train\n",
    "        self.test_dataset = test\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model_init()\n",
    "\n",
    "    def forward(self, **inputs):\n",
    "        return self.model(**inputs)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = {a: b for a, b in batch.items() if a != 'targets'}\n",
    "        y = batch['targets']\n",
    "        outputs = self(**x)\n",
    "        logits = outputs.logits\n",
    "        loss = self.loss_func(logits, y)\n",
    "        \n",
    "        f1 = f1_score(y.cpu(), logits.cpu().argmax(dim=-1), average='macro')\n",
    "        \n",
    "        self.log(f'train_loss', loss)\n",
    "        self.log(f'avg_train_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log(f'train_f1', f1)\n",
    "        self.log(f'avg_train_f1', f1, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x = {a: b for a, b in batch.items() if a != 'targets'}\n",
    "        y = batch['targets']\n",
    "        outputs = self(**x)\n",
    "        logits = outputs.logits\n",
    "        loss = self.loss_func(logits, y)\n",
    "        \n",
    "        f1 = f1_score(y.cpu(), logits.cpu().argmax(dim=-1), average='macro')\n",
    "        \n",
    "        self.log(f'val_loss', loss)\n",
    "        self.log(f'avg_val_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log(f'val_f1', f1)\n",
    "        self.log(f'avg_val_f1', f1, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x = {a: b for a, b in batch.items() if a != 'targets'}\n",
    "        y = batch['targets']\n",
    "        outputs = self(**x)\n",
    "        logits = outputs.logits\n",
    "        loss = self.loss_func(logits, y)\n",
    "        \n",
    "        f1 = f1_score(y.cpu(), logits.cpu().argmax(dim=-1), average='macro')\n",
    "        \n",
    "        self.log(f'test_loss', loss)\n",
    "        self.log(f'avg_test_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log(f'test_f1', f1)\n",
    "        self.log(f'avg_test_f1', f1, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def on_train_batch_end(self, outputs, batch, batch_idx, dataloader_idx):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "#         logger.info(f'Batch train loss {metrics}')\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        print(f'Train loss: {metrics[\"avg_train_loss\"]}')\n",
    "        print(f'Train f1: {metrics[\"avg_train_f1\"]}')\n",
    "\n",
    "    def on_validation_batch_end(self, outputs, batch, batch_idx, dataloader_idx):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "#         logger.info(f'Batch validation loss {metrics}')\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        print(f'Val loss: {metrics[\"avg_val_loss\"]}')\n",
    "        print(f'Val f1: {metrics[\"avg_val_f1\"]}')\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        print(f'Test loss: {metrics[\"avg_test_loss\"]}')\n",
    "        print(f'Test f1: {metrics[\"avg_test_f1\"]}')\n",
    "\n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "\n",
    "#     def prepare_data(self):\n",
    "#         self.data = nn.utils.rnn.pad_sequence(self.data)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            train_size = int(0.9 * len(self.train_dataset))\n",
    "            val_size = len(self.train_dataset) - train_size\n",
    "            self.data_train, self.data_val = random_split(self.train_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.data_test = self.test_dataset\n",
    "\n",
    "        self.loss_func = nn.CrossEntropyLoss() # forgot to add ignore_index for BERT\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.data_train, batch_size=BERT_BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.data_val, batch_size=BERT_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.data_test, batch_size=BERT_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "chechpoint_path_sentiment = \"checkpoints_sentiment_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:326: LightningDeprecationWarning: Base `LightningModule.on_train_batch_end` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                          | Params\n",
      "------------------------------------------------------------\n",
      "0 | model     | BertForSequenceClassification | 167 M \n",
      "1 | loss_func | CrossEntropyLoss              | 0     \n",
      "------------------------------------------------------------\n",
      "167 M     Trainable params\n",
      "0         Non-trainable params\n",
      "167 M     Total params\n",
      "669.432   Total estimated model params size (MB)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc67f8da8ce4fdf9fc50c34ab096044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ccf9eea511427bb8414ebf9b34e139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.4595077931880951\n",
      "Val f1: 0.7569757649757656\n",
      "Train loss: 0.5105921626091003\n",
      "Train f1: 0.7239659161140654\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb3196f92e2413bbf78f0ef6ae56431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.44707849621772766\n",
      "Val f1: 0.7718704998705\n",
      "Train loss: 0.3826514482498169\n",
      "Train f1: 0.8090180820551214\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2a02591815499fb351a6bf34d43c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5468509197235107\n",
      "Val f1: 0.753365104031771\n",
      "Train loss: 0.2608020603656769\n",
      "Train f1: 0.8838819178078472\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acce1836b34444f3ab953be715c29010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.514435887336731\n",
      "Val f1: 0.76698121631455\n",
      "Train loss: 0.16835558414459229\n",
      "Train f1: 0.9281298673891294\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38168783973648278bce43e4c0127a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6579263806343079\n",
      "Val f1: 0.7702524142524145\n",
      "Train loss: 0.12034978717565536\n",
      "Train f1: 0.951384626347592\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SentimentDataset(train_sentiment.text.tolist(), train_sentiment.target.tolist(), sentiment_tokenizer)\n",
    "test_dataset = SentimentDataset(test_sentiment.text.tolist(), test_sentiment.target.tolist(), sentiment_tokenizer)\n",
    "sentiment_pl = LitSentiment(sentiment_model_init, train_dataset, test_dataset, 2e-5)\n",
    "sentiment_pl.train()\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=chechpoint_path_sentiment, save_top_k=2, monitor=\"val_loss\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=5,\n",
    "    progress_bar_refresh_rate=20,\n",
    "    gpus=1,\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "trainer.fit(sentiment_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/jovyan/notebooks/checkpoints_sentiment_2/epoch=1-step=2026.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /home/jovyan/notebooks/checkpoints_sentiment_2/epoch=1-step=2026.ckpt\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce3d1f5d89c491fb3f9cc4c6db78cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.49640092253685\n",
      "Test f1: 0.7464845376845383\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\">        Test metric        </span>‚îÉ<span style=\"font-weight: bold\">       DataLoader 0        </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">        avg_test_f1        </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">    0.7464845376845383     </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">       avg_test_loss       </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">     0.49640092253685      </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">          test_f1          </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">    0.7464845376845383     </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">     0.49640092253685      </span>‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m       avg_test_f1       \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m   0.7464845376845383    \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m      avg_test_loss      \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m    0.49640092253685     \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m         test_f1         \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m   0.7464845376845383    \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m    0.49640092253685     \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment_pl.stage = 'test'\n",
    "sentiment_pl.eval()\n",
    "\n",
    "results = trainer.test(sentiment_pl, ckpt_path='best')\n",
    "with open('sentiment_original_2.txt', 'w') as f:\n",
    "    print(results, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                          | Params\n",
      "------------------------------------------------------------\n",
      "0 | model     | BertForSequenceClassification | 167 M \n",
      "1 | loss_func | CrossEntropyLoss              | 0     \n",
      "------------------------------------------------------------\n",
      "167 M     Trainable params\n",
      "0         Non-trainable params\n",
      "167 M     Total params\n",
      "669.432   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9440e7bbb542a787174366605935ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3daf6a851a134550a120ca0812ed66e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5553672909736633\n",
      "Val f1: 0.6788034188034192\n",
      "Train loss: 0.6107645034790039\n",
      "Train f1: 0.623277287869879\n"
     ]
    }
   ],
   "source": [
    "anon_train_dataset = SentimentDataset(train_sentiment.anonymized_text.tolist(), train_sentiment.target.tolist(), sentiment_tokenizer)\n",
    "anon_test_dataset = SentimentDataset(test_sentiment.anonymized_text.tolist(), test_sentiment.target.tolist(), sentiment_tokenizer)\n",
    "sentiment_pl = LitSentiment(sentiment_model_init, anon_train_dataset, anon_test_dataset, 2e-5)\n",
    "sentiment_pl.train()\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=chechpoint_path_sentiment, save_top_k=2, monitor=\"val_loss\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=5,\n",
    "    progress_bar_refresh_rate=20,\n",
    "    gpus=1,\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "trainer.fit(sentiment_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pl.stage = 'test'\n",
    "sentiment_pl.eval()\n",
    "\n",
    "results = trainer.test(sentiment_pl, ckpt_path='best')\n",
    "with open('sentiment_anonymized_2.txt', 'w') as f:\n",
    "    print(results, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem                              Inodes     IUsed     IFree IUse% Mounted on\n",
      "overlay                              244142080   1715770 242426310    1% /\n",
      "tmpfs                                 32939964        20  32939944    1% /dev\n",
      "tmpfs                                 32939964        17  32939947    1% /sys/fs/cgroup\n",
      "shm                                   32939964         2  32939962    1% /dev/shm\n",
      "/dev/mapper/cl-root                   26214400    101408  26112992    1% /mnt/shdstorage\n",
      "/dev/sdb                             244142080   1715770 242426310    1% /etc/hosts\n",
      "ces3.ess:/gpfs/gpfs0/for_DN_1        715165696 272756974 442408722   39% /mnt/ess_storage/DN_1\n",
      "ces4.ess:/gpfs/gpfs0/homedirs/vpanov 715165696 272763597 442402099   39% /home/jovyan/notebooks\n",
      "tmpfs                                 32939964         6  32939958    1% /proc/driver/nvidia\n",
      "devtmpfs                              32934061       629  32933432    1% /dev/nvidia0\n",
      "tmpfs                                 32939964         1  32939963    1% /proc/acpi\n",
      "tmpfs                                 32939964         1  32939963    1% /proc/scsi\n",
      "tmpfs                                 32939964         1  32939963    1% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "# !df -i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1 ./.docker\n",
      "      1 ./absa/ABSA-PyTorch/.git/info\n",
      "      1 ./absa/ABSA-PyTorch/.git/logs/refs/heads\n",
      "      1 ./absa/ABSA-PyTorch/.git/logs/refs/remotes\n",
      "      1 ./absa/ABSA-PyTorch/.git/logs/refs/remotes/origin\n",
      "      1 ./absa/ABSA-PyTorch/.git/refs/heads\n",
      "      1 ./absa/ABSA-PyTorch/.git/refs/remotes\n",
      "      1 ./absa/ABSA-PyTorch/.git/refs/remotes/origin\n",
      "      1 ./absa/ABSA-PyTorch/__pycache__\n",
      "      1 ./absa/ABSA-PyTorch/models/.ipynb_checkpoints\n",
      "      1 ./absa/examplejson\n",
      "      1 ./alpha/data/test_buckets_rnn\n",
      "      1 ./alpha/dl-fintech-bki-master/__pycache__\n",
      "      1 ./alpha/dl-fintech-bki-master/rnn_baseline/checkpoints\n",
      "      1 ./lightning_logs/version_60\n",
      "      2 ./absa/ABSA-PyTorch/.git/logs\n",
      "      2 ./absa/ABSA-PyTorch/.git/logs/refs\n",
      "      2 ./absa/ABSA-PyTorch/.git/objects\n",
      "      2 ./absa/ABSA-PyTorch/.git/objects/pack\n",
      "      2 ./alpha/dl-fintech-bki-master/gb_baseline\n",
      "      2 ./checkpoints_sentiment_2\n",
      "      2 ./lightning_logs\n",
      "      2 ./lightning_logs/version_61\n",
      "      3 ./absa/ABSA-PyTorch/.git/refs\n",
      "      3 ./absa/ABSA-PyTorch/.ipynb_checkpoints\n",
      "      3 ./absa/ABSA-PyTorch/datasets\n",
      "      3 ./alpha/data\n",
      "      4 ./alpha/dl-fintech-bki-master/rnn_baseline/__pycache__\n",
      "      4 ./checkpoints_eng_distilbert_with_static_embs\n",
      "      5 ./absa/ABSA-PyTorch/datasets/acl-14-short-data\n",
      "      5 ./absa/ABSA-PyTorch/layers/__pycache__\n",
      "      5 ./absa/ABSA-PyTorch/state_dict\n",
      "      5 ./alpha/dl-fintech-bki-master\n",
      "      6 ./absa/ABSA-PyTorch/layers\n",
      "      6 ./alpha/data/train_buckets_rnn\n",
      "      6 ./alpha/data/val_buckets_rnn\n",
      "      6 ./checkpoints_eng_distilbert\n",
      "      6 ./checkpoints_sentiment\n",
      "      7 ./alpha/dl-fintech-bki-master/rnn_baseline/.ipynb_checkpoints\n",
      "      8 ./absa/ABSA-PyTorch/datasets/semeval14\n",
      "      8 ./alpha\n",
      "      8 ./checkpoints\n",
      "      9 ./.ipynb_checkpoints\n",
      "      9 ./absa/.ipynb_checkpoints\n",
      "     10 ./alpha/dl-fintech-bki-master/rnn_baseline/checkpoints/pytorch_baseline\n",
      "     11 ./absa/ABSA-PyTorch/.git\n",
      "     11 ./absa/ABSA-PyTorch/.git/hooks\n",
      "     11 ./absa/ABSA-PyTorch/datasets/auto\n",
      "     16 ./absa/ABSA-PyTorch/models/__pycache__\n",
      "     16 ./alpha/dl-fintech-bki-master/rnn_baseline\n",
      "     18 ./absa/ABSA-PyTorch/models\n",
      "     19 ./absa\n",
      "     20 ./absa/ABSA-PyTorch\n",
      "     31 .\n"
     ]
    }
   ],
   "source": [
    "# !find ./ -xdev -printf '%h\\n' | sort | uniq -c | sort -k 1 -n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf \"./.vscode-server\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vpanov    1910 47.0  0.0  11676  3104 pts/1    Ss+  16:03   0:00 /bin/bash -c ps -aux | grep vscode\n",
      "vpanov    1912  0.0  0.0  13220  1052 pts/1    S+   16:03   0:00 grep vscode\n"
     ]
    }
   ],
   "source": [
    "# !ps -aux | grep vscode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SentenceTransformer embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteDisconnected\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m# sending a valid response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             raise RemoteDisconnected(\"Remote end closed connection without\"\n\u001b[0m\u001b[1;32m    277\u001b[0m                                      \" response\")\n",
      "\u001b[0;31mRemoteDisconnected\u001b[0m: Remote end closed connection without response",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    441\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    786\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m# sending a valid response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             raise RemoteDisconnected(\"Remote end closed connection without\"\n\u001b[0m\u001b[1;32m    277\u001b[0m                                      \" response\")\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-33ca4c565621>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msent_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'distiluse-base-multilingual-cased-v1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;31m# Download from hub with caching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 snapshot_download(model_name_or_path,\n\u001b[0m\u001b[1;32m     87\u001b[0m                                     \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                                     \u001b[0mlibrary_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sentence-transformers'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sentence_transformers/util.py\u001b[0m in \u001b[0;36msnapshot_download\u001b[0;34m(repo_id, revision, cache_dir, library_name, library_version, user_agent, ignore_files, use_auth_token)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0m_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHfApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0mmodel_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     storage_folder = os.path.join(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/huggingface_hub/utils/_deprecation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             args_msg = [\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mmodel_info\u001b[0;34m(self, repo_id, revision, token, timeout, securityStatus)\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"authorization\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mf\"Bearer {token}\"\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0mstatus_query_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"securityStatus\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msecurityStatus\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m         r = requests.get(\n\u001b[0m\u001b[1;32m   1119\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus_query_param\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    527\u001b[0m         }\n\u001b[1;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mProtocolError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMaxRetryError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))"
     ]
    }
   ],
   "source": [
    "sent_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
