# socialnet-processing

## Структура

1. **anonymization** - ноутбуки по анонимизации
- *mucaat* - основной ноутбук, есть обучение метода MuCAAT и тестирование анонимизированных данных на задачах Authorship identification и Sentiment analysis
- *mucaat-eng_distilbert.ipynb* - замена мультиязычного distilbert на английскую версию
- *mucaat-eng_distlilbert_with_static_embs.ipynb* - замена, как в предыдущем ноутбуке + в рекурентную часть сети попадают статичные эмбеддинги из словаря (получены с помощью усреднения всех эмбеддингов слов на датасете)
- *mucaat-Copy1.ipynb* - не помню, зачем делал копию, скорей всего код никак не отличается от mucaat.ipynb
- *utils.py* - полезные функции
- *vk_distilbert.ipynb* - обучение и тестирование метода MuCAAT аналогично ноутбуку mucaat.ipynb, но на русских текстах. Пришлось немного поменять архитектуру, добавив активации после каждого рекурентного слоя, но больше ничего в архитектуре не поменялось.
- В какой-то момент я заново сбилдил контейнер, некоторые библиотеки обновились, и в новой версии pytorch-lightning поменялись некоторые моменты из-за чего все ноутбуки кроме vk_distilbert.ipynb могут не работать. Самый актуальный и оттестированный код в vk_distilbert.ipynb.
- ноутбук mucaat содержит комментарии, в принципе в других ноутбуках в этой папке делается то же самое, так что комменты только в одном ноутбуке

2. **jkh**
- *clickhouse_requests.md* - SQL запросы к кликхаусу для извлечения ЖКХ постов, в базе данных содержатся посты только до 2019 года
- *jkh_groups_data.tar.gz* - данные, которые я использовал или сохранял в процессе работы ноутбуков
- *jkh_groups_try2.ipynb* - ноутбук с тематическим моделированием постов из ЖКХ групп, используются данные, полученные в topic_modelling.ipynb
- *semconvtree.py* - классы, относящиеся к semconvtree
- *topic_modelling.ipynb* - тут весь препроцессинг текста из инсты и вк, и фильтрация постов
- *utils.py* - полезные функции

3. **jkh_colab**
- *data* - данные
- *posts.zip* - посты из групп с 2017 по 2022 года
- *purchases.zip* - заказы различных организаций в Санкт-Петербурге, в том числе и ЖКС
- *zakupki.zip* - закупки различных организаций в Санкт-Петербурге, в том числе и ЖКС
- *finding_jkh_problems.ipynb* - поиск в посте описания проблемы с помощью gpt-3.5
- *reading_xml_purchases.ipynb* - парсинг xml файлов о заказах в csv
- *reading_xml_zakupki.ipynb* - парсинг xml файлов о закупках в csv
- *visualize_posts_and_zakupki.ipynb* - визуализация заказов и закупок и постов на интерактивной карте
- закупки (zakupki.zip) и заказы (purchases.zip) отличаются скорей всего тем, что первые - это что-то свершившееся на момент регистрации, а вторые ещё не свершились
- закупки и заказы - это открытые данные правительства РФ, они были скачаны с ftp сервера ftp.zakupki.gov.ru, логин: `fz223free`, пароль: `fz223free`
- есть [репозиторий](https://github.com/Homyakin/ZakupkiParser) с парсерор данных закупок и заказов, но запустить его не удалось, был написан вручную код

4. **jkh_local**
- *extract_address_from_vk.ipynb* - вытаскиваю адреса ЖКХ компаний с сайта mingkh.ru и связываю их с группами по адресу
- *get_comments.ipynb* - вытаскивание постов из групп с помощью vk api

5. **base.dockerfile** - докерфайл с зафиксированными версиями библиотек, строил контейнеры на его базе
6. **twiiter.tar.gz** - датасет mokoron, русский язык, sentiment analysis, для vk_distilbert.ipynb
7. **vk.tar.gz** - датасет с публикациями из вк, русский язык, для vk_distilbert.ipynb